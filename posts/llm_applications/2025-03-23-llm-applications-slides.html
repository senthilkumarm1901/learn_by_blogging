<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Senthil Kumar">
<meta name="dcterms.date" content="2025-04-16">

<title>The Evolution Of GenAI Applications -   From Single LLM Call to Agentic AI ‚Äì Learn by Blogging</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-01da79b04741a7368f1573b6126597b3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Learn by Blogging</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/senthilkumarm1901"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/senthilkumarm1901"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">The Evolution Of GenAI Applications - <br> From Single LLM Call to Agentic AI</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">LLMs</div>
                <div class="quarto-category">AI Agents</div>
                <div class="quarto-category">LLM Applications</div>
                <div class="quarto-category">üåü Featured in Medium.com</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Senthil Kumar </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 16, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="motivation-of-the-talk" class="level1">
<h1>Motivation of the Talk</h1>
<blockquote class="blockquote">
<ul>
<li>Before jumping onto the Agentic AI bandwagon, <br>could we reflect on the evolution that led to the current Agentic AI era?</li>
</ul>
</blockquote>
<hr>
<section id="agenda-of-this-presentation-in-a-picture" class="level2">
<h2 class="anchored" data-anchor-id="agenda-of-this-presentation-in-a-picture">Agenda of this Presentation in a Picture</h2>
<p><img src="images/main_pic_3.png" alt="" width="400"></p>
<hr>
</section>
<section id="agenda" class="level2">
<h2 class="anchored" data-anchor-id="agenda">Agenda</h2>
<ul>
<li>Evolution of GenAI Applications
<ul>
<li><ol type="1">
<li>Stream Processing <b><em>LLM</em></b> Applications</li>
</ol></li>
<li><ol start="2" type="1">
<li>Batch Processing <b><em>LLM</em></b> Applications</li>
</ol></li>
<li>Detour: The Evolution of Reasoning in LLMs</li>
<li><ol start="3" type="1">
<li><b><em>Agentic</em></b> Applications</li>
</ol></li>
</ul></li>
<li>What the Experts say?</li>
</ul>
<hr>
</section>
<section id="agenda-1" class="level2">
<h2 class="anchored" data-anchor-id="agenda-1">Agenda</h2>
<p><img src="images/llm_categorization.png" alt="LLM Categotization" width="400"></p>
<hr>
</section>
<section id="agenda-2" class="level2">
<h2 class="anchored" data-anchor-id="agenda-2">Agenda</h2>
<ul>
<li>Evolution of GenAI Applications
<ul>
<li><ol type="1">
<li>Stream Processing <em>LLM</em> Applications</li>
</ol>
<ul>
<li><code>Data processed in real-time</code></li>
</ul></li>
<li><ol start="2" type="1">
<li>Batch Processing <em>LLM</em> Applications</li>
</ol>
<ul>
<li><code>Data collected and processed in batches</code></li>
</ul></li>
<li>The Evolution of Reasoning in LLMs</li>
<li><ol start="3" type="1">
<li>Agentic Applications</li>
</ol>
<ul>
<li>Almost all agentic apps are streaming LLM applications</li>
<li>Some agentic apps do process data in batch, at least in the background!</li>
</ul></li>
</ul></li>
</ul>
<hr>
</section>
<section id="section-1" class="level2">
<h2 class="anchored" data-anchor-id="section-1">Section 1</h2>
<section id="stream-processing-llm-applications" class="level3">
<h3 class="anchored" data-anchor-id="stream-processing-llm-applications">Stream Processing <em>LLM</em> Applications</h3>
<ul>
<li>A Single LLM API Call Response</li>
<li>A Chatbot with Contextual History</li>
<li>A RAG Chatbot</li>
</ul>
<hr>
</section>
</section>
<section id="llm-application-with-a-single-llm-api-call" class="level2">
<h2 class="anchored" data-anchor-id="llm-application-with-a-single-llm-api-call">LLM Application with a Single LLM API Call</h2>
<p><img src="images/streaming_application_1.png" alt="" width="200"></p>
<ul>
<li>1 LLM call per response</li>
<li>Your query fits into a set prompt of the selected LLM model</li>
</ul>
<hr>
</section>
<section id="chatbot-application-with-a-single-llm-api-call" class="level2">
<h2 class="anchored" data-anchor-id="chatbot-application-with-a-single-llm-api-call">Chatbot Application with a Single LLM API Call</h2>
<p><img src="images/chatbot_app_streaming_2.png" alt="" width="200"></p>
<ul>
<li>Adds contextual history to prompts, enhancing conversational memory.</li>
<li>Still makes only one LLM call per message, but simulates continuity.</li>
<li>Chat history is stitched manually into each prompt (stateless memory).</li>
</ul>
<p><br></p>
<p>Image Inspiration: Jay Alammar‚Äôs Hands-on Large Language Models</p>
<hr>
</section>
<section id="rag-chatbot-12" class="level2">
<h2 class="anchored" data-anchor-id="rag-chatbot-12">RAG Chatbot (1/2)</h2>
<p><img src="images/rag_llm_1.png" alt="" width="300"></p>
<ul>
<li>Embeddings + vector search = more accurate and context-aware responses.</li>
<li>A powerful architecture for grounding answers in known data sources (better for avoiding hallucinations)</li>
</ul>
<hr>
</section>
<section id="rag-chatbot-22" class="level2">
<h2 class="anchored" data-anchor-id="rag-chatbot-22">RAG Chatbot (2/2)</h2>
<p><img src="images/rag_llm_embedding_2.png" alt="" width="200"></p>
<ul>
<li>Converts raw documents (text/images) into semantically rich embeddings.</li>
<li>Embeddings are indexed into a Vector DB for fast similarity search.</li>
<li>Document chunking improves search granularity and retrieval accuracy.</li>
<li>Better your chunking, better is the accuracy of answers</li>
<li>Better the embeddings in encoding meaning, better is the accuracy of answers</li>
</ul>
<hr>
</section>
<section id="llm-rag-vs-agentic-rag" class="level2">
<h2 class="anchored" data-anchor-id="llm-rag-vs-agentic-rag">LLM RAG vs Agentic RAG</h2>
<ul>
<li>Jumping a few steps here but we will circle back to Agentic RAG</li>
</ul>
<div style="display: flex; justify-content: space-around; align-items: center;">
<p><img src="images/llm_rag.png" alt="" width="30%"> <img src="images/agentic_rag.png" alt="" width="40%"></p>
</div>
<hr>
</section>
</section>
<section id="batch-processing-llm-applications" class="level1">
<h1>2. Batch Processing <em>LLM</em> Applications</h1>
<hr>
<section id="section-2" class="level2">
<h2 class="anchored" data-anchor-id="section-2">Section 2</h2>
<section id="batch-processing-llm-applications-1" class="level3">
<h3 class="anchored" data-anchor-id="batch-processing-llm-applications-1">Batch Processing <em>LLM</em> Applications</h3>
<ul>
<li>A Text Classification Application
<ul>
<li>with 1 LLM API call per datapoint</li>
</ul></li>
<li>A Chained LLM Application</li>
</ul>
<hr>
</section>
</section>
<section id="a-typical-batch-processing-llm-application" class="level2">
<h2 class="anchored" data-anchor-id="a-typical-batch-processing-llm-application">A Typical Batch Processing LLM Application</h2>
<p><img src="images/prompt_templatizing.png" alt="" width="300"></p>
<ul>
<li>Context or instructions can be dynamically adjusted via prompt templating</li>
<li>External context can be modularized to avoid long, hard-coded prompts</li>
<li>All data in the same batch use the same prompt template</li>
</ul>
<hr>
</section>
<section id="a-text-classification-application" class="level2">
<h2 class="anchored" data-anchor-id="a-text-classification-application">A Text Classification Application</h2>
<p><img src="images/batchjob_app_text_cat.png" alt="" width="200"></p>
<ul>
<li>Processes multiple data items (e.g., documents) using the same LLM pipeline.</li>
<li>Scales LLM use to bulk operations like NER tagging or classification.</li>
</ul>
<hr>
</section>
<section id="a-chained-llm-application-12" class="level2">
<h2 class="anchored" data-anchor-id="a-chained-llm-application-12">A Chained LLM Application (1/2)</h2>
<p><img src="images/batchjob_app_text_cat_2.png" alt="" width="200"></p>
<ul>
<li>Uses chained prompts where the output of one LLM call feeds into another.</li>
<li>Demonstrates how logic can be split into reusable, modular steps.</li>
</ul>
<hr>
</section>
<section id="a-chained-llm-application-22" class="level2">
<h2 class="anchored" data-anchor-id="a-chained-llm-application-22">A Chained LLM Application (2/2)</h2>
<p><img src="images/llm_chaining_1.png" alt="" style="width: 40%;"></p>
<p><br></p>
<p><img src="images/llm_chaining_2.png" alt="" style="width: 70%;"></p>
<hr>
</section>
<section id="detour-section--" class="level2">
<h2 class="anchored" data-anchor-id="detour-section--">Detour Section -</h2>
<section id="the-evolution-of-reasoning-in-llms" class="level3">
<h3 class="anchored" data-anchor-id="the-evolution-of-reasoning-in-llms">The Evolution of Reasoning in LLMs</h3>
<ul>
<li>Prompt Engineering Approaches - In Focus - CoT and ReAct</li>
<li>Large Reasoning Models &lt;‚Äì Are there any takers?</li>
</ul>
<hr>
</section>
</section>
<section id="how-prompt-engineering-started" class="level2">
<h2 class="anchored" data-anchor-id="how-prompt-engineering-started">How Prompt Engineering Started</h2>
<p><img src="images/prompt_engg_1.png" alt="" width="200"></p>
<ul>
<li>As the context window of LLMs improved,
<ul>
<li>Input-Output Prompting evolved into Few Shot Prompting for better results</li>
</ul></li>
</ul>
<hr>
</section>
<section id="reasoning-prompts---cot-react-prompts-in-few-shot-style" class="level2">
<h2 class="anchored" data-anchor-id="reasoning-prompts---cot-react-prompts-in-few-shot-style">Reasoning Prompts - CoT &amp; ReAct Prompts in Few Shot Style</h2>
<p><img src="images/prompt_engg_2.png" alt="" width="200"></p>
<ul>
<li>Explaining LLMs to think/reason step by step with examples</li>
</ul>
<hr>
</section>
<section id="reasoning-prompts---cot-react-techniques-during-inference" class="level2">
<h2 class="anchored" data-anchor-id="reasoning-prompts---cot-react-techniques-during-inference">Reasoning Prompts - CoT &amp; ReAct Techniques During Inference</h2>
<p><img src="images/prompt_engg_3.png" alt="" width="200"></p>
<ul>
<li>Explaining LLMs to think/reason step by step with examples</li>
</ul>
<hr>
</section>
<section id="structured-function-calling---a-robust-alternative-to-react" class="level2">
<h2 class="anchored" data-anchor-id="structured-function-calling---a-robust-alternative-to-react">Structured Function Calling - A Robust Alternative to ReAct</h2>
<p><img src="images/structured_func_call_new.png" alt="" width="600"></p>
<ul>
<li>The structured JSON that LLM generates</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"function"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"name"</span><span class="fu">:</span> <span class="st">"search_web"</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">},</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"parameters"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"query"</span><span class="fu">:</span> <span class="st">"capital of Japan"</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">}</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
<section id="structured-function-calling---openai-example" class="level2">
<h2 class="anchored" data-anchor-id="structured-function-calling---openai-example">Structured Function Calling - OpenAI Example</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#0. Implement the tool</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> search_web(search_query)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  ...</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  ...</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> tool_answer</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Describe the tool</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>tools <span class="op">=</span> [</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"type"</span>: <span class="st">"function"</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"function"</span>: {</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">"name"</span>: <span class="st">"search_web"</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            <span class="st">"description"</span>: <span class="st">"Searches the web for a factual answer to a question."</span>,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">"parameters"</span>: {</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>                <span class="st">"type"</span>: <span class="st">"object"</span>,</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>                <span class="st">"properties"</span>: {</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"query"</span>: {</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"type"</span>: <span class="st">"string"</span>,</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"description"</span>: <span class="st">"The question or term to search for"</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>                    }</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>                },</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>                <span class="st">"required"</span>: [<span class="st">"query"</span>]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Pass the prompt query to the OpenAI</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Let OpenAI decide if it wants to use the tool</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>messages <span class="op">=</span> [</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"What is the capital of Japan?"</span>}</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">"gpt4o"</span>, </span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    messages<span class="op">=</span>messages,</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    tools<span class="op">=</span>tools,</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    tool_choice<span class="op">=</span><span class="st">"auto"</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Execute the Tool Call</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>tool_call <span class="op">=</span> response.choices[<span class="dv">0</span>].message.get(<span class="st">"tool_calls"</span>, [<span class="va">None</span>])[<span class="dv">0</span>]</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> tool_call:</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    function_name <span class="op">=</span> tool_call.function.name</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    arguments <span class="op">=</span> <span class="bu">eval</span>(tool_call.function.arguments)  <span class="co"># or use `json.loads`</span></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 4: Simulate calling the function (you‚Äôd implement it)</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> function_name <span class="op">==</span> <span class="st">"search_web"</span>:</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>        query <span class="op">=</span> arguments[<span class="st">"query"</span>]</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        tool_result <span class="op">=</span> search_web(query)</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Step 5: Append tool response and ask model to finish</span></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>        messages <span class="op">+=</span> [</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>            response.choices[<span class="dv">0</span>].message,</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>                <span class="st">"role"</span>: <span class="st">"tool"</span>,</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>                <span class="st">"tool_call_id"</span>: tool_call.<span class="bu">id</span>,</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>                <span class="st">"name"</span>: function_name,</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>                <span class="st">"content"</span>: tool_result</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>        final_response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>            model<span class="op">=</span><span class="st">"gpt4o"</span>,</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>            messages<span class="op">=</span>messages</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"üß† Final Answer:"</span>, final_response.choices[<span class="dv">0</span>].message[<span class="st">"content"</span>])</span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"üí¨ Direct Answer:"</span>, response.choices[<span class="dv">0</span>].message[<span class="st">"content"</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
</section>
<section id="react-vs-structured-function-calling" class="level2">
<h2 class="anchored" data-anchor-id="react-vs-structured-function-calling">ReAct vs Structured Function Calling</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 38%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>ReAct (Prompt Text)</th>
<th>Function Calling (Structured JSON)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Output Format</td>
<td><code>"Action: Search('capital of Japan')"</code></td>
<td>Structured JSON with function + args</td>
</tr>
<tr class="even">
<td>Parsing Required?</td>
<td>‚ùå You parse the text manually</td>
<td>‚úÖ Handled by OpenAI, LangChain toolkit</td>
</tr>
<tr class="odd">
<td>Execution Clarity</td>
<td>‚ùå Model can hallucinate tool syntax</td>
<td>‚úÖ Only valid, defined tools used</td>
</tr>
<tr class="even">
<td>Model Adherence</td>
<td>üü° You ‚Äúhope‚Äù it follows format</td>
<td>üéØ You give it tool schema (e.g.: OpenAPI)</td>
</tr>
<tr class="odd">
<td>Robustness for Development</td>
<td>‚ùå Fragile</td>
<td>‚úÖ Very reliable and scalable</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="large-reasoning-models" class="level2">
<h2 class="anchored" data-anchor-id="large-reasoning-models">Large Reasoning Models</h2>
<p><img src="images/LLMs_vs_LRMs.png" alt="" width="200"></p>
<ul>
<li>LLMs: input ‚Üí LLM ‚Üí output statement</li>
<li>LRMs: input ‚Üí LRM ‚Üí Keeps Planning Steps ‚Üí Finally, output statement <br></li>
<li>LRMs are generating text similar LLMs but they are trained to ‚Äúthink before acting‚Äù</li>
<li>E.g.: OpenAI o1, DeepSeek R1</li>
<li>LRMs think during inference, hence needing more ‚Äútest-time compute‚Äù</li>
</ul>
<p><a href="https://thenuancedperspective.substack.com/p/day-6-planning-in-agents-reasoning">Source 1: Aishwarya Naresh‚Äôs Substack</a> <br> <a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms">Source 2: A Visual Guide to Reasoning LLMs</a></p>
<hr>
</section>
<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">Recap</h2>
<ul>
<li>We have discussed the following so far:
<ul>
<li>How LLMs are used in streaming and batch application</li>
<li>How LLMs work with Tools and RAG setup</li>
<li>How LLMs think (planning/reasoning/reflection,etc.,)</li>
<li>In Agentic AI, we put the above concepts together</li>
</ul></li>
</ul>
<hr>
</section>
<section id="section-3--" class="level2">
<h2 class="anchored" data-anchor-id="section-3--">Section 3 -</h2>
<section id="agentic-ai-applications" class="level3">
<h3 class="anchored" data-anchor-id="agentic-ai-applications">Agentic AI Applications</h3>
<ul>
<li>Components that comprise an Agent</li>
<li>Architecture of a Single Agent</li>
<li>What do these protocols - MCP and Google‚Äôs A2A - mean?</li>
<li>Real World Agents - ChatGPT vs Perplexity vs DeepResearch</li>
<li>What are Multi-Agent Systems</li>
<li>What do the Experts say?</li>
</ul>
<hr>
</section>
</section>
<section id="what-are-agents" class="level2">
<h2 class="anchored" data-anchor-id="what-are-agents">What are Agents?</h2>
<ul>
<li>LLMs generate text</li>
<li>Agents generate text and also <strong>perform actions</strong></li>
<li>Chatbot = LLM + Memory</li>
<li>RAG Chatbot = LLM + Memory + Vectorized(Source Docs)</li>
<li>Tool LLMs = LLM (brain) + Function Calling (hands)</li>
<li>Agent = LLM + Tools + Memory + Planning (next steps, state management)</li>
<li>Agent = Engineering Wrappers around LLMs</li>
</ul>
<p><br></p>
<p>Source for the perspective - ‚ÄúEngineering Wrappers around LLMs‚Äù:<br><a href="https://thenuancedperspective.substack.com/p/day-1-what-are-agents-anyway">Aishwarya Naresh in Substack</a></p>
<hr>
</section>
<section id="architecture-of-a-single-agent" class="level2">
<h2 class="anchored" data-anchor-id="architecture-of-a-single-agent">Architecture of a Single Agent</h2>
<p><img src="images/single_agent_mermaid.png" alt="" width="300"></p>
<hr>
</section>
<section id="example-of-a-single-agent-application" class="level2">
<h2 class="anchored" data-anchor-id="example-of-a-single-agent-application">Example of a Single Agent Application</h2>
<p><img src="images/single_agent_example.png" alt="" width="300"></p>
<hr>
</section>
<section id="agentic-rag" class="level2">
<h2 class="anchored" data-anchor-id="agentic-rag">Agentic RAG</h2>
<p><img src="images/agentic_rag.png" alt="" width="300"></p>
<ul>
<li>Agentic RAG is not one-shot retrieval.</li>
<li>The Agent retrieves, then reflects on the result, re-fetches if necessary</li>
</ul>
<hr>
</section>
<section id="where-does-mcp-fit-here" class="level2">
<h2 class="anchored" data-anchor-id="where-does-mcp-fit-here">Where does MCP fit here?</h2>
<p><strong>Before MCP</strong>:</p>
<p><img src="images/mcp_2.png" alt="" width="300"></p>
<p><strong>After MCP</strong>:</p>
<p><img src="images/mcp_1.png" alt="" width="300"></p>
<p>Source of the amazing images: <a href="https://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/">Norah Sakal Blog Post</a></p>
<hr>
</section>
<section id="where-does-mcp-fit-here-1" class="level2">
<h2 class="anchored" data-anchor-id="where-does-mcp-fit-here-1">Where does MCP fit here?</h2>
<p><img src="images/mcp_sequence_diagram.png" alt="" width="200"></p>
<ul>
<li>MCP - Not just a package or library (well it has a python package!).</li>
<li>It is a protocol like TCP/SMTP. It is like OpenAPI Spec for REST APIs. <a href="https://gyliu513.medium.com/mcp-the-openapi-for-ai-agents-725588f2b0d3">source of the analogy</a></li>
<li>MCP standardizes how the context (prompt, tools, memory, retrieved docs, etc.,) get passed on to the Model.</li>
</ul>
<p>Source of the amazing image: <a href="https://blog.stackademic.com/mcp-model-context-protocol-simplified-976b46f01efd">Hirusha Fernando Medium Article</a></p>
<hr>
</section>
<section id="real-world-agents---chatgpt-vs-perplexity-vs-openai-deepresearch" class="level2">
<h2 class="anchored" data-anchor-id="real-world-agents---chatgpt-vs-perplexity-vs-openai-deepresearch">Real World Agents - ChatGPT vs Perplexity vs OpenAI DeepResearch</h2>
<ul>
<li>ChatGPT: General Purpose Conversational AI whose knowledge is limited to the time of training data</li>
<li>Perplexity: Google (Search Engine) + ChatGPT (Conversational AI)
<ul>
<li>Generates text as an answer with sources for every portion</li>
</ul></li>
<li>Deep Research: An Agentic RAG with WebSearch (&amp; other tools) and Multi-step reasoning <a href="https://thenuancedperspective.substack.com/p/day-9-real-world-agentic-systems">source</a></li>
</ul>
<hr>
</section>
<section id="multi-agent-systems" class="level2">
<h2 class="anchored" data-anchor-id="multi-agent-systems">Multi-Agent Systems</h2>
<p><img src="images/multi_agent_simple_view.png" alt="" width="200"></p>
<ul>
<li>Agents operate in parallel with their own responsibilities.</li>
<li>Shared memory is used for cross-agent communication.</li>
<li>Tool usage and autonomy allow scalable, modular problem-solving.</li>
</ul>
<hr>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<hr>
<section id="what-the-experts-say-12" class="level2">
<h2 class="anchored" data-anchor-id="what-the-experts-say-12">What the Experts Say? (1/2)</h2>
<ul>
<li>‚ÄúLet us build a Multi-Agent System‚Äù - ‚ùå a wrong view to start with
<ul>
<li>‚úÖ ‚ÄúWhat are we trying to solve‚Äù</li>
</ul></li>
<li>Simpler systems are better:
<ul>
<li>RAG LLM Chatbot &gt;&gt; Agentic RAG</li>
<li>LLM + Function Calling &gt;&gt; Single Agent</li>
<li>Single Agent (with different ‚Äúmodes‚Äù) &gt;&gt; Multi Agents</li>
</ul></li>
<li>Have caution in using inference-compute-heavy Large Reasoning Models - the jury is still out!</li>
</ul>
<hr>
</section>
<section id="what-the-experts-say-22" class="level2">
<h2 class="anchored" data-anchor-id="what-the-experts-say-22">What the Experts Say? (2/2)</h2>
<ul>
<li>Observability:
<ul>
<li>Capability to review logs of LLMs or Agents function is key to success</li>
</ul></li>
<li>Latency:
<ul>
<li>Complex systems typically come with high Latency</li>
</ul></li>
<li>Evaluation:
<ul>
<li>Accuracy: Have your test questions clearly prepared and tested!</li>
<li>Cost: Have a tab on the token usage.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="my-main-resources" class="level2">
<h2 class="anchored" data-anchor-id="my-main-resources">My Main Resources</h2>
<ul>
<li>Mermaid Charts drawn from practical experience are collated <a href="https://gist.github.com/senthilkumarm1901/59c83abf23e70d935d25b73ef8bbf44f">here</a></li>
<li>Extensive interactions with ChatGPT/ Perplexity for correcting/editing my mermaid charts</li>
<li>The 10 Article Substack Piece by Aishwarya Naresh - <a href="https://thenuancedperspective.substack.com/">The Nuanced Perspective</a></li>
<li>O‚Äôreilly Course on <a href="https://learning.oreilly.com/course/modern-automated-ai/9780135414965/">Modern Automated AI Agents</a></li>
</ul>
<hr>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/senthilkumarm1901\.github\.io\/learn_by_blogging\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<script src="https://utteranc.es/client.js" repo="senthilkumarm1901/QuartoBlogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>