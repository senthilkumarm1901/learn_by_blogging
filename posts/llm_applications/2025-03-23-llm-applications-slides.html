<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="author" content="Senthil Kumar">
  <meta name="dcterms.date" content="2025-04-16">
  <title>Learn by Blogging – The Evolution Of GenAI Applications -   From Single LLM Call to Agentic AI</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-534cd8e3a96973385dffff3f4709048d.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" style="font-size: 0.6em;" class="quarto-title-block center">
  <h1 class="title">The Evolution Of GenAI Applications - <br> From Single LLM Call to Agentic AI</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Senthil Kumar 
</div>
</div>
</div>

  <p class="date">2025-04-16</p>
</section>
<section>
<section id="motivation-of-the-talk" class="title-slide slide level1 center">
<h1>Motivation of the Talk</h1>
<blockquote>

<ul>
<li class="fragment">Before jumping onto the Agentic AI bandwagon, <br>could we reflect on the evolution that led to the current Agentic AI era?</li>
</ul>

</blockquote>
</section>
<section id="agenda-of-this-presentation-in-a-picture" class="slide level2">
<h2>Agenda of this Presentation in a Picture</h2>

<img src="images/main_pic_3.png" alt="" width="400" class="r-stretch"></section>
<section id="agenda" class="slide level2">
<h2>Agenda</h2>
<div style="font-size: 0.8em;">
<ul>
<li>Evolution of GenAI Applications
<ul>
<li><ol type="1">
<li>Stream Processing <b><em>LLM</em></b> Applications</li>
</ol></li>
<li><ol start="2" type="1">
<li>Batch Processing <b><em>LLM</em></b> Applications</li>
</ol></li>
<li>Detour: The Evolution of Reasoning in LLMs</li>
<li><ol start="3" type="1">
<li><b><em>Agentic</em></b> Applications</li>
</ol></li>
</ul></li>
<li>What the Experts say?</li>
</ul>
</div>
</section>
<section id="agenda-1" class="slide level2">
<h2>Agenda</h2>

<img src="images/llm_categorization.png" alt="LLM Categotization" width="400" class="r-stretch"></section>
<section id="agenda-2" class="slide level2">
<h2>Agenda</h2>
<div style="font-size: 0.8em;">
<ul>
<li>Evolution of GenAI Applications
<ul>
<li><ol type="1">
<li>Stream Processing <em>LLM</em> Applications</li>
</ol>
<ul>
<li><code>Data processed in real-time</code></li>
</ul></li>
<li><ol start="2" type="1">
<li>Batch Processing <em>LLM</em> Applications</li>
</ol>
<ul>
<li><code>Data collected and processed in batches</code></li>
</ul></li>
<li>The Evolution of Reasoning in LLMs</li>
<li><ol start="3" type="1">
<li>Agentic Applications</li>
</ol>
<ul>
<li>Almost all agentic apps are streaming LLM applications</li>
<li>Some agentic apps do process data in batch, at least in the background!</li>
</ul></li>
</ul></li>
</ul>
</div>
</section>
<section id="section-1" class="slide level2">
<h2>Section 1</h2>
<h3 id="stream-processing-llm-applications">Stream Processing <em>LLM</em> Applications</h3>
<ul>
<li class="fragment">A Single LLM API Call Response</li>
<li class="fragment">A Chatbot with Contextual History</li>
<li class="fragment">A RAG Chatbot</li>
</ul>
</section>
<section id="llm-application-with-a-single-llm-api-call" class="slide level2">
<h2>LLM Application with a Single LLM API Call</h2>

<img src="images/streaming_application_1.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">1 LLM call per response</li>
<li class="fragment">Your query fits into a set prompt of the selected LLM model</li>
</ul>
</div>
</section>
<section id="chatbot-application-with-a-single-llm-api-call" class="slide level2">
<h2>Chatbot Application with a Single LLM API Call</h2>

<img src="images/chatbot_app_streaming_2.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">Adds contextual history to prompts, enhancing conversational memory.</li>
<li class="fragment">Still makes only one LLM call per message, but simulates continuity.</li>
<li class="fragment">Chat history is stitched manually into each prompt (stateless memory).</li>
</ul>
</div>
<div style="font-size: 0.3em;">
<p>Image Inspiration: Jay Alammar’s Hands-on Large Language Models</p>
</div>
</section>
<section id="rag-chatbot-12" class="slide level2">
<h2>RAG Chatbot (1/2)</h2>

<img src="images/rag_llm_1.png" alt="" width="300" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">Embeddings + vector search = more accurate and context-aware responses.</li>
<li class="fragment">A powerful architecture for grounding answers in known data sources (better for avoiding hallucinations)</li>
</ul>
</div>
</section>
<section id="rag-chatbot-22" class="slide level2">
<h2>RAG Chatbot (2/2)</h2>

<img src="images/rag_llm_embedding_2.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">Converts raw documents (text/images) into semantically rich embeddings.</li>
<li class="fragment">Embeddings are indexed into a Vector DB for fast similarity search.</li>
<li class="fragment">Document chunking improves search granularity and retrieval accuracy.</li>
<li class="fragment">Better your chunking, better is the accuracy of answers</li>
<li class="fragment">Better the embeddings in encoding meaning, better is the accuracy of answers</li>
</ul>
</div>
</section>
<section id="llm-rag-vs-agentic-rag" class="slide level2">
<h2>LLM RAG vs Agentic RAG</h2>
<div style="font-size: 0.5em;">
<ul>
<li>Jumping a few steps here but we will circle back to Agentic RAG</li>
</ul>
</div>
<div style="display: flex; justify-content: space-around; align-items: center;">
<p><img src="images/llm_rag.png" alt="" width="30%"> <img src="images/agentic_rag.png" alt="" width="40%"></p>
</div>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="batch-processing-llm-applications" class="title-slide slide level1 center">
<h1>2. Batch Processing <em>LLM</em> Applications</h1>

</section>
<section id="section-2" class="slide level2">
<h2>Section 2</h2>
<h3 id="batch-processing-llm-applications-1">Batch Processing <em>LLM</em> Applications</h3>
<ul>
<li class="fragment">A Text Classification Application
<ul>
<li class="fragment">with 1 LLM API call per datapoint</li>
</ul></li>
<li class="fragment">A Chained LLM Application</li>
</ul>
</section>
<section id="a-typical-batch-processing-llm-application" class="slide level2">
<h2>A Typical Batch Processing LLM Application</h2>

<img src="images/prompt_templatizing.png" alt="" width="300" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">Context or instructions can be dynamically adjusted via prompt templating</li>
<li class="fragment">External context can be modularized to avoid long, hard-coded prompts</li>
<li class="fragment">All data in the same batch use the same prompt template</li>
</ul>
</div>
</section>
<section id="a-text-classification-application" class="slide level2">
<h2>A Text Classification Application</h2>

<img src="images/batchjob_app_text_cat.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">Processes multiple data items (e.g., documents) using the same LLM pipeline.</li>
<li class="fragment">Scales LLM use to bulk operations like NER tagging or classification.</li>
</ul>
</div>
</section>
<section id="a-chained-llm-application-12" class="slide level2">
<h2>A Chained LLM Application (1/2)</h2>

<img src="images/batchjob_app_text_cat_2.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">Uses chained prompts where the output of one LLM call feeds into another.</li>
<li class="fragment">Demonstrates how logic can be split into reusable, modular steps.</li>
</ul>
</div>
</section>
<section id="a-chained-llm-application-22" class="slide level2">
<h2>A Chained LLM Application (2/2)</h2>
<p><img src="images/llm_chaining_1.png" alt="" style="width: 40%;"></p>
<p><br></p>
<p><img src="images/llm_chaining_2.png" alt="" style="width: 70%;"></p>
</section>
<section id="detour-section--" class="slide level2">
<h2>Detour Section -</h2>
<h3 id="the-evolution-of-reasoning-in-llms">The Evolution of Reasoning in LLMs</h3>
<ul>
<li class="fragment">Prompt Engineering Approaches - In Focus - CoT and ReAct</li>
<li class="fragment">Large Reasoning Models &lt;– Are there any takers?</li>
</ul>
</section>
<section id="how-prompt-engineering-started" class="slide level2">
<h2>How Prompt Engineering Started</h2>

<img src="images/prompt_engg_1.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">As the context window of LLMs improved,
<ul>
<li class="fragment">Input-Output Prompting evolved into Few Shot Prompting for better results</li>
</ul></li>
</ul>
</div>
</section>
<section id="reasoning-prompts---cot-react-prompts-in-few-shot-style" class="slide level2">
<h2>Reasoning Prompts - CoT &amp; ReAct Prompts in Few Shot Style</h2>

<img src="images/prompt_engg_2.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">Explaining LLMs to think/reason step by step with examples</li>
</ul>
</div>
</section>
<section id="reasoning-prompts---cot-react-techniques-during-inference" class="slide level2">
<h2>Reasoning Prompts - CoT &amp; ReAct Techniques During Inference</h2>

<img src="images/prompt_engg_3.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.8em;">
<ul>
<li class="fragment">Explaining LLMs to think/reason step by step with examples</li>
</ul>
</div>
</section>
<section id="structured-function-calling---a-robust-alternative-to-react" class="slide level2">
<h2>Structured Function Calling - A Robust Alternative to ReAct</h2>

<img src="images/structured_func_call_new.png" alt="" width="600" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li>The structured JSON that LLM generates</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb1-1"><a></a><span class="fu">{</span></span>
<span id="cb1-2"><a></a>  <span class="dt">"function"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-3"><a></a>    <span class="dt">"name"</span><span class="fu">:</span> <span class="st">"search_web"</span></span>
<span id="cb1-4"><a></a>    <span class="fu">},</span></span>
<span id="cb1-5"><a></a>  <span class="dt">"parameters"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb1-6"><a></a>    <span class="dt">"query"</span><span class="fu">:</span> <span class="st">"capital of Japan"</span></span>
<span id="cb1-7"><a></a>  <span class="fu">}</span></span>
<span id="cb1-8"><a></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="structured-function-calling---openai-example" class="slide level2">
<h2>Structured Function Calling - OpenAI Example</h2>
<div style="font-size: 0.5em;">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="co">#0. Implement the tool</span></span>
<span id="cb2-2"><a></a></span>
<span id="cb2-3"><a></a><span class="kw">def</span> search_web(search_query)</span>
<span id="cb2-4"><a></a>  ...</span>
<span id="cb2-5"><a></a>  ...</span>
<span id="cb2-6"><a></a>  <span class="cf">return</span> tool_answer</span>
<span id="cb2-7"><a></a></span>
<span id="cb2-8"><a></a><span class="co"># 1. Describe the tool</span></span>
<span id="cb2-9"><a></a>tools <span class="op">=</span> [</span>
<span id="cb2-10"><a></a>    {</span>
<span id="cb2-11"><a></a>        <span class="st">"type"</span>: <span class="st">"function"</span>,</span>
<span id="cb2-12"><a></a>        <span class="st">"function"</span>: {</span>
<span id="cb2-13"><a></a>            <span class="st">"name"</span>: <span class="st">"search_web"</span>,</span>
<span id="cb2-14"><a></a>            <span class="st">"description"</span>: <span class="st">"Searches the web for a factual answer to a question."</span>,</span>
<span id="cb2-15"><a></a>            <span class="st">"parameters"</span>: {</span>
<span id="cb2-16"><a></a>                <span class="st">"type"</span>: <span class="st">"object"</span>,</span>
<span id="cb2-17"><a></a>                <span class="st">"properties"</span>: {</span>
<span id="cb2-18"><a></a>                    <span class="st">"query"</span>: {</span>
<span id="cb2-19"><a></a>                        <span class="st">"type"</span>: <span class="st">"string"</span>,</span>
<span id="cb2-20"><a></a>                        <span class="st">"description"</span>: <span class="st">"The question or term to search for"</span></span>
<span id="cb2-21"><a></a>                    }</span>
<span id="cb2-22"><a></a>                },</span>
<span id="cb2-23"><a></a>                <span class="st">"required"</span>: [<span class="st">"query"</span>]</span>
<span id="cb2-24"><a></a>            }</span>
<span id="cb2-25"><a></a>        }</span>
<span id="cb2-26"><a></a>    }</span>
<span id="cb2-27"><a></a>]</span>
<span id="cb2-28"><a></a></span>
<span id="cb2-29"><a></a><span class="co"># Step 2: Pass the prompt query to the OpenAI</span></span>
<span id="cb2-30"><a></a><span class="co"># Let OpenAI decide if it wants to use the tool</span></span>
<span id="cb2-31"><a></a>messages <span class="op">=</span> [</span>
<span id="cb2-32"><a></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"What is the capital of Japan?"</span>}</span>
<span id="cb2-33"><a></a>]</span>
<span id="cb2-34"><a></a></span>
<span id="cb2-35"><a></a></span>
<span id="cb2-36"><a></a>response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb2-37"><a></a>    model<span class="op">=</span><span class="st">"gpt4o"</span>, </span>
<span id="cb2-38"><a></a>    messages<span class="op">=</span>messages,</span>
<span id="cb2-39"><a></a>    tools<span class="op">=</span>tools,</span>
<span id="cb2-40"><a></a>    tool_choice<span class="op">=</span><span class="st">"auto"</span></span>
<span id="cb2-41"><a></a>)</span>
<span id="cb2-42"><a></a></span>
<span id="cb2-43"><a></a><span class="co"># Step 3: Execute the Tool Call</span></span>
<span id="cb2-44"><a></a>tool_call <span class="op">=</span> response.choices[<span class="dv">0</span>].message.get(<span class="st">"tool_calls"</span>, [<span class="va">None</span>])[<span class="dv">0</span>]</span>
<span id="cb2-45"><a></a></span>
<span id="cb2-46"><a></a><span class="cf">if</span> tool_call:</span>
<span id="cb2-47"><a></a>    function_name <span class="op">=</span> tool_call.function.name</span>
<span id="cb2-48"><a></a>    arguments <span class="op">=</span> <span class="bu">eval</span>(tool_call.function.arguments)  <span class="co"># or use `json.loads`</span></span>
<span id="cb2-49"><a></a></span>
<span id="cb2-50"><a></a>    <span class="co"># Step 4: Simulate calling the function (you’d implement it)</span></span>
<span id="cb2-51"><a></a>    <span class="cf">if</span> function_name <span class="op">==</span> <span class="st">"search_web"</span>:</span>
<span id="cb2-52"><a></a>        query <span class="op">=</span> arguments[<span class="st">"query"</span>]</span>
<span id="cb2-53"><a></a>        tool_result <span class="op">=</span> search_web(query)</span>
<span id="cb2-54"><a></a></span>
<span id="cb2-55"><a></a>        <span class="co"># Step 5: Append tool response and ask model to finish</span></span>
<span id="cb2-56"><a></a>        messages <span class="op">+=</span> [</span>
<span id="cb2-57"><a></a>            response.choices[<span class="dv">0</span>].message,</span>
<span id="cb2-58"><a></a>            {</span>
<span id="cb2-59"><a></a>                <span class="st">"role"</span>: <span class="st">"tool"</span>,</span>
<span id="cb2-60"><a></a>                <span class="st">"tool_call_id"</span>: tool_call.<span class="bu">id</span>,</span>
<span id="cb2-61"><a></a>                <span class="st">"name"</span>: function_name,</span>
<span id="cb2-62"><a></a>                <span class="st">"content"</span>: tool_result</span>
<span id="cb2-63"><a></a>            }</span>
<span id="cb2-64"><a></a>        ]</span>
<span id="cb2-65"><a></a></span>
<span id="cb2-66"><a></a>        final_response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb2-67"><a></a>            model<span class="op">=</span><span class="st">"gpt4o"</span>,</span>
<span id="cb2-68"><a></a>            messages<span class="op">=</span>messages</span>
<span id="cb2-69"><a></a>        )</span>
<span id="cb2-70"><a></a></span>
<span id="cb2-71"><a></a>        <span class="bu">print</span>(<span class="st">"🧠 Final Answer:"</span>, final_response.choices[<span class="dv">0</span>].message[<span class="st">"content"</span>])</span>
<span id="cb2-72"><a></a><span class="cf">else</span>:</span>
<span id="cb2-73"><a></a>    <span class="bu">print</span>(<span class="st">"💬 Direct Answer:"</span>, response.choices[<span class="dv">0</span>].message[<span class="st">"content"</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="react-vs-structured-function-calling" class="slide level2">
<h2>ReAct vs Structured Function Calling</h2>
<div style="font-size: 0.5em;">
<table class="caption-top">
<colgroup>
<col style="width: 19%">
<col style="width: 38%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>ReAct (Prompt Text)</th>
<th>Function Calling (Structured JSON)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Output Format</td>
<td><code>"Action: Search('capital of Japan')"</code></td>
<td>Structured JSON with function + args</td>
</tr>
<tr class="even">
<td>Parsing Required?</td>
<td>❌ You parse the text manually</td>
<td>✅ Handled by OpenAI, LangChain toolkit</td>
</tr>
<tr class="odd">
<td>Execution Clarity</td>
<td>❌ Model can hallucinate tool syntax</td>
<td>✅ Only valid, defined tools used</td>
</tr>
<tr class="even">
<td>Model Adherence</td>
<td>🟡 You “hope” it follows format</td>
<td>🎯 You give it tool schema (e.g.: OpenAPI)</td>
</tr>
<tr class="odd">
<td>Robustness for Development</td>
<td>❌ Fragile</td>
<td>✅ Very reliable and scalable</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="large-reasoning-models" class="slide level2">
<h2>Large Reasoning Models</h2>

<img src="images/LLMs_vs_LRMs.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">LLMs: input → LLM → output statement</li>
<li class="fragment">LRMs: input → LRM → Keeps Planning Steps → Finally, output statement <br></li>
<li class="fragment">LRMs are generating text similar LLMs but they are trained to “think before acting”</li>
<li class="fragment">E.g.: OpenAI o1, DeepSeek R1</li>
<li class="fragment">LRMs think during inference, hence needing more “test-time compute”</li>
</ul>
<p><a href="https://thenuancedperspective.substack.com/p/day-6-planning-in-agents-reasoning">Source 1: Aishwarya Naresh’s Substack</a> <br> <a href="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms">Source 2: A Visual Guide to Reasoning LLMs</a></p>
</div>
</section>
<section id="recap" class="slide level2">
<h2>Recap</h2>
<div style="font-size: 0.8em;">
<ul>
<li class="fragment">We have discussed the following so far:
<ul>
<li class="fragment">How LLMs are used in streaming and batch application</li>
<li class="fragment">How LLMs work with Tools and RAG setup</li>
<li class="fragment">How LLMs think (planning/reasoning/reflection,etc.,)</li>
<li class="fragment">In Agentic AI, we put the above concepts together</li>
</ul></li>
</ul>
</div>
</section>
<section id="section-3--" class="slide level2">
<h2>Section 3 -</h2>
<h3 id="agentic-ai-applications">Agentic AI Applications</h3>
<div style="font-size: 0.8em;">
<ul>
<li class="fragment">Components that comprise an Agent</li>
<li class="fragment">Architecture of a Single Agent</li>
<li class="fragment">What do these protocols - MCP and Google’s A2A - mean?</li>
<li class="fragment">Real World Agents - ChatGPT vs Perplexity vs DeepResearch</li>
<li class="fragment">What are Multi-Agent Systems</li>
<li class="fragment">What do the Experts say?</li>
</ul>
</div>
</section>
<section id="what-are-agents" class="slide level2">
<h2>What are Agents?</h2>
<div style="font-size: 0.8em;">
<ul>
<li class="fragment">LLMs generate text</li>
<li class="fragment">Agents generate text and also <strong>perform actions</strong></li>
<li class="fragment">Chatbot = LLM + Memory</li>
<li class="fragment">RAG Chatbot = LLM + Memory + Vectorized(Source Docs)</li>
<li class="fragment">Tool LLMs = LLM (brain) + Function Calling (hands)</li>
<li class="fragment">Agent = LLM + Tools + Memory + Planning (next steps, state management)</li>
<li class="fragment">Agent = Engineering Wrappers around LLMs</li>
</ul>
</div>
<p><br></p>
<div style="font-size: 0.3em;">
<p>Source for the perspective - “Engineering Wrappers around LLMs”:<br><a href="https://thenuancedperspective.substack.com/p/day-1-what-are-agents-anyway">Aishwarya Naresh in Substack</a></p>
</div>
</section>
<section id="architecture-of-a-single-agent" class="slide level2">
<h2>Architecture of a Single Agent</h2>

<img src="images/single_agent_mermaid.png" alt="" width="300" class="r-stretch"></section>
<section id="example-of-a-single-agent-application" class="slide level2">
<h2>Example of a Single Agent Application</h2>

<img src="images/single_agent_example.png" alt="" width="300" class="r-stretch"></section>
<section id="agentic-rag" class="slide level2">
<h2>Agentic RAG</h2>

<img src="images/agentic_rag.png" alt="" width="300" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">Agentic RAG is not one-shot retrieval.</li>
<li class="fragment">The Agent retrieves, then reflects on the result, re-fetches if necessary</li>
</ul>
</div>
</section>
<section id="where-does-mcp-fit-here" class="slide level2">
<h2>Where does MCP fit here?</h2>
<p><strong>Before MCP</strong>:</p>
<p><img src="images/mcp_2.png" alt="" width="300"></p>
<p><strong>After MCP</strong>:</p>
<p><img src="images/mcp_1.png" alt="" width="300"></p>
<div style="font-size: 0.3em;">
<p>Source of the amazing images: <a href="https://norahsakal.com/blog/mcp-vs-api-model-context-protocol-explained/">Norah Sakal Blog Post</a></p>
</div>
</section>
<section id="where-does-mcp-fit-here-1" class="slide level2">
<h2>Where does MCP fit here?</h2>

<img src="images/mcp_sequence_diagram.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">MCP - Not just a package or library (well it has a python package!).</li>
<li class="fragment">It is a protocol like TCP/SMTP. It is like OpenAPI Spec for REST APIs. <a href="https://gyliu513.medium.com/mcp-the-openapi-for-ai-agents-725588f2b0d3">source of the analogy</a></li>
<li class="fragment">MCP standardizes how the context (prompt, tools, memory, retrieved docs, etc.,) get passed on to the Model.</li>
</ul>
</div>
<div style="font-size: 0.3em;">
<p>Source of the amazing image: <a href="https://blog.stackademic.com/mcp-model-context-protocol-simplified-976b46f01efd">Hirusha Fernando Medium Article</a></p>
</div>
</section>
<section id="real-world-agents---chatgpt-vs-perplexity-vs-openai-deepresearch" class="slide level2">
<h2>Real World Agents - ChatGPT vs Perplexity vs OpenAI DeepResearch</h2>
<div style="font-size: 0.8em;">
<ul>
<li class="fragment">ChatGPT: General Purpose Conversational AI whose knowledge is limited to the time of training data</li>
<li class="fragment">Perplexity: Google (Search Engine) + ChatGPT (Conversational AI)
<ul>
<li class="fragment">Generates text as an answer with sources for every portion</li>
</ul></li>
<li class="fragment">Deep Research: An Agentic RAG with WebSearch (&amp; other tools) and Multi-step reasoning <a href="https://thenuancedperspective.substack.com/p/day-9-real-world-agentic-systems">source</a></li>
</ul>
</div>
</section>
<section id="multi-agent-systems" class="slide level2">
<h2>Multi-Agent Systems</h2>

<img src="images/multi_agent_simple_view.png" alt="" width="200" class="r-stretch"><div style="font-size: 0.5em;">
<ul>
<li class="fragment">Agents operate in parallel with their own responsibilities.</li>
<li class="fragment">Shared memory is used for cross-agent communication.</li>
<li class="fragment">Tool usage and autonomy allow scalable, modular problem-solving.</li>
</ul>
</div>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="conclusion" class="title-slide slide level1 center">
<h1>Conclusion</h1>

</section>
<section id="what-the-experts-say-12" class="slide level2">
<h2>What the Experts Say? (1/2)</h2>
<div style="font-size: 0.8em;">
<ul>
<li class="fragment">“Let us build a Multi-Agent System” - ❌ a wrong view to start with
<ul>
<li class="fragment">✅ “What are we trying to solve”</li>
</ul></li>
<li class="fragment">Simpler systems are better:
<ul>
<li class="fragment">RAG LLM Chatbot &gt;&gt; Agentic RAG</li>
<li class="fragment">LLM + Function Calling &gt;&gt; Single Agent</li>
<li class="fragment">Single Agent (with different “modes”) &gt;&gt; Multi Agents</li>
</ul></li>
<li class="fragment">Have caution in using inference-compute-heavy Large Reasoning Models - the jury is still out!</li>
</ul>
</div>
</section>
<section id="what-the-experts-say-22" class="slide level2">
<h2>What the Experts Say? (2/2)</h2>
<div style="font-size: 0.8em;">
<ul>
<li class="fragment">Observability:
<ul>
<li class="fragment">Capability to review logs of LLMs or Agents function is key to success</li>
</ul></li>
<li class="fragment">Latency:
<ul>
<li class="fragment">Complex systems typically come with high Latency</li>
</ul></li>
<li class="fragment">Evaluation:
<ul>
<li class="fragment">Accuracy: Have your test questions clearly prepared and tested!</li>
<li class="fragment">Cost: Have a tab on the token usage.</li>
</ul></li>
</ul>
</div>
</section>
<section id="my-main-resources" class="slide level2">
<h2>My Main Resources</h2>
<div style="font-size: 0.8em;">
<ul>
<li class="fragment">Mermaid Charts drawn from practical experience are collated <a href="https://gist.github.com/senthilkumarm1901/59c83abf23e70d935d25b73ef8bbf44f">here</a></li>
<li class="fragment">Extensive interactions with ChatGPT/ Perplexity for correcting/editing my mermaid charts</li>
<li class="fragment">The 10 Article Substack Piece by Aishwarya Naresh - <a href="https://thenuancedperspective.substack.com/">The Nuanced Perspective</a></li>
<li class="fragment">O’reilly Course on <a href="https://learning.oreilly.com/course/modern-automated-ai/9780135414965/">Modern Automated AI Agents</a></li>
</ul>
</div>
</section>
<section class="slide level2">



</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/senthilkumarm1901\.github\.io\/learn_by_blogging\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    <script src="https://utteranc.es/client.js" repo="senthilkumarm1901/QuartoBlogComments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
    </script>
    

</body></html>