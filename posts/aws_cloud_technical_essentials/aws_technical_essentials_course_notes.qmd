---
author: Senthil Kumar
badges: true
branch: master
categories:
- AWS
description: In this blog, I cover my learnings from the Coursera-AWS course titled AWS Cloud Technical Essentials
date: '2024-10-15'
draft: false
image: images/course_certificate.png
toc: true
title: "What I Learned About AWS Fundamentals from a Coursera Course"
output-file: 2024-10-15-aws-technical-essentials-course-notes.html
---

I’ve pulled together my notes on AWS Fundamentals — covering Security, Compute, Networking, Databases, and more — based on the AWS Technical Essentials course from Coursera.
I’ve also included my ChatGPT interactions, where I explored specific doubts and clarified tricky concepts along the way. This resource should be handy for anyone attempting to revise concepts before an AWS exam

![](images/course_certificate.png)

> Source: All pictures are from the Coursera Course (unless specified otherwise) and are intended only for learning purposes. 

# 1. Introduction to AWS

## 1.  Introduction to AWS - The Critical Elements

- **Regions → AZs → Data Centers**
    
    - AWS Regions consist of **Availability Zones (AZs)**.
    - AZs consist of **one or more physical data centers**.


- **Root account first steps (non‑negotiable)**
    
    1. Enable **MFA** on the root user immediately
    2. Create an **IAM Administrator role**
        - Full service creation permissions
        - No account‑level or billing changes
    3. Lock away root credentials

- **IAM policies cannot restrict the root user**
    
    - Root user always has unrestricted access, regardless of IAM policies.

- **Shared Responsibility Model**
    
    - AWS = **security _of_ the cloud**
    - Customer = **security _in_ the cloud**

- Summary: **Every activity in AWS is an API call**
    
    - Console clicks, CLI commands, SDK calls → all become **authenticated & authorized AWS API requests**.



---


### Choose the Right AWS Region

**Essential takeaway:**  
Choose Region in this order:

1. **Compliance / data residency**
2. **Latency**
3. **Service availability**
4. **Cost**
5. **Availability & DR needs**

![](./images/how_to_choose_aws_region.png)

---

### Availability Zones

![](./images/regioin-az-datacenters.png){width=100%}

- Each **Region contains multiple AZs**
- Each **AZ = one or more data centers**
- Data centers are:
    - Physically separate
    - Redundantly powered and networked
- AZs are connected by **low‑latency, high‑bandwidth links**
- AZ names:
    - `<region><letter>` (example: `us-east-1a`)
    - Letter mappings differ per account
- Resource location example:
    - `us-east-1c` → AZ “c” inside `us-east-1`

---

### Scope of AWS Services

![](./images/aws_scope_and_responsibility_of_services_2.png)

**Scope summary:**

- **Global services**

    - Single logical control plane across AWS
    - Example: IAM, Route 53, CloudFront
- **Regional services**
    
    - Live within a Region, usually span multiple AZs
    - Example: S3, DynamoDB, VPC, RDS Multi‑AZ
- **Zonal services**
    
    - Bound to a single AZ
    - Example: EC2, EBS, RDS Single‑AZ

**Availability & durability:**

- Some services are **AWS‑managed**
- Others require **customer‑designed HA/DR**

---

### Maintain Resiliency

- Prefer **Region‑scoped managed services**
- Otherwise:
    - Deploy across **multiple AZs**
    - Minimum **two AZs**
- AZ failure ≠ application outage when designed correctly

---

### Security and the AWS Shared Responsibility Model

#### Core distinction

- **AWS responsibility (security of the cloud):**
    
    - Physical data centers
    - Hardware, networking
    - Host OS and virtualization layer
- **Customer responsibility (security in the cloud):**
    
    - IAM, access control
    - Data protection & encryption
    - Network security (SGs, NACLs)
    - Backups and recovery

> AWS manages the infrastructure.  
> You secure what you build on top of it.

---

## Protect the AWS Root User

### Authentication vs Authorization

- **Authentication:**  
    “Who are you?” (passwords, MFA, tokens)
    
- **Authorization:**  
    “What are you allowed to do?” (IAM policies)
    

---

### AWS Root User

- Created with the AWS account
- Has **full, unrestricted access**
- Credentials:
    - Email + password (console)
    - Access keys (programmatic)

**Critical facts:**

- IAM policies **cannot limit root**
- Root should never be used for daily work

---

### Root User Best Practices

- Enable **MFA**
- Strong, unique password
- **Delete root access keys**
- Use root **only** for:
    - Account setup
    - Billing
    - Rare account‑level tasks

---

### Why MFA Matters

- Passwords alone are weak
- MFA adds a second factor:
    - Something you know
    - Something you have
    - Something you are
- **Always enable MFA on root**

---

## Control Plane APIs and Data Plane APIs in AWS

* AWS describes control plane as administrative APIs (CRUDL) like “creating an S3 bucket”, while data plane includes “getting and putting objects in an S3 bucket

- Source: [Control Planes and Data Planes in AWS](https://docs.aws.amazon.com/whitepapers/latest/aws-fault-isolation-boundaries/control-planes-and-data-planes.html)

S3 **Control plane** APIs (AWS CLI examples)

✅ Create a bucket (control plane)

```bash
aws s3api create-bucket \
  --bucket my-example-bucket-123 \
  --region ap-south-1 \
  --create-bucket-configuration LocationConstraint=ap-south-1
```

`create-bucket` “Creates a new S3 bucket.”

> * Rule of thumb: Anything *Bucket* (create bucket, put bucket encryption, put bucket policy, lifecycle, versioning…) is typically “control plane” style because you’re configuring the container and its behavior.

```bash
aws s3api delete-object \
  --bucket my-example-bucket-123 \
  --key docs/readme.txt
```

> * Rule of thumb: Anything *Object* (PutObject/GetObject/ListObjects/DeleteObject/HeadObject) is “data plane” because you’re interacting with the stored data.

---

## Summary: Every AWS Activity Is an API Call

![](./images/every_aws_service_use_is_an_api_call.png)

- Console, CLI, SDK → **AWS API**
- API calls are:
    - Authenticated
    - Authorized
    - Evaluated by IAM
- Understanding this explains:
    - IAM behavior
    - Auditing (CloudTrail)
    - Automation (IaC, CI/CD)
    - Security boundaries

> **By understanding APIs, IAM, Regions, AZs, and responsibility boundaries — one understands AWS.**



---

# 2. Security 

![](./images/aws_iam_user_role_groups_policies.jpg)
Source: AWS Builder


Below is a **bare‑minimum, distilled version** of your AWS Security notes — keeping only the concepts that actually matter long‑term and removing all repetition and teaching detail.

***

## AWS Security - Quick Notes

### 1. AWS Identity and Access Management (IAM)

*   **IAM controls authentication and authorization** for AWS accounts and resources.
*   Lets you **share access without using root credentials**.
*   Provides **fine‑grained, explicit permissions**.
*   **IAM is global** (not Region‑specific).
*   Supports **MFA, password policies, and identity federation**.
*   IAM itself is **free**.

***

### 2. IAM Identities

*   **IAM User**
    *   Represents a person or service.
    *   Has permanent credentials (console and/or programmatic).
    *   Should **not share credentials**.

*   **IAM Group**
    *   Collection of users.
    *   Permissions are assigned **to groups, not individuals**.
    *   Users can belong to multiple groups.

*   **IAM Role**
    *   No long‑term credentials.
    *   Uses **temporary credentials**.
    *   Preferred for:
        *   AWS services
        *   Federated users
        *   Cross‑account access

***

### 3. IAM Policies

*   **Policies define permissions** (allow/deny).
*   Attached to **users, groups, or roles**.
*   Evaluated on **every AWS API call**.
*   Core elements:
    *   `Effect` (Allow / Deny)
    *   `Action`
    *   `Resource`
*   `*` on action and resource = **full access**.
*   **Explicit deny always wins**.

***

### 4. Security Best Practices

*   **Lock down the root user**
    *   Enable MFA
    *   Delete root access keys
    *   Never use root for daily work

*   **Least privilege**
    *   Start with minimal access
    *   Grant only what is required

*   **Prefer roles over users**
    *   Avoid long‑lived access keys
    *   Reduce blast radius of credential leaks

***

### 5. Federation & Centralized Identity

*   Use an **Identity Provider (IdP)** when possible.
*   Grant access via **IAM roles**, not IAM users.
*   **AWS IAM Identity Center (SSO)**:
    *   Central user & permission management
    *   Works across multiple AWS accounts
    *   Integrates with external IdPs

***

### One‑Line Mental Model

> **IAM decides *who* can call *which AWS APIs* on *which resources*.**

## Deep Dive into IAM Policy

- **IAM policies** manage access and permissions to AWS services/resources.  
- Policies can be attached to **users, groups, or roles**.  
- When a request is made, AWS evaluates:  
  - Policies on the **user/role**  
  - Policies on any **groups** the user belongs to  
- Example: A developer in the **developers group** → AWS checks both the **group policies** and the **user’s policies** to decide allow/deny.  


### IAM POLICY EXAMPLES

Most policies are stored in AWS as JSON documents with several policy elements. Take a look at the following example of what providing admin access through an IAM identity-based policy looks like.

```json
{

"Version": "2012-10-17",    
     "Statement": [{        
          "Effect": "Allow",        
          "Action": "*",        
          "Resource": "*"     
     }]
}
```

- An **IAM policy** has four key JSON elements:  

  1. **Version** → defines the policy language version.  
     - Always use `"Version": "2012-10-17"` for full feature support.  
  2. **Effect** → specifies whether to **Allow** or **Deny** access.  
  3. **Action** → describes the allowed/denied actions.  
     - `"*"` = wildcard → all actions.  
  4. **Resource** → defines which resources are affected.  
     - `"*"` = all resources.  

- Example: Policy with `"Action": "*"` and `"Resource": "*"` → grants **administrator access** (all actions on all resources).  

```json
{"Version": "2012-10-17",    
     "Statement": [{        
          "Effect": "Allow",        
          "Action": [            
               "iam: ChangePassword",            
               "iam: GetUser"            
               ],        
          "Resource": "arn:aws:iam::123456789012:user/${aws:username}"    
     }]
}
```

- More granular example:  
  - Allows a user to:  
    - `iam:ChangePassword` (change their own password)  
    - `iam:GetUser` (get info about their own user)  
  - Uses **variable substitution** `${aws:username}` → limits permissions to the **specific user** only.  

### UNDERSTAND POLICY STRUCTURE

When creating a policy, it is required to have each of the following elements inside a policy statement.

![](./images/iam_policy_3_essential_elements.png)


### Summarizing Security

![](./images/security_summary.png)

---

#### Different types of AWS IAM Users 

- Even a CICD System can be an IAM User (with specific permissions)

![](./images/iam_user_differences.png)
Source: AWS Blg

#### The concept of Groups and Roles 

- One user could be in multiple groups

![](./images/different_groups_different_permissions.png)
---

#### How to enables employees access AWS Account (via IdP)

![](./images/how_to_access_aws_account_via_IDP.png)

---

#### How to enable customers access to Application deployed in AWS Account

![](./images/how_to_enable_acesss_to_apps_in_aws_account_2.png)

| Feature                | AWS IAM Identity Center | AWS Cognito                 |
| ---------------------- | ------------------- | ----------------------- |
| Used by                | Employees           | App users               |
| Purpose                | Access AWS accounts | Access your application |
| Grants console access? | Yes                 | No                      |
| Grants CLI access?     | Yes                 | No                      |
| Issues AWS creds?      | Yes                 | Yes (via Identity Pool) |
| Scope                  | Organization-wide   | Application-level       |


---

### Week 1's Quiz: 

[A GitHub Source for Week 1 Quiz](https://github.com/salimt/Courses-/blob/master/AWS%20Cloud%20Solutions%20Architect%20Professional/c01-%20AWS%20Cloud%20Technical%20Essentials/w1-%20Amazon%20Web%20Services%20(AWS)/Week%201%20Quiz%20_%20Coursera.pdf)

---



# 3. Compute as a Service

## 3.1 Introduction to Compute Options in AWS

### Understanding Servers

- A **server** processes requests from clients and returns responses.
- Servers provide **CPU, memory, and networking** for applications.
- Most applications serve **HTTP/API requests** (web servers like IIS, Apache, Nginx).
- In AWS, you choose a **compute service** to run these servers.

---

### Choose the Right Compute Option

AWS compute falls into **three categories**:

- **Virtual Machines**
- **Containers**
- **Serverless**

**Virtual Machines (VMs)**

- Closest to traditional servers
- Full OS control
- Run on a **hypervisor**

**Amazon EC2**

- AWS VM service
- AWS manages hardware + hypervisor
- You manage OS and applications

**Hypervisor**

- Enables multiple OSs on one physical machine
- Provides isolation, scalability, and flexibility

---

## 3.2 Amazon Elastic Compute Cloud (EC2)

- EC2 provides **resizable virtual servers** called instances
- Instances are created via Console, CLI, SDK, or automation
- You define:
    - Hardware (CPU, memory, storage, networking)
    - OS, security, networking, access

### Amazon Machine Image (AMI)

- Template used to launch EC2 instances
- Contains:
    - OS
    - Architecture
    - Storage mappings
    - Optional software


![](./images/ami_ec2_rootvolume.png)

**AMI vs EC2**

- AMI = template / recipe
- EC2 instance = running server / instantiation of the recipe
- Equivalent to **Class vs Object**

**AMI Reuse**

- Create once, launch many identical instances
- Avoids manual reconfiguration and errors

![](./images/create_ami_from_running_instance.png)

---

### Where Can You Find AMIs?

- AWS Quick Start AMIs
- AWS Marketplace
- My AMIs
- Community AMIs
- EC2 Image Builder

---

## 3.3 Types of EC2 Instances

```{mermaid}
flowchart TD
  EC2((EC2 Family)) 
  E1(Gen Purpose)
  E2(Compute Optimized)
  E3(Storage Optimized)
  E4(Memory/RAM Optimized)
  E5(Accelerated Computing)

  U1[Web Servers]   
  U2[ML/DL in High power CPU]   
  U3[MongoDB/NoSQL DBs]
  U4[Capable of processing<br>large workloads<br>in memory]
  U5[Workloads<br>needing GPUs]

  EC2 --> E1
  EC2 --> E2
  EC2 --> E3
  EC2 --> E4
  EC2 --> E5

  E1 --> U1
  E2 --> U2
  E3 --> U3
  E4 --> U4
  E5 --> U5
```

---

## 3.3 Container Services on AWS

- Containers package **code + dependencies**
- Portable across environments (dev → prod → cloud)
- Solve “works on my machine” problems

### Docker

- Most common container runtime
- Simplifies container build and execution

![](./images/containers_and_virtual_machines.png)

**Containers vs VMs**

- Containers share host OS → lightweight, fast startup
- VMs include full OS → heavier, more isolation

---

### Orchestrate Containers

At scale, you need orchestration to handle:

- Placement
- Failures
- Scaling
- Monitoring

AWS orchestration services:

- **Amazon ECS**
- **Amazon EKS**

---

## Amazon Elastic Container Service (ECS)

- AWS‑native container orchestration
- Runs containers on EC2 or **AWS Fargate**

![](./images/one_ec2_multiple_containers.png)



### ECS Agent

- Installed on EC2 instances
- EC2 + agent = **container instance**



![](./images/ecs_agent_to_orchestrate_containers.png)

### Task Definition

- JSON blueprint describing containers and resources

```json
{

  "family": "webserver",
  "containerDefinitions": [
    {

      "name": "web",
      "image": "nginx",
      "memory": "100",
      "cpu": "99"
    }

  ],

  "requiresCompatibilities": ["FARGATE"],
  "networkMode": "awsvpc",
  "memory": "512",
  "cpu": "256"
}
```

---

### ECS Summary

- AWS‑native orchestration
- No Kubernetes
- Containers = **tasks**
- Can run on EC2 or Fargate

---

## Amazon Elastic Kubernetes Service (EKS)

- Managed **Kubernetes** on AWS
- AWS manages control plane
- EC2 instances = **worker nodes**
- Containers run inside **pods**

---

### ECS vs EKS Terminology


| ECS                                                                                                                                                | EKS                                                                                                                                                                                                   |
| -------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| EC2 Instances where containers are run `EC2 Container Instances`                                                                                   | EC2 Instances where containers run `Worker Nodes`                                                                                                                                                     |
| A `task` refers to a set of one or more containers that are scheduled together                                                                     | A `pod` - the smallest deployable unit and equivalent of `task` in ECS - consists of one or more containers that share resources                                                                      |
| Summary: In ECS, the EC2 instances where containers run are called container instances because they have the ECS agent installed to manage `tasks` | Summary: In EKS (Kubernetes), the EC2 instances are called worker nodes, and they are part of the broader Kubernetes cluster. Kubernetes distributes containers (in the form of pods) to these nodes. |

![](./images/a_EKS_worker_node.png)

|ECS|EKS|
|---|---|
|Container Instance|Worker Node|
|Task|Pod|
|AWS-native|Kubernetes|

---

## 3.4 Serverless and AWS Lambda

### Remove Undifferentiated Heavy Lifting

- EC2 → you manage OS, patching, scaling
- Containers → AWS helps, but EC2 still exists
- **Serverless → no servers to manage**

### Serverless Characteristics

- No infrastructure management
- Auto scaling
- Pay per use
- Built‑in availability

---

## AWS Fargate

- Serverless compute for containers
- Works with ECS and EKS
- No EC2 management
- Native IAM and VPC integration

---

## AWS Lambda

- Run code without servers or containers
- Event‑driven execution
- Automatic scaling
- Millisecond‑level billing

### Lambda Function Structure

```python
def handler_name(event, context): 

  ...

  return some_value
```


- **Handler** = entry point
- **Trigger** = when it runs
- **Configuration** = memory, timeout, IAM, networking

### Billing

- Charged per request
- Charged per execution time (ms)
- No cost when idle

---

## 3.5 Notes from `Computing` Quiz

- EC2 = Virtual Machines
- Multiple containers can run on one EC2
- Instance type = family + generation + size
	- EC2 Instance type indicate the following: `instance family` and `instance size`. E.g.: `c5.large` –> c - compute optimized, c5 - 5th generation, large - indicates instance size
> AMI = template for EC2

- AWS Fargate vs AWS EC2 in ECS: For Fargate, AWS manages the provision, configuration and scale of the clusters. For `EC2 in ECS`, user manages the provisioning, configuration and scale of EC2 instance cluster
- Serverless services do not require VPC. But can be included in a VPC of your own account.

- ECS + EC2 → user manages instances
- ECS + Fargate → AWS manages infrastructure
- Serverless does not require VPC but can run inside one

---

# 4 Networking on AWS

Here is a **bare‑minimum, essentials‑only rewrite** of that Networking section.  
I’ve **removed all analogy storytelling**, kept only the **concepts you need to remember**, and preserved the **technical accuracy**.

***

## Introduction to Networking in AWS

### What Is Networking?

> **Networking is the routing of data between uniquely identified endpoints using IP addresses across a global network.**

*   **Networking** enables computers to communicate with each other.
*   In AWS, networking spans **Regions, Availability Zones, and data centers**.
*   AWS operates a **global network** connecting these resources.

***

### Networking Basics

*   Communication requires:
    *   **Source**
    *   **Destination**
    *   **Data (payload)**
*   Messages are delivered using **routing**, which determines the path to the destination.

***

### IP Addresses

*   An **IP address** uniquely identifies a computer on a network.
*   Computers use **binary addresses (0s and 1s)** for routing.
*   **IPv4 addresses are 32‑bit** values.

***

### IPv4 Notation

*   IPv4 is written in **decimal format** for readability.
*   The 32 bits are split into **4 groups of 8 bits (octets)**.
*   Each octet is converted to a decimal number and separated by dots
    *   Example format: `x.x.x.x`

***

## IPv4 → CIDR (why you need ranges)

![](./images/ipv4_notation.png)

- **IPv4** identifies a single host (32 bits → dotted decimal `x.x.x.x`).
- Networks need **ranges**, not single IPs → use **CIDR**.

### CIDR Notation (range)

- Format: `STARTING_IP/NUMBER_OF_FIXED_BITS`
    - Example: `192.168.1.0/24` → first 24 bits fixed → **256 IPs** (2⁸).
- In AWS:
    - Smallest VPC/subnet range: **/28 = 16 IPs**
    - Largest VPC range: **/16 = 65,536 IPs**
- AWS reserves **5 IPs per subnet**, so small subnets lose usable space fast.

---

## AWS VPC (what you must choose)

![](./images/vpc_azs_region.png)

**VPC requires:**

1. **Name**
2. **Region** (VPC spans multiple AZs in that region)
3. **CIDR range** (VPC size; up to **four /16 ranges** per VPC)

---

## Subnets (how you place resources)

![](./images/VPC-split-by-subnet.png)

- **Subnet = smaller CIDR block inside a VPC**, tied to **one AZ**.
- Subnet CIDR must be a **subset** of VPC CIDR.
- EC2 instances are launched **inside subnets** (therefore in a specific AZ).
- For **high availability**, create **at least two subnets in two AZs**.

### Reserved IPs in every subnet

![](./images/5_reserved_ip_addresses.png)

- AWS reserves **5 IP addresses per subnet** for routing/DNS/management.  
    → Plan subnet sizes with this overhead in mind.

---

## Public vs Private subnets (core pattern)

![](./images/public_and_private_subnetets_inside_vpc.png)

- **Public subnet**: has a route to an **Internet Gateway (IGW)**.
- **Private subnet**: no direct IGW route; inbound from internet is blocked by design.
- Common architecture:
    - **Public**: Load balancer
    - **Private**: app servers + databases
    - **NAT Gateway**: private subnet outbound internet access (updates, external APIs)

---

## Gateways (what they do)

- **Internet Gateway (IGW)**
    
    - Enables internet connectivity for the VPC (must be **attached** to the VPC).
- **Virtual Private Gateway (VGW)**
    
    - Connects VPC to another private network via **encrypted VPN** (with Customer Gateway on the other side).
- **NAT Gateway**
    
    - Allows **outbound-only** internet from **private subnets** by translating private IP → public IP.
    - **Stateful return traffic** is allowed only for connections initiated from inside.

---

## VPC Routing & Security (the essential controls)

### Main Route Table

![]("./images/main_route_table_(of_a_vpc.png)")

- Default route table created with the VPC.
- Contains routes (Destination → Target).
- Default behavior: allows **VPC-local traffic** between subnets.

### Custom Route Tables

![](./images/custom_route_tables.png)

- Route tables can be attached to **specific subnets** for custom routing.
- If a subnet has a custom route table, it uses that instead of the main route table.

---

### Network ACLs (subnet-level firewall)

![](./images/network_acl_inbound_and_outbound_rules.png)

- **NACL = stateless** subnet firewall.
- Must allow **both inbound and outbound** explicitly (return traffic isn’t automatic).
- Default vs custom behavior often differs (custom typically starts restrictive).

### Security Groups (instance-level firewall)

![](./images/NACL_vs_sec_group_rules.png)

- **Security Group = stateful** instance firewall.
- Default SG behavior:
    - **Inbound: deny all**
    - **Outbound: allow all**
- For web servers, allow inbound HTTP/HTTPS:

![](./images/inbound_sg_rules_for_http_https.png)

---

## Port 80 vs 443 (only what matters)

![](./images/http_vs_https.png)

- **80 = HTTP** (unencrypted)
- **443 = HTTPS** (encrypted via TLS)

---

## Multi-tier security group isolation (typical 3-tier)

![](./images/networking_sg_rules_for_a_multi_tier_system.png)

- Web tier: allow internet → web over **HTTPS**
- App tier: allow web → app over **HTTP/needed ports**
- DB tier: allow app → DB over **DB port** (e.g., MySQL 3306)
- This isolates tiers without VLANs (security groups enforce isolation).

---

## How private-subnet EC2 reaches the internet

![](./images/how_EC2_in_private_subnet.png)

- Private EC2 → routes outbound traffic to **NAT Gateway** (in a public subnet) → internet.
- No direct inbound internet connectivity to private EC2.

---

## 10 VPC troubleshooting checks (public EC2 web app not loading)

1. **IGW attached to VPC**
2. Subnet route table has `0.0.0.0/0 → igw`
3. **Security Group** allows inbound `80/443` (and outbound allowed)
4. **NACL** allows inbound + outbound for required ports (stateless)
5. Instance has a **public IP** (auto-assign enabled)
6. Using correct **HTTP vs HTTPS**
7. **User data script** ran successfully (`/var/log/cloud-init*`)
8. Instance has correct **IAM role permissions** (S3/DDB/etc.)
9. Your corporate/personal network isn’t blocking access
10. App + web server running; check application logs

---

## Quiz Notes 

- VPC requires **Region**, contains **AZs** and **subnets**
- Route tables attach to **VPC (main)** and **subnets (custom)**
- Public subnet needs **IGW + route** to IGW
- By default, a `security group` blocks all incoming traffic and allows all outgoing traffic. It is stateful (meaning an result of an incoming traffic is allowed automatically)
- NACLs: **stateless** (must allow inbound + outbound). The `default NACL` is associated with all subnets in the VPC by default, allowing all traffic.
- CIDR determines network size: **/16 larger than /28**

[A Github Source for Week 2 Quiz](https://github.com/salimt/Courses-/blob/master/AWS%20Cloud%20Solutions%20Architect%20Professional/c01-%20AWS%20Cloud%20Technical%20Essentials/w2-%20AWS%20Compute%20and%20Networking/Week%202%20Quiz%20_%20Coursera.pdf)

---

# 5. Storage

## 5.1 Storage Types on AWS

3 Different AWS Storage Types:
- block storage
- file storage
- object storage

### 5.1.1 File Storage

- Structure: Data is stored as files in a tree-like hierarchical directory structure (like a traditional file system).

> Each file has metadata such as file name, file size, and the date the file was created. The file also has a path, for example, computer/Application_files/Cat_photos/cats-03.png. When you need to retrieve a file, your system can use the path to find it in the file hierarchy.

> Every additional folder adds latency to the structure

Usecases:
- Large content repositories
- Development environments
- User home directories

### 5.1.2 Block Storage

- While file storage treats files as a singular unit, block storage splits files into fixed-size chunks of data called blocks that have their own addresses. Since each block is addressable, blocks can be retrieved efficiently.

![](./images/block_storage.png)

### 5.1.2 Object Storage

- Very similar to File Storage but no `hierarchical` storage
- Flat structure
- Each object is a file with a unique identifier. This identifier, along with any additional metadata, is bundled with the data and stored.


| File Storage | Object Storge |
|---|---|
|Hierarchy - YES; Folder or tree-like structure | Flat Structure. No hierarchy |
|Good for low-latency read-write | Good for high throughput |
|Edit a portion, you overwrite the whole file | Edit a portion, you overwrite the whole object|
|Amazon EFS | Amazon S3 |


---

## 5.2: Amazon EC2 Instance Store and Amazon Elastic Block Store

### 5.2.1 The two types of EC2 Instance Storage Options
```{mermaid}
flowchart TD
  A[[Temporary<br>Instance Store]]
  B[[Permanent<br>EBS]]
  C(Storage connected<br>to EC2)
  C --> A
  C --> B  
```

### 5.2.2 How many EBS Volumes to every EC2 Instance

**1 EC2 to Many EBS Volumes**:
```{mermaid}
flowchart LR
  EC[EC2]
  EB1[[EBS 1]]
  EB2[[EBS 2]]
  EB3[[EBS 3]]
  EC --> EB1
  EC --> EB2
  EC --> EB3
```

> `In the same AZ`, an EBS can be detached from 1 EC2 and connected to a new EC2 instance

**1 EBS to 1 EC2** (typically):

```{mermaid}
flowchart LR
  EC[EC2] --> EB1[[EBS 1]]
```

**1 EBS volume to Many EC2 Instances** (recently supported for some instances):

```{mermaid}
flowchart LR
  EB1[[EBS 1]]
  ECA[EC2 A]
  ECB[EC2 B]

  EB1 --> ECA
  EB1 --> ECB
```

Additional Points: 

> The external drive is separate from the computer. That means, if an accident happens and the computer goes down, you still have your data on your external drive. The same is true for EBS volumes.

> You’re limited to the size of the external drive, since it has a fixed limit to how scalable it can be. For example, you may have a 2 TB external drive and that means you can only have 2 TB of content on there. This relates to EBS as well, since volumes also have a max limitation of how much content you can store on the volume.

### 5.2.3 How to scale Amazon EBS Volumes

1. Increase the volume size, as long as it doesn’t increase above the maximum size limit. For EBS volumes, the maximum amount of storage you can have is 16 TB. That means if you provision a 5 TB EBS volume, you can choose to increase the size of your volume until you get to 16 TB.

2. Attach multiple volumes to a single Amazon EC2 instance. EC2 has a one-to-many relationship with EBS volumes. You can add these additional volumes during or after EC2 instance creation to provide more storage capacity for your hosts.


### 5.2.4 Two types of AMIs for EC2 Instances 

```{mermaid}
flowchart TD
  AMI(AMI)
  AMI1[[Instance Store<br>Backed AMI]]
  AMI2[[EBS-Volume<br>backed AMI<br>most common]]
  AMI --> AMI1
  AMI --> AMI2   
```

**Key Points**: 
- When EC2 running on instance-store backed AMI is stopped, data is lost. 
- Instance-store backed AMIs are useful for stateless applications
- It can be rebooted without losing data


### 5.2.5 **Latency vs Throughput** discussion

Latency:
- Amount of time it takes for ONE data packet to reach its destination
- For databases and Web <-> Server Interactions

```{mermaid}
flowchart LR
  W[Web Server] -- 1 packet sent<br> in 10 millisec --> C[Client]
```

Throughput:
- Number of packets that can reach a destination within 1 sec
- Needed in Big Data Analytics

```{mermaid}
flowchart LR
  W[Web Server] -- 10 packets sent<br> in 1 sec --> C[Client]
```

### 5.2.6 Types of EBS Volumes

```{mermaid}
flowchart TD
  EBS(EBS Volumes)
  subgraph SSD
    EBS_SSD(EBS SSD)
    SSD1[[EBS Provisioned IOPS SSD]]
    SSD2[[EBS General Purpose SSD]]
    EBS_SSD --> SSD1
    EBS_SSD --> SSD2
    SSD1 --> app1((for latency sensitive<br>workloads))
    app1 --> ex1((E.g. I/O intensive<br> NoSQL RDS<br>e.g. io2,io3))
    SSD2 --> app2((for general purpose;<br>variety of transactional<br>workloads))
    app2 --> ex2((for low-latency interactive apps;<br>e.g.:gp2,gp3)) 
    max1((Max IOPS/Volume =<br> 64K))
    vol_size1((Vol Size =<br> 4GB - 16 TB))
    max2((Max IOPS/Volume =<br> 16K))
    vol_size2((Vol Size =<br> 1GB - 16 TB))
    ex1 --> max1
    ex2 --> max2 
    max1 --> vol_size1
    max2 --> vol_size2
  end
  subgraph HDD
    EBS_HDD(EBS HDD)
    HDD1[[Throughput<br>Optimized HDD]]
    HDD2[[Cold HDD]]
    apphd1((for frequently accessed<br>throughput intensive<br>workloads))
    apphd2((for less frequently<br>accessed workloads))
    maxhd1((Max IOPS/Volume =<br> 500))
    vol_sizehd1((Vol Size =<br> 500GB - 16 TB))
    maxhd2((Max IOPS/Volume =<br> 250))
    vol_sizehd2((Vol Size =<br> 500GB - 16 TB))
    EBS_HDD --> HDD1
    EBS_HDD --> HDD2
    HDD1 --> apphd1 --> maxhd1 --> vol_sizehd1
    HDD2 --> apphd2 --> maxhd2 --> vol_sizehd2
  end      
  EBS --> EBS_SSD
  EBS --> EBS_HDD
  style HDD fill:#FFFF00,stroke:#333,stroke-width:2px
  style SSD fill:#FFFF00,stroke:#333,stroke-width:2px
```

Key Point: 
- solid-state drives (SSDs) are faster and expensive than hard-disk drives (HDDs)


|Need on Latency/Throughput | Applications | Most suited type of EBS |
|---|---|--|
| Very low latency | Databases, payment systems | Provisioned IOPS SSD |
| low latency |  Web Server | General Purpose SSD |
| Very high throughput | Big Data | Throughput optimized HDD |
| can tolerate high latency but still might need good throughput because of data transer | Infrequently accessed data | Cold HDD |

### 5.2.7 Backups via EBS Snapshots:

- Concept: Incremental backups
     - First time: Stores the entire data
     - Second Snapshot: Store only data on what has changed

---

## 5.3: Object Storage with Amazon S3

### 5.3.1 WHAT IS AMAZON S3? UNDERSTAND AMAZON S3 CONCEPTS

- Amazon S3 is an object storage service.
- Object storage stores data in a flat structure, using unique identifiers to look up objects when requested. An object is simply a file combined with metadata and that you can store as many of these objects as you’d like. 
- All of these characteristics of object storage are also characteristics of Amazon S3. 


![](./images/s3_url_structure.png)

### 5.3.2 Security for S3 Objects

- Everything is private by default

> If you decide that you want everyone on the internet to see your photos, you can choose to make your buckets, folders, and objects public. Keep in mind that a public resource means that everyone on the internet can see it. Most of the time, you don’t want your permissions to be all or nothing. Typically, you want to be more granular about the way you provide access to your resources. 

Amazon S3 provides two main access management features: `IAM policies` and `S3 bucket policies`.

### 5.3.3 When should one use S3 bucket policies:
- When you need a simple way to do cross-account access to S3, without using IAM roles.
- Your IAM policies bump up against the defined size limit. S3 bucket policies have a larger size limit.

> S3 Bucket policies can only be placed on buckets, and cannot be used for folders or objects. 

### 5.3.3 ENCRYPT S3

Amazon **S3 reinforces encryption in transit** (as it travels to and from Amazon S3) and **at rest**. To protect data at rest, you can use:

**Server-side encryption**: This allows Amazon S3 to encrypt your object before saving it on disks in its data centers and then decrypt it when you download the objects.

**Client-side encryption**: Encrypt your data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, the encryption keys, and all related tools.

### 5.3.4 USE VERSIONING TO PRESERVE OBJECTS

Versioning-enabled buckets let you recover objects from accidental deletion or overwrite.

> Deleting an object does not remove the object permanently. Instead, Amazon S3 puts a marker on the object that shows you tried to delete it. If you want to restore the object, you can remove this marker and it reinstates the object.

> If you overwrite an object, it results in a new object version in the bucket. You still have access to previous versions of the object.

Buckets can be in one of three states.

- Unversioned (the default): No new or existing objects in the bucket have a version.
- Versioning-enabled: This enables versioning for all objects in the bucket.
- Versioning-suspended: This suspends versioning for new objects. All new objects in the bucket will not have a version. However, all existing objects keep their object versions.

### 5.3.5 AMAZON S3 STORAGE CLASSES

Here are the main types of Amazon S3 storage options:

1. **S3 Standard**
Use Case: Frequently accessed data.
Availability: 99.99%.
Durability: 99.999999999% (11 nines).
Performance: Low latency, high throughput.
Cost: Higher cost compared to other classes.
Typical Uses: Websites, content distribution, data analytics, and mobile applications.

2. **S3 Intelligent-Tiering**
Use Case: Data with unpredictable access patterns.
Availability: 99.9%.
Durability: 99.999999999% (11 nines).
Performance: Automatically moves data between two access tiers (frequent and infrequent) to optimize cost.
Cost: Slightly higher than Standard but saves on infrequently accessed data by automatically moving data to lower-cost storage tiers.

3. **S3 Standard-Infrequent Access (S3 Standard-IA)**
Use Case: Data that is infrequently accessed but requires rapid access when needed.
Availability: 99.9%.
Durability: 99.999999999% (11 nines).
Cost: Lower storage cost, higher retrieval cost compared to S3 Standard.
Typical Uses: Backups, disaster recovery, long-term storage.

4. **S3 One Zone-Infrequent Access (S3 One Zone-IA)**
Use Case: Infrequently accessed data that doesn't require multi-zone redundancy.
Availability: 99.5%.
Durability: 99.999999999% (11 nines) within a single Availability Zone.
Cost: Lower cost than S3 Standard-IA.
Typical Uses: Data that can be recreated easily, backups, or secondary copies.


5. **S3 Glacier**

Use Case: Long-term archive storage where retrieval time can range from minutes to hours.
Availability: 99.99%.
Durability: 99.999999999% (11 nines).
Cost: Very low storage cost, retrieval incurs additional cost and delay.
Typical Uses: Archival data, regulatory compliance, and historical records.


6. **S3 Glacier Deep Archive**
Use Case: Long-term archive for data that is rarely accessed and has retrieval times of up to 12 hours.
Availability: 99.99%.
Durability: 99.999999999% (11 nines).
Cost: Lowest-cost storage option in S3, with higher retrieval times.
Typical Uses: Long-term data retention for compliance or legal purposes.


7. **S3 Outposts**
Use Case: Storing data on-premises for applications that need local data residency.
Durability: Same as S3 (99.999999999%).
Typical Uses: Local workloads that need low latency or local data processing, and when compliance requires data to stay on-premises.

### 5.3.6 AUTOMATE TIER TRANSITIONS WITH OBJECT LIFECYCLE MANAGEMENT

When you define a lifecycle policy configuration for an object or group of objects, you can choose to automate two actions: transition and expiration actions.

- Transition actions are used to define when you should transition your objects to another storage class.
- Expiration actions define when objects expire and should be permanently deleted.

The following use cases are good candidates for lifecycle management.

- Periodic logs: If you upload periodic logs to a bucket, your application might need them for a week or a month. After that, you might want to delete them.

- Data that changes in access frequency: Some documents are frequently accessed for a limited period of time. After that, they are infrequently accessed. At some point, you might not need real-time access to them, but your organization or regulations might require you to archive them for a specific period. After that, you can delete them.


### 5.3.7 AWS Storage Services Recap

#### Amazon EC2 Instance Store

- Instance store is ephemeral block storage
- For stateless applications

> EC2 Instance Store is not meant for data that is persistent or long-lasting. If you need persistent long-term block storage that can be detached from Amazon EC2 and provide you more management flexibility, such as increasing volume size or creating snapshots, then you should use Amazon EBS. 

#### Amazon EBS

Amazon EBS is meant for data that changes frequently and needs to persist through instance stops, terminations, or hardware failures. Amazon EBS has two different types of volumes

- SSD - For I/O-sensitive workloads
- HDD - For Throughput-intensive workloads


#### Amazon S3

- It is object storage.
- You pay for what you use (you don’t have to provision storage in advance).
- Amazon S3 replicates your objects across multiple Availability Zones in a Region.
- Amazon S3 is not storage attached to compute.

#### Amazon Elastic File System (Amazon EFS) and Amazon FSx

- Also Serverless
- No need to provision in advance
- Pay for what you use

---

## 5.4 Notes from `Storage` Quiz

- The size of an individual object in S3 can be 5 TB. S3 can be really useful for media hosting and storing videos
- EBS works well as a storage layer for high transaction relational database. 
- The data on an instance store volume (also informally referred to as local storage of the EC2 instance) persists even if the instance is rebooted. However, the data does not persist if the instance is stopped, hibernated, or terminated.
- `S3 Standard Infrequent Access` when rarely accessed file need quick retrieval vs `S3 Glacier Deep Archive` (the lowest-cost option) when rarely accessed file needs to be stored only for legal requirements and are ok for longer retrieval times
- `Block Storage` is the best storage option if only a small portion of the files require change. 
- `Amazon DynamoDB` allows `flexible schema` - where the `items` in a table can have varying attributes outside of the `primary` and `secondary` key
 
[Storage Quiz](https://github.com/salimt/Courses-/blob/master/AWS%20Cloud%20Solutions%20Architect%20Professional/c01-%20AWS%20Cloud%20Technical%20Essentials/w3-%20AWS%20Storage%20and%20Databases/Week%203%20Quiz%20_%20Coursera.pdf)

---

# 6. Databases in AWS

## 6.1 My ChatGPT Interactions on Databases in AWS

### 6.1.1 Q) What is the difference between database, data warehouse and data lake. Explain with examples from AWS. 


```{mermaid}
flowchart TD
  Q((Where is<br>data stored?))
  A1[[Database]]
  A2[[Data Warehouse]]
  A3[[Data Lake]]

  P1((for OLTP))
  P2((for OLAP))
  P3((for storing raw data))

  E1[Amazon RDS<br>for an e-commerce<br>application]
  E2[Amazon Redshift<br>to query and analyze <br>vast amounts of <br>structured data<br>quickly and efficiently.]
  E3[Amazon S3<br>for storing vast amounts of<br>unstructured raw data]

  Q --> A1 
  Q --> A2
  Q --> A3

  A1 --> P1 --> E1
  A2 --> P2 --> E2
  A3 --> P3 --> E3   
```

The terms **database**, **data warehouse**, and **data lake** all refer to systems for managing and storing data, but they serve different purposes and are optimized for different types of data and use cases. Here’s a breakdown, along with AWS examples:

#### 1. **Database**  
- **Purpose:** A **database** is designed to store structured data that can be easily queried and updated. It's typically used for transactional processing (OLTP: Online Transaction Processing) where you need to manage day-to-day operations like inserts, updates, and deletes efficiently.
  
- **Data Type:** Structured data (e.g., relational data with tables, rows, and columns).
  
- **Use Cases:** Applications like inventory management, customer management, e-commerce websites, or any app that involves a lot of concurrent, real-time transactions.

- **AWS Example:** 
  - **Amazon RDS (Relational Database Service):** Supports databases like MySQL, PostgreSQL, SQL Server, and Oracle. It's managed, which means AWS takes care of backups, patching, and scaling.
  - **Amazon DynamoDB:** A NoSQL database for high-speed, low-latency performance, often used for large-scale applications that require flexible data models.

**Example Use Case:** An e-commerce website storing customer orders and product information in **Amazon RDS** for efficient querying and real-time updates.

---

#### 2. **Data Warehouse**  
- **Purpose:** A **data warehouse** is optimized for **analytical processing** (OLAP: Online Analytical Processing) where large volumes of structured data are aggregated and analyzed. It is ideal for complex queries, reporting, and business intelligence (BI) tasks.

- **Data Type:** Primarily structured data, although it may support semi-structured data (e.g., JSON or Parquet formats). Data is typically cleaned and organized before loading into a data warehouse.

- **Use Cases:** Business analytics, trend analysis, data mining, generating reports or dashboards across large data sets (e.g., sales trends across regions or customer segments).

- **AWS Example:** 
  - **Amazon Redshift:** A fully managed, petabyte-scale data warehouse designed for fast query execution across large datasets. Redshift is built for complex queries and analytics, and it integrates well with BI tools like Amazon QuickSight.

**Example Use Case:** A retail company uses **Amazon Redshift** to analyze sales data across regions to understand seasonal buying trends and forecast future demand.

---

#### 3. **Data Lake**  
- **Purpose:** A **data lake** is a centralized repository that allows you to store **structured, semi-structured, and unstructured** data at any scale. It’s highly flexible and is often used to store raw data until it’s needed for analysis. It supports various formats (e.g., JSON, CSV, images, video, text logs) and allows for big data analytics and machine learning.

- **Data Type:** Structured, semi-structured, and unstructured data (e.g., documents, audio, videos, logs, sensor data).

- **Use Cases:** Data exploration, machine learning, big data analytics, and situations where you want to store a vast array of data types before deciding what analysis or processing you need.

- **AWS Example:**
  - **Amazon S3 (Simple Storage Service):** Typically used to build a data lake in AWS. You can store any type of data in its native format and then later analyze it using other AWS services like AWS Glue (for data transformation), Amazon Athena (for querying), or Amazon EMR (for big data processing).

**Example Use Case:** A healthcare company uses **Amazon S3** to store vast amounts of raw patient data, including medical images, doctor notes, and sensor data from wearables. They later process this data for machine learning models and analytics.

---

#### Key Differences:
| Feature         | Database (RDS/DynamoDB)         | Data Warehouse (Redshift)         | Data Lake (S3)                |
|-----------------|---------------------------------|-----------------------------------|-------------------------------|
| **Primary Use**  | Transactional (OLTP)            | Analytical (OLAP)                 | Store raw data, Big Data       |
| **Data Type**    | Structured                      | Structured, Semi-structured       | Structured, Semi-structured, Unstructured |
| **Processing**   | Real-time transactions          | Aggregated, Complex queries       | Data exploration, batch processing |
| **AWS Service**  | Amazon RDS, DynamoDB            | Amazon Redshift                   | Amazon S3                      |
| **Example**      | E-commerce apps, customer orders| Business analytics, dashboards    | Raw data for analytics, ML     |

#### Summary of AWS Services:
- **Database** → **Amazon RDS** for relational databases or **DynamoDB** for NoSQL databases.
- **Data Warehouse** → **Amazon Redshift** for OLAP and analytical workloads.
- **Data Lake** → **Amazon S3** to store large datasets in various formats for big data analytics.




### 6.1.2 Q) Are all AWS Databases in EC2 instances? Are they named as db.xxx ?


No, **not all AWS databases run on EC2 instances**, and they are **not named as `db.xxx` by default**. While some database services in AWS may use EC2 instances under the hood, many of them are fully managed services, meaning you don't need to worry about the underlying EC2 infrastructure. Let me explain further:

#### 1. **Managed Databases** (Not necessarily tied to EC2 instances)
AWS provides **fully managed databases**, which abstract away the underlying infrastructure, including EC2 instances, networking, and scaling. With these services, AWS handles most operational tasks like backups, patching, scaling, and failover.

Here are some examples of **fully managed AWS database services**:
- **Amazon RDS (Relational Database Service):** A managed service for relational databases like MySQL, PostgreSQL, Oracle, SQL Server, and MariaDB. It is designed to handle the operational management of these databases, though the actual database may run on EC2 instances in the background. As a user, you don’t have direct access to the underlying EC2 instances.
  
- **Amazon Aurora:** A high-performance, MySQL- and PostgreSQL-compatible relational database built for the cloud. Like RDS, Aurora abstracts away the EC2 instances, providing a managed environment.

- **Amazon DynamoDB:** A fully managed NoSQL database that scales horizontally. It doesn’t require EC2 instances, and you don’t need to manage the underlying servers or instances.

- **Amazon Redshift:** A managed data warehouse that allows you to run analytics on structured data. While Redshift clusters are backed by EC2 instances, you manage them at a higher level through the Redshift interface.

- **Amazon DocumentDB:** A fully managed MongoDB-compatible database that abstracts away the underlying EC2 instances.

In these fully managed services, the database instances are **not explicitly named as `db.xxx`**; instead, you interact with these services through their respective APIs or consoles without seeing the underlying infrastructure. However, you may define instance identifiers or cluster names like "db1" when provisioning databases, but this is customizable.

#### 2. **Self-Managed Databases on EC2** (Named as `db.t3.medium`, etc.)
If you **self-manage** a database on an EC2 instance, then you directly control the EC2 infrastructure. In this case, you would need to handle database installation, patching, backups, scaling, and networking yourself. You could launch a database server (e.g., MySQL, PostgreSQL) on an EC2 instance, and here you would see the EC2 instance types named in the `t3`, `m5`, `db.m6g`, or similar families.

Some instance types in RDS do use naming patterns like `db.m6g.large`, but this is specific to Amazon RDS and Aurora, which provide a **managed environment on top of EC2**. For example:
- `db.t3.medium` (RDS instance) → This is an instance class used for databases in Amazon RDS, where `t3.medium` is an EC2 instance type optimized for general-purpose workloads, but **the naming convention** here indicates that it's used for a database (`db.` prefix).

### **Summary**:
- **Not all AWS databases** run on EC2 instances. Services like DynamoDB and Aurora abstract the infrastructure so you don't manage EC2s directly.
- In **Amazon RDS**, the underlying instances may be named as `db.xxx` (e.g., `db.t3.medium`), but this is specific to the RDS service.
- If you're running a database **directly on EC2**, you choose standard EC2 instance types like `t3.medium`, and you’re responsible for managing the database yourself.

---

### 6.1.3 Q) So a PostgreSQL DB can be either Self-Managed Databases on EC2 or AWS Managed ?

Yes, in AWS, a PostgreSQL database can be deployed in two primary ways:

1. **Self-Managed on EC2**:
   - **Description**: You launch a PostgreSQL database on an EC2 instance, essentially creating a self-managed environment where you control the entire database stack.
   - **Responsibilities**: You handle **installation, configuration, patching, backup, scaling,** and **security management**.
   - **Flexibility**: Full control over the PostgreSQL settings, customizations, and extensions.
   - **Use Case**: Ideal if you need custom configurations or PostgreSQL plugins that aren’t supported in managed services, or if you want to control the environment entirely.

2. **AWS Managed PostgreSQL (Amazon RDS or Amazon Aurora)**:
   - **Description**: Amazon RDS for PostgreSQL and Amazon Aurora (PostgreSQL-compatible) are fully managed database services that AWS operates.
   - **Responsibilities**: AWS handles **provisioning, patching, backup, scaling,** and **automatic failover**. You only need to manage data, schema, and performance tuning.
   - **Flexibility**: Limited to configurations and extensions that AWS supports.
   - **Use Case**: Best for users who prefer a managed, highly available, and scalable PostgreSQL solution without the administrative overhead.

So, **self-managed on EC2** gives you complete control and flexibility, whereas **AWS-managed services** offer ease of use and reduced operational burden at the cost of some customization flexibility.

---

## 6.2. Managed Databases in Amazon

```{mermaid}

flowchart TD
  DB((Databases))
  ADB[Databases in AWS]   
  M[AWS Managed Databases]
  UM[Self Managed Databases]
  OP[On-Prem Database]
  SM[Self-managed Database on Amazon EC2]

  M1[Amazon RDS]
  M2[Amazon Aurora]
  M3[Amazon DynamoDB]
  M4[Amazon Redshift]

  REL((Releational DB))   
  MEX1[MySQL]
  MEX2[PostgreSQL]
  MEX3[MariaDB]
  MEX4[SQLServer]
  MEX5[Oracle]

  MAA1[Aurora MySQL]
  MAA2[Aurora PostgreSQL]

  MAAP1((5x faster than RDS))
  MAAP2[Aurora Serverless]

  NOREL((NoSQL DB))   
  
  DDB1((Serverless))
  BOTH1((Charges based on usage and storage))
  BOTH2((High Availability))
  BOTH3((High Durable))
  BOTH4((Because: SSD-backed Instances))

  DB --> ADB
  DB --> OP

  ADB --> M
  ADB --> UM
  ADB --> SM
  M --> M1
  M --> M2
  M --> M3
  M --> M4
  
  M1 --> REL --> MEX1
  REL --> MEX2
  REL --> MEX3
  REL --> MEX4
  REL --> MEX5

  M2 --> MAA1 --> MAAP1 
  M2 --> MAA2 --> MAAP1
  M2 --> MAA1 --> MAAP2
  M2 --> MAA2 --> MAAP2   
  MAAP2 --> BOTH1
  BOTH2 --> BOTH4
  BOTH3 --> BOTH4

  M3 --> NOREL --> DDB1 --> BOTH1 
  DDB1 --> BOTH2 
  DDB1 --> BOTH3
  MAAP2 --> BOTH2 
  MAAP2 --> BOTH3
```

## 6.3 Decisions to make when choosing a DB

```{mermaid}
flowchart TB
  DB[Choices<br>in Selecing a DB<br>in AWS]
  ENG[Engine]
  STORAGE[Storage]
  COMPUTE[Compute]  

  ENG1((Commercial))
  ENG2((Open Source))
  ENG3((AWS Native))

  ENG1A[[Oracle<br>SQLServer]]
  ENG2A[[MySQL<br>PostgreSQL]]
  ENG3A[[Amazon Aurora]]

  
  STORAGE1[[EBS Volumes for RDS]]
  COMPUTE1[[Compute Instance <br>Size and Family <br><br>db.xx?]]   

  TYPE1[Standard<br> <code>m</code> classes?]
  TYPE2[Memory<br>Optimized<br><code>r</code> and <code>x` classes?]
  TYPE3[Burstable<br><code>t</code> classes?]

  S1[SSD?]
  S2[HDD?]
  S3[Magnetic Storage?] 

  DB --> ENG --> ENG1
  ENG --> ENG2
  ENG --> ENG3

  ENG1 --> ENG1A
  ENG2 --> ENG2A
  ENG3 --> ENG3A

  DB --> STORAGE --> STORAGE1
  DB --> COMPUTE --> COMPUTE1

  STORAGE1 --> S1
  STORAGE1 --> S2
  STORAGE1 --> S3   

  COMPUTE1 --> TYPE1
  COMPUTE1 --> TYPE2
  COMPUTE1 --> TYPE3
```

## 6.4 Where are Database Instances placed?

### RDS lies inside VPC Private Subnet
![](./images/dbs_inside_private_subnet.png)



### Dynamo DB lies outside VPC

![](./images/dynamo_DB_lies_outside_vpc.png)


Source: [AWS rePost](https://repost.aws/questions/QUsOBNlERPQZejZsyo3rtxGg/lambda-in-private-subnet-cannot-reach-dynamodb)

## 6.5 Backups in RDS

```{mermaid}
flowchart TD
  B((Backups))
  A((Automated Backups))
  M((Manual Snapshots))

  K((Keep backups<br>for 0 to 35 days))
  ZERO((0 days means<br>no backup))   
  E((Enables in<br>point-in-time<br>recovery))

  P((For storage<br>longer than 35 days))

  Q((Which backup<br>to use))
  ANS((Both Automated &<br>Manual combo))   

  B --> A
  B --> M

  A --> K --> ZERO --> E

  M --> P

  B --> Q --> ANS
```

## 6.6 Redundancy in RDS via Multiple Avalaibility Zones

```{mermaid}
flowchart TD
  RDS[[Amazon RDS]]
  subgraph AZ1
     subgraph subnetA
       C1[[Copy 1 of RDS]]
     end
  end

  subgraph AZ2
    subgraph subnetB
      C2[[Copy 2 of RDS]]
    end
  end
  RDS --> C1
  RDS --> C2
  %% Apply bright yellow background to subgraphs
  style AZ1 fill:#FFFF00,stroke:#333,stroke-width:2px
  style AZ2 fill:#FFFF00,stroke:#333,stroke-width:2px
  style subnetA fill:#FFFF00,stroke:#333,stroke-width:2px
  style subnetB fill:#FFFF00,stroke:#333,stroke-width:2px
```

- Multi AZ deployment ensure `High Availability` and `High Durability`

---

## 6.7 Encryption of EBS Volumes


> Consider this scenario: You are a cloud engineer who works at a company that uses Amazon Elastic Compute Cloud (Amazon EC2) instances and Amazon Elastic Block Store (Amazon EBS) volumes. The company is currently using unencrypted EBS volumes. You are tasked with migrating the data on these unencrypted EBS volumes to encrypted EBS volumes. What steps can you take to migrate the data to encrypted EBS volumes? 

```
To migrate data from unencrypted to encrypted Amazon EBS volumes, follow these steps:

1. Create a snapshot of the unencrypted EBS volume.
2. Copy the snapshot, and during the copy process, select the option to encrypt the snapshot.
3. Once the encrypted snapshot is created, create a new EBS volume from the encrypted snapshot.
4. Detach the unencrypted volume from the EC2 instance.
5. Attach the new encrypted volume to the EC2 instance in place of the original.

This ensures seamless migration of data from unencrypted to encrypted EBS volumes without downtime.
```
Source: One of the answers from a Cousera Forum 

---

## 6.8 DynamoDB

- Amazon DynamoDB is a fully managed NoSQL database service
- With DynamoDB, you can create database tables that can store and retrieve any amount of data and serve any level of request traffic.
- Data in DynamoDB stored in Key-Value pair format


| RDS | NoSQL DB |
|---|---|
| Table | Table |
| Row/Record | Item |
| Column| Attribute|

Like a `primary column` in RDS, a `primary attribute` is needed in Dynamo DB. An item could have any number of attributes

---

## 6.9 Notes from `Database` Quiz


[Database Quiz](https://github.com/salimt/Courses-/blob/master/AWS%20Cloud%20Solutions%20Architect%20Professional/c01-%20AWS%20Cloud%20Technical%20Essentials/w3-%20AWS%20Storage%20and%20Databases/Week%203%20Quiz%20_%20Coursera.pdf)

---

# 7. Monitoring in AWS

**Why Monitoring?**
- Ensuring reliable performance
- Are we using resources in a cost-effective way?
- Preventive Healthcheck: Prevent outage by scaling infra or fixing issues automated
- For security

## 7.1 Intro to AWS CloudWatch

### 7.1.1 **Services in CloudWatch**:
- Metrics
- Alarms (when a metric goes above a threshold)
- Logs

### 7.1.2 Types of Cloudwatch Metrics

```{mermaid}
flowchart TD
  M((Metrics))
  M1((Default <br>AWS Service Metrics))
  M2((Custom<br>Application Metrics))

  EX1((Eg -<br>No of hits to a Service))
  EX2((Eg -<br>Website Load Times))

  M --> M1
  M --> M2

  M1 --> EX1
  M2 --> EX2
```

### 7.1.3 Types of Monitoring

- By default, with the AWS account, a `basic monitoring` is enabled (where every 5 minutes some metrics reach the CloudWatch dashboard)
- A `detailed monitoring` at additional cost can be setup if say, metrics need to be logged every 1 minute instead of 5 minutes


### 7.1.4 How to filter/categorize Metrics


```{mermaid}
flowchart TD
  M((Metrics))

  M1((Dimensions))
  M2((Namespaces))

  EX1((Key/Value pair-<br>FunctionName/MyLambda))   
  EX2((Metrics <br>belonging to<br>different categories-<br>aws/ec2,<br>aws/lambda))

  M --> M1 --> EX1
  M --> M2 --> EX2
```

- A `Dimension` can be used to filter the metrics
- A `Namespace` gives a logical grouping of the logs into different categories

### 7.1.5 Custom Metrics

Using `boto3` sdk, you can ensure `custom metrics` like the following that reflect the health of your application can be sent to CloudWatch logs

- Web page Load Time
- Amount of tasks handled 


## 7.2 Other Services in CloudWatch
### 7.2.1 Understand the CloudWatch Dashboards

- For viewing aggregated statistics of CloudWatch metrics

### 7.2.2 CloudWatch Logs

- For lambda, easy to setup: Enable in IAM policy
- For EC2, enable CW logs agent


### 7.2 CloudWatch Alarms 

- When a metric goes above a threshold, an alarm can be set

## 7.3 EventBridge

- For a Rule-triggered workflow 
- Allows you to define rules that filter events based on specific patterns and forward those events to one or more targets.

---

## 7.4 Notes from `Monitoring` Quiz

- Amazon CloudWatch Widgets are used to view and analyze metrics in CloudWatch Dashboard

![](https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2022/06/21/devops_1335_2.png)

- The 3 states of a metric alarm in CloudWatch: `OK` (metric is within the defined threshold), `Alarm` (metric is outside the defined threshold), `Insufficient_data` (metric does not have enough data to decide on the alarm)

- VPC Network traffic (what network comes in and out of the VPC) can be measured by VPC Flow Logs

- By default, Lambda functions run in a `Lambda-managed VPC that has internet access`. So one need not configure a VPC, Subenets and Security Group unless they want to have their lambda accessed from inside a VPC in their own account. In that case,m you can add a VPC configuration to a lambda function. This restricts the lambda function to resources within that VPC, unless the VPC has internet access

Source: [A github source for Week 4 Quiz](https://github.com/salimt/Courses-/blob/master/AWS%20Cloud%20Solutions%20Architect%20Professional/c01-%20AWS%20Cloud%20Technical%20Essentials/w4-%20Monitoring%20and%20Optimizing%20Solutions%20on%20AWS/Week%204%20Quiz%20_%20Coursera.pdf)
---

# 8. Optimization in AWS

## 8.1 Notation in Nines:

![](./images/notation_in_nines.png)

## 8.2 Automatically use a Second Server in a different availability zone

```{mermaid}
flowchart TD
  client
  load_balancer
  subgraph AZ1
    server_1
  end
  subgraph AZ2
    server_2
    server_3
  end 

  client --> load_balancer
  load_balancer --> server_1
  load_balancer -- if server_1<br>goes down --> server_2
```

## 8.3 Types of High Availability Architecture

![](./images/active-active-arch.png)

> Active-active clusters rely on a dedicated load balancer for routing or distributing traffic across all participating nodes. The manner by which a load balancer distributes traffic depends on the specific load balancing algorithm used. For instance, some load balancers distribute traffic using Round-Robin, Weighted Round Robin or Random algorithm.

![](./images/active-passive-arch.png)

> Active-passive setups are common in disaster recovery (DR) strategies. In some DR strategies, the passive node is set up in a separate geographical location and then brought into play once the active node becomes incapacitated

Source for the images and above content: [An article on High Availability Architectures](https://www.jscape.com/blog/active-active-vs-active-passive-high-availability-cluster)

```{mermaid}
flowchart TD
  HA[high_availability<br> architectures]
  AP[active_passive]
  AA[active_active]

  P1((for Stateful<br>Applications))
  P2((for Stateless<br>Applications))

  HA --> AP
  HA --> AA  

  AP --> P1
  AA --> P2 
```
---

## 8.4 Route Traffic with Amazon Elastic Load Balancing

### 8.4.1 What is a Load Balancer:

- Purpose is to distribute the requests across all the servers hosting the application using a load balancer

Load balancing refers to the process of distributing tasks across a set of resources. In the case of the corporate directory application, the resources are EC2 instances that host the application, and the tasks are the different requests being sent. It’s time to distribute the requests across all the servers hosting the application using a load balancer.

To do this, you first need to enable the load balancer to take all of the traffic and redirect it to the backend servers based on an algorithm. The most popular algorithm is round-robin, which sends the traffic to each server one after the other.

A typical request for the application would start from the browser of the client. It’s sent to a load balancer. Then, it’s sent to one of the EC2 instances that hosts the application. The return traffic would go back through the load balancer and back to the client browser. Thus, the load balancer is directly in the path of the traffic.

Although it is possible to install your own software load balancing solution on EC2 instances, AWS provides a service for that called Elastic Load Balancing (ELB).


### 8.4.2 FEATURES OF ELB

The ELB service provides a major advantage over using your own solution to do load balancing, in that you don’t need to manage or operate it. It can distribute incoming application traffic across EC2 instances as well as containers, IP addresses, and AWS Lambda functions.

- The fact that ELB can load balance to IP addresses means that it can work in a hybrid mode as well, where it also load balances to on-premises servers.

- ELB is highly available. The only option you have to ensure is that the load balancer is deployed across multiple Availability Zones.

- In terms of scalability, ELB automatically scales to meet the demand of the incoming traffic. It handles the incoming traffic and sends it to your backend application.

### 8.4.3 HEALTH CHECKS

Taking the time to define an appropriate health check is critical. Only verifying that the port of an application is open doesn’t mean that the application is working. It also doesn’t mean that simply making a call to the home page of an application is the right way either.

For example, the employee directory application depends on a database, and S3. The health check should validate all of those elements. One way to do that would be to create a monitoring webpage like “/monitor” that will make a call to the database to ensure it can connect and get data, and make a call to S3. Then, you point the health check on the load balancer to the “/monitor” page.

![](./images/EC2_monitor_health_via_ELB.png)

 After determining the availability of a new EC2 instance, the load balancer starts sending traffic to it. If ELB determines that an EC2 instance is no longer working, it stops sending traffic to it and lets EC2 Auto Scaling know. EC2 Auto Scaling’s responsibility is to remove it from the group and replace it with a new EC2 instance. Traffic only sends to the new instance if it passes the health check.

In the case of a scale down action that EC2 Auto Scaling needs to take due to a scaling policy, it lets ELB know that EC2 instances will be terminated. ELB can prevent EC2 Auto Scaling from terminating the EC2 instance until all connections to that instance end, while preventing any new connections. That feature is called **connection draining**.

### 8.4.4 ELB COMPONENTS


![](./images/components_of_ELB.png)

- Listeners: The client connects to the listener. This is often referred to as client-side. To define a listener, a port must be provided as well as the protocol, depending on the load balancer type. There can be many listeners for a single load balancer.

- Target groups: The backend servers, or server-side, is defined in one or more target groups. This is where you define the type of backend you want to direct traffic to, such as EC2 Instances, AWS Lambda functions, or IP addresses. Also, a health check needs to be defined for each target group.

- Rules: To associate a target group to a listener, a rule must be used. Rules are made up of a condition that can be the source IP address of the client and a condition to decide which target group to send the traffic to.

### 8.5 APPLICATION LOAD BALANCER

- **Granular routing:** Routes traffic based on HTTP request data (URL path, host, headers, method, source IP).  
- **Direct responses:** Can send fixed responses (e.g., HTML) or redirects (e.g., HTTP → HTTPS).  
- **TLS offloading:** Handles HTTPS traffic with SSL certificates from IAM or AWS Certificate Manager (ACM).  
- **User authentication:** Supports OpenID Connect and integrates with SAML, LDAP, Microsoft AD, etc.  
- **Traffic security:** Uses security groups to restrict allowed IP ranges.  
- **Round-robin routing:** Distributes requests evenly across servers.  
- **Least outstanding requests routing:** Balances load by sending new requests to servers with fewer pending requests.  
- **Sticky sessions:** Uses HTTP cookies to keep traffic from a client directed to the same backend server.  
- **Protocol scope:** Supports HTTP and HTTPS only; use **Network Load Balancer (NLB)** for other protocols.  


### 8.6 NLB

- **Protocol support:** Works with TCP, UDP, and TLS. Operates at the connection layer, so it does not understand HTTP/HTTPS.  
- **Flow hash routing:** Routes traffic based on protocol, source/destination IP and port, and TCP sequence number.  
- **Sticky sessions:** Based on the client’s source IP address (not cookies like ALB).  
- **TLS offloading:** Can terminate TLS to reduce backend server load.  
- **High performance:** Instantly handles millions of requests per second (no warm-up needed).  
- **Static and Elastic IPs:** Supports direct client connections via fixed IP addresses—useful for DNS-restricted or firewall-rule scenarios.  
- **Source IP preservation:** Passes the client’s real IP address to the backend (unlike ALB, which shows the LB’s IP).  

![](./images/different_ELBs.png)

---

## 8.7 Intro to Amazon EC2 Auto Scaling

Availability and reachability is improved by adding one more server. However, the entire system can again become unavailable if there is a capacity issue. Let’s look at that load issue with both types of systems we discussed, active-passive and active-active.

### 8.7.1 **Vertical Scaling**

### Active-Passive vs Active-Active Systems in Scaling

When too many requests are sent to a **single active-passive system**, the active server becomes unavailable and (hopefully) fails over to the passive server.  
But this doesn’t really solve the problem.  

#### Why Active-Passive Needs Vertical Scaling
- Active-Passive systems rely on **vertical scaling** (increasing server size).  
- With **EC2 instances**, this means:
  - Choosing a larger instance type
  - Or switching to a different type  
- **Limitation:** Scaling can only be done when the instance is **stopped**.

#### Steps for Vertical Scaling in Active-Passive
1. **Stop** the passive instance (safe, since it’s not receiving traffic).  
2. **Change** the instance size or type, then **start** it again.  
3. **Shift traffic** to the passive instance (making it active).  
4. **Stop, resize, and start** the previous active instance (so both match).  

#### Drawbacks of Active-Passive Scaling
- Manual and repetitive work each time traffic changes.  
- A server can only scale **vertically up to a limit**.  
- Once the limit is reached, the only option is to:
  - Create **another active-passive system**
  - Split requests and functionalities across them  
  - (Often requires **massive application rewriting**)  

#### Active-Active Advantage
- With **active-active systems**, scaling is **horizontal**.  
- Instead of making servers bigger, you simply **add more servers**.  
- This approach is easier, more flexible, and avoids rewriting applications.


### 8.7.2 **Horizontal Scaling**

- **Active-active system** works well because the application is **stateless** (no client sessions stored on the server).  
  - Scaling from 2 → 4 servers requires **no code changes**.  
  - Just add or remove instances as needed.  

- **Amazon EC2 Auto Scaling** handles this automatically:  
  - Creates new EC2 instances when traffic increases.  
  - Terminates instances when traffic decreases.  

- **Key advantage:**  
  - Active-active + stateless apps = **true scalability**.  
  - Much more efficient compared to active-passive systems.  


### 8.7.3 **Integrate ELB with EC2 Auto Scaling**

#### ELB and Auto Scaling Integration  

The **ELB service** integrates seamlessly with **EC2 Auto Scaling**. As soon as a new EC2 instance is added to or removed from the EC2 Auto Scaling group, ELB is notified. However, before it can send traffic to a new EC2 instance, it needs to validate that the application running on that EC2 instance is available.  

This validation is done via the **health checks feature of ELB**. Monitoring is an important part of load balancers, as it should route traffic to only healthy EC2 instances. That’s why ELB supports two types of health checks:  

- **TCP Health Check**: Establishing a connection to a backend EC2 instance using TCP, and marking the instance as available if that connection is successful.  
- **HTTP/HTTPS Health Check**: Making an HTTP or HTTPS request to a webpage that you specify, and validating that an HTTP response code is returned.  

---

#### Traditional Scaling vs Auto Scaling  

##### Traditional Scaling  
- With a traditional approach to scaling, you **buy and provision enough servers** to handle traffic at its peak.  
- At low traffic times (e.g., nighttime), there is **more capacity than traffic**.  
- This leads to **wasted money**, since turning off servers only saves electricity, not provisioning costs.  

##### Cloud (Auto Scaling) Approach  
- Cloud uses a **pay-as-you-go** model.  
- It’s important to **turn off unused services**, especially EC2 instances that run On-Demand.  
- Manual scaling can work for predictable traffic, but unusual spikes cause:  
  - **Over-provisioning** → wasted resources.  
  - **Under-provisioning** → loss of customers.  

##### Solution → **EC2 Auto Scaling**  
- Automatically adds and removes EC2 instances **based on conditions you define**.  
- Ensures the right number of EC2 instances are running at any time.  


### 8.7.4 **Using Amazon EC2 Auto Scaling**
The EC2 Auto Scaling service works to add or remove capacity to keep a steady and predictable performance at the lowest possible cost. By adjusting the capacity to exactly what your application uses, you only pay for what your application needs. And even with applications that have steady usage, EC2 Auto Scaling can help with fleet management. If there is an issue with an EC2 instance, EC2 Auto Scaling can automatically replace that instance. This means that EC2 Auto Scaling helps both to scale your infrastructure and ensure high availability. 

## 8.8 **Configure EC2 Auto Scaling Components**
There are three main components to EC2 Auto Scaling.

> 1. **Launch template or configuration**: 
  - *What resource* should be automatically scaled?
  - A configuration of parameters are used to create a EC2 instance
    - AMI 
    - Security Group associated with the EC2 Instance
    - EC2 Instance Type
    - Additional EBS Volumes 
    - more

- All of these information are needed by `EC2 Auto Scaling` to create the EC2 instances on our behalf

> 2. **EC2 Auto Scaling Group** (ASG): *Where* should the resources be deployed? and How many should be deployed?

Where do you deploy the EC2 instances created via `EC2 Auto Scaling`
- VPC
- Subnets across different Availability Zones
- Type of EC2 instance purchase: On-demand, Spot ? 

How many EC2 instances should the ASG create?
- Minimum
- Maximum
- Desired

> 3. **Scaling policies**: *When* should the resources be added or removed?

- Scaling policy can be set based on metrics like CPU utilization, measured via a CloudWatch Alarm 

### 8.8.1 **Learn About Launch Templates**

![](./images/launch_templates.png)

- There are multiple parameters required to create EC2 instances:  
  - Amazon Machine Image (AMI) ID  
  - Instance type  
  - Security group  
  - Additional Amazon Elastic Block Store (EBS) volumes  
  - And more...  

- All this information is also required by **EC2 Auto Scaling** to create the EC2 instance on your behalf when there is a need to scale.  
- This information is stored in a **launch template**.  

---

#### Launch Template Usage
- You can use a **launch template** to manually launch an EC2 instance.  
- You can also use it with **EC2 Auto Scaling**.  
- It supports **versioning**, which allows:  
  - Quickly rolling back if there was an issue.  
  - Specifying a default version of your launch template.  
  - Iterating on a new version while other users continue launching EC2 instances with the default version.  

---

#### Ways to Create a Launch Template
1. **Using an existing EC2 instance** (fastest way, since all settings are already defined).  
2. **From an existing template or a previous version** of a launch template.  
3. **From scratch**, where you need to define:  
   - AMI ID  
   - Instance type  
   - Key pair  
   - Security group  
   - Storage  
   - Resource tags  

---

#### Note
- Another way to define what Amazon EC2 Auto Scaling needs to scale is by using **a launch configuration**.  
- However, a launch configuration:  
  - Does **not** support versioning.  
  - Cannot be created from an existing EC2 instance.  
- For these reasons, and to ensure that you get the latest features, **use a launch template instead of a launch configuration**.  


### 8.8.2 Get to Know EC2 Auto Scaling Groups

- The next component that EC2 Auto Scaling needs is an **EC2 Auto Scaling Group (ASG)**.  
  - An ASG enables you to define where EC2 Auto Scaling deploys your resources.  
  - This is where you specify the **Amazon Virtual Private Cloud (VPC)** and **subnets** the EC2 instance should be launched in.  

- EC2 Auto Scaling takes care of creating the EC2 instances across the subnets.  
  - It’s important to select **at least two subnets** that are across different **Availability Zones (AZs)**.  

- ASGs also allow you to specify the **type of purchase** for the EC2 instances:  
  - **On-Demand only**  
  - **Spot only**  
  - **Combination of On-Demand and Spot** (lets you take advantage of Spot instances with minimal admin overhead).  

- To specify how many instances EC2 Auto Scaling should launch, configure three **capacity settings** for the group size:  
  - **Minimum**: The minimum number of instances running in your ASG, even if the threshold for lowering the amount of instances is reached.  
  - **Maximum**: The maximum number of instances running in your ASG, even if the threshold for adding new instances is reached.  
  - **Desired capacity**: The target number of instances in your ASG.  
    - This number must be within or equal to the minimum and maximum.  
    - EC2 Auto Scaling automatically adds or removes instances to match this number.  

![](./images/mini_desired_max_capacity.png)

- **Minimum capacity**  
  - EC2 Auto Scaling keeps removing EC2 instances until it reaches the minimum capacity.  
  - Best practice: set at least **two instances** to ensure high availability.  
  - Even if scaling down is instructed, EC2 Auto Scaling won’t remove instances below the minimum.  

- **Maximum capacity**  
  - When traffic grows, EC2 Auto Scaling keeps adding instances.  
  - Costs will also increase as more instances are added.  
  - Setting a **maximum** ensures the number of instances doesn’t exceed your budget.  

- **Desired capacity**  
  - This is the number of EC2 instances created when the Auto Scaling group is launched.  
  - If the desired capacity decreases, Auto Scaling removes the **oldest instance** by default.  
  - If it increases, Auto Scaling **creates new instances** using the launch template.  

- **Ensure availability with EC2 Auto Scaling**  
  - Minimum, maximum, and desired capacity can be set to **different values** for dynamic scaling.  
  - If you want Auto Scaling only for **fleet management**, configure all three to the **same value** (e.g., 4).  
  - EC2 Auto Scaling will **replace unhealthy instances** to always maintain that count, ensuring high availability.  

![](./images/mini_desired_max_capacity_2.png)

### 8.8.3 **Enable Automation with Scaling Policies**

- **ASG Desired Capacity**
  - By default, ASG stays at its initial desired capacity.  
  - Desired capacity can be **manually changed** or adjusted with **scaling policies**.  
  - Scaling policies use **CloudWatch metrics & alarms** (e.g., CPU > 70%) to trigger scaling actions.  

- **Types of Scaling Policies**  

  - **Simple Scaling Policy**  
    - Uses a **CloudWatch alarm** to add/remove instances or set desired capacity.  
    - Can use a **fixed number** or a **percentage of group size**.  
    - Includes a **cooldown period** to avoid premature scaling while new instances boot.  
    - Limitation: can’t handle multiple thresholds (e.g., 65% vs 85%).  

  - **Step Scaling Policy**  
    - Handles **multiple thresholds** with incremental actions.  
    - Example:  
      - +2 instances if CPU ≥ 85%  
      - +4 instances if CPU ≥ 95%  
    - Responds to alarms even if scaling activity is still in progress.  

  - **Target Tracking Scaling Policy**  
    - Simplest and most dynamic option.  
    - Set a **target value** (e.g., avg CPU %, network in/out, request count).  
    - Automatically creates and manages the required **CloudWatch alarms**.  


---

## 8.9 `Optimization` Notes from Quiz

- 3 Components of `EC2 AutoScaling`: 1) Launch Template 2) `EC2 AutoScaling Group` , 3) `Scaling Policy`
- A ELB automatically scales to meet incoming demand
- When a user uses ELB with an Auto Scaling Group, there is no need to manually register the individual EC2 instances scaled with the load balancer
- If you are routing to targets based on a rule that uses the path of the request, you are using `Application Load Balancer`
- If you are running low-latency apps, real time games or IoT applications, use `Network Load Balancer` (if routing is NOT based on content-based routing)
- An application can be scaled `Vertically` by adding more firepower (compute capacity) to the existing machine OR by scaling `horizontally` by adding more EC2 instances of similar compute capacity

Source: [A github source for Week 4 Quiz](https://github.com/salimt/Courses-/blob/master/AWS%20Cloud%20Solutions%20Architect%20Professional/c01-%20AWS%20Cloud%20Technical%20Essentials/w4-%20Monitoring%20and%20Optimizing%20Solutions%20on%20AWS/Week%204%20Quiz%20_%20Coursera.pdf)

---


# 9. Additional References

- AWS Coursera Course on `AWS Technical Essentials`

- [My ChatGPT Interactions on Networking in AWS](https://chatgpt.com/share/67077451-51e0-800f-ad65-98c6b109e330)
- [My ChatGPT Interactions on Computing in AWS](https://chatgpt.com/share/6703b5e9-1154-800f-8c1d-03f16c3ae6e0)
- [My ChatGPT Interactions on Storage Services in AWS](https://chatgpt.com/share/6728503c-722c-800f-a6fc-f16d4e1888f3)
- [My ChatGPT Interactions on Database Services in AWS](https://chatgpt.com/share/67285596-cb00-800f-b999-f317d4ae56c4)

> Disclaimer: Beware: Not all information provided by ChatGPT is accurate. They get wrong quite a lot in nuanced sub-topics. 

---

# **Plagiarism Disclosure**: <br>
> - The below notes contain my own writing like mermaid charts and bullet points combined with copy-paste paragraph notes from Coursera course (not to be misjudged for plagiarism).
<br>
> - Most pics are from Coursera course. If a pic is taken from outside, source is cited below it
<br>
> - I have plenty of interactions with ChatGPT weaved into appropriate sections for better reading
<br>
> - The below notes are purely to refresh my memory when I take up any AWS exam in future. Unlike other articles, the below notes are not meant to be reviewed from the pov of plagiarism.

