{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /pytorch/2021/08/15/PyTorch_NN_model_on_FashionMNIST_Tensorboard\n",
    "author: Senthil Kumar\n",
    "badges: true\n",
    "branch: master\n",
    "categories:\n",
    "- AI/Foundations\n",
    "- Programming/Python\n",
    "date: '2021-08-15'\n",
    "description: This blog post explains the basics of PyTorch Tensors, the workflow to\n",
    "  train a 2 layer Neural Network for a vision dataset and track the progress in a\n",
    "  Tensorboard\n",
    "hide: false\n",
    "image: images/pytorch_nn/pytorch_offl_image.png\n",
    "output-file: 2021-08-15-pytorch_nn_model_on_fashionmnist_tensorboard.html\n",
    "title: An Introduction to PyTorch Fundamentals for Training DL Models\n",
    "toc: true\n",
    "\n",
    "---\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932889a",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba578d6a",
   "metadata": {},
   "source": [
    "- We have taken `FashionMNIST` dataset and prepared a simple 2-layer NN model to uncover the fundamental concepts of PyTorch\n",
    "- Before going into the DL portions, let us look at Tensors first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7ad860",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea11f715",
   "metadata": {},
   "source": [
    "## 0. What are Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e63d2",
   "metadata": {},
   "source": [
    "- Tensors are **like** numerical arrays that encode the input, output and weights/parameters of a model in the form of arrays and matrices.\n",
    "- Typical 1D and 2D arrays:\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/24909551/157380975-0402a8ec-7f49-49a3-aef8-5fadc19d4c9c.png)\n",
    "Source:  docs.microsoft.com/en-US/learn    \n",
    "\n",
    "- How to imagine a 3D array:\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/24909551/157381034-056897c1-acea-459b-b43a-1b56d55b2434.png)\n",
    "Source:  docs.microsoft.com/en-US/learn    \n",
    "\n",
    "- Tensors work better on GPUs. They are optimized for **automatic differentiation**\n",
    "- Tensors and numpy often have the same memory address. For example, review the code below <br>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data = [[1,2],[3,4]]\n",
    "np_array = np.array(data)\n",
    "tensor_array = torch.from_numpy(np_array)\n",
    "\n",
    "# doing multiplication opearation on `np_array`\n",
    "np.multiply(np_array,2,out=np_array)\n",
    "\n",
    "print(f\"Numpy array:{np_array}\")\n",
    "print(f\"Tensor array:{tensor_array}\")\n",
    "```\n",
    "\n",
    "```python\n",
    "Numpy array:[[2 4]\n",
    " [6 8]]\n",
    "Tensor array:tensor([[2, 4],\n",
    "        [6, 8]])\n",
    "```\n",
    "\n",
    "**How to initialize a tensor?**: <br>\n",
    "\n",
    "```python    \n",
    "# directly from a python datastructure element\n",
    "data = [[1,2],[3,4]]\n",
    "x_tensor_from_data = torch.tensor(data)\n",
    "\n",
    "# from numpy_array\n",
    "np_array = np.array(data)\n",
    "x_tensor_from_numpy = torch.from_numpy(np_array)\n",
    "\n",
    "# from other tensors\n",
    "x_new_tensor = torch.rand_like(x_tensor_from_data, dtype=torch.float) # dtype overrides the dtype of z_tensor_from_data\n",
    "    \n",
    "# random or new tensor of given shape\n",
    "shape = (2,3,) # or just (2,3)\n",
    "x_new_tensor_2 = torch.ones(shape)\n",
    "```\n",
    "    \n",
    "**What are the `attributes` of a tensor?**:<br>\n",
    "\n",
    "```python\n",
    "print(f\"{x_new_tensor_2.shape}\")\n",
    "print(f\"{x_new_tensor_2.dtype}\")\n",
    "print(f\"{x_new_tensor_2.device}\") # whether stored in CPU or GPU\n",
    "```\n",
    "\n",
    "**When to use CPU and and when to use GPU while `operating` tensors?**: <br>\n",
    "\n",
    "- Some common tensor operations include: Any arithmetic operation, linear algebra, matrix manipulation (transposing, indexing, slicing)\n",
    "- Typical GPUs have 1000s of cores. GPUs can handle parallel processing.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/24909551/159158293-6faec4f4-e959-4fa6-a5cf-114ddb83810b.png)\n",
    "Source:  docs.microsoft.com/en-US/learn    \n",
    "\n",
    "- Typical CPUs have 4 cores. Modern CPUs can have upto 16 cores. Cores are units that do the actual computation. Each core processes tasks in **sequential** order\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/24909551/159158302-d75e6fea-eaaa-4c01-a930-0b41a5cfde7c.png)\n",
    "Source:  docs.microsoft.com/en-US/learn    \n",
    "\n",
    "- Caveat: Copying large tensors across devices can be expensive w.r.t `time` and `memory`\n",
    "\n",
    "- `PyTorch` uses Nvidia `CUDA` library in the backend to operate on GPU cards\n",
    "\n",
    "```python\n",
    "if torch.cuda._is_available():\n",
    "    gpu_tensor = original_tensor.to('cuda') \n",
    "```\n",
    "\n",
    "**What are the common tensor operations?**: <br>\n",
    "- `Joining` or `ConCATenate`\n",
    "```python\n",
    "new_tensor = torch.cat([tensor, tensor],dim=1) # join along column if dim=1\n",
    "```    \n",
    "- `Matrix Multiplication`   \n",
    "```python\n",
    "# you would have to do the transpose\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "assert y1 = y2 = y3\n",
    "```\n",
    "\n",
    "- `Element-wise Multiplication`    \n",
    "```python\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "```  \n",
    "\n",
    "- `Single element tensor` into python numerical value    \n",
    "```python\n",
    "sum_of_values = tensor.sum()\n",
    "sum_of_values_python_variable = sum_of_values.item()\n",
    "print(sum_of_values.dtype, type(sum_of_values_python_variable))\n",
    "# >> torch.int64, <class 'int'>\n",
    "```\n",
    "\n",
    "- `In-place Operations`    \n",
    "\n",
    "```python\n",
    "# add in_place\n",
    "tensor.add_(5)\n",
    "```\n",
    "\n",
    "```\n",
    "# transpose  in place\n",
    "tensor.t_()\n",
    "\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef238f",
   "metadata": {},
   "source": [
    "Summary of the key operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36554d55",
   "metadata": {},
   "source": [
    " - `torch.cuda.is_available()` gives a boolean output\n",
    " - `torch.tensor(x)` <br>\n",
    "  - x could be a 1D or 2D iterable (list or tuple) <br>\n",
    " - `torch.ones_like(tensor_variable)`, `torch.rand_like(tensor_variable)` <br>\n",
    " - `torch.ones(shape_in_a_tuple_or_list)` , `torch.zeros(shape_in_a_tuple_or_list)` and  `torch.rand(shape_in_a_tuple_or_list)` <br>\n",
    " - `torch_tensor_variable[start_index:end_index:step_value]` (similar to a numpy indexing)\n",
    " - numpy to torch tensor: `torch.from_numpy(np_array)`\n",
    " - torch_tensor to numpy: `torch_tensor_variable.numpy()`\n",
    " - Concatenate across rows `torch.cat((an_iterable_of_tensors),dim=0)`<br>\n",
    " - Concatenate across columns `torch.cat((an_iterable_of_tensors),dim=1)` <br>\n",
    " - tensor multiplication `tensor1 * tensor2 == torch.mul(tensor1,tensor2,out=tensor3) == tensor1.mul(tensor2)` <br>\n",
    " - convert single_element_tensor into a python datatype using `.item()` --> `single_element_tensor = tensor1.sum(); python_variable = single_element_tensor.item()` <br>\n",
    " - In-place Operations in torch using `_`: `x.add_(5)` will add 5 to each element of x <br>\n",
    " - tensor `n = t.numpy()` & np.add(n,2,out=n) --> A change in `n` will automatically change `t` (vice versa is true too)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180ebac",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586e9a4d",
   "metadata": {},
   "source": [
    "Importing relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87f786b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# torchvision.datasets module contains `Dataset` objects for many real-world vision data\n",
    "from torchvision import datasets # other domain-specific libraries TorchAudio, TorchText\n",
    "from torchvision.transforms import (\n",
    "    ToTensor, # for normalizing the pixel values to the range [0,1]\n",
    "    Lambda, # to make user-defined functions as one of the transformations \n",
    "    )\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bdcc12",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd412b",
   "metadata": {},
   "source": [
    "## 1. Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa0c40",
   "metadata": {},
   "source": [
    "Two data `primitives` to handle data efficiently: <br>\n",
    "- `torch.utils.data.Dataset`\n",
    "- `torch.utils.data.DataLoader` \n",
    "\n",
    "**How should the data be preprocessed before training in DL?**: <br>\n",
    "- Pass samples of data in `minibatches`\n",
    "- reshuffle the data at every epoch to overfitting\n",
    "- leverage Python's `multiprocessing` to speed up data retrieval\n",
    "\n",
    "**`torch.utils.data.DataLoader` abstracts all the above steps**\n",
    "\n",
    "\n",
    "What does `Dataset` do?\n",
    "- `Dataset`: Stores data samples and their corresponding labels\n",
    "- `DataLoader`: Wraps an iterable around Dataset to enable easy access to the samples. `DataLoader` can also be used along with `torch.multiprocessing`\n",
    "- `torchvision.datasets` and `torchtext.datasets` are both subclasses of `torch.utils.data.Dataset` (they have __getitem__ and __len__ methods implemented) and also they can be passed to a `torch.utils.data.DataLoader`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16279017",
   "metadata": {},
   "source": [
    "**What does normalization do?**: <br>\n",
    "- Changes the range of the data\n",
    "- When one pixel value is 15 and another pixel is 190, the higher pixel value will deviate the learning \n",
    "\n",
    "**Why do we do normalization of data before training a DL**:\n",
    "- Prediction accuracy is better for normalized data\n",
    "- Model can learn faster if data is normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8518ca3e",
   "metadata": {},
   "source": [
    "**More details on PyTorch Primitives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac3c21",
   "metadata": {},
   "source": [
    "- `torchvision.datasets` --> to use pre-existing datasets like FashionMNIST, coco, cifar, etc.,\n",
    "- torchvision.datasets have arguments/parameters to `transform` featuers (aka inputs) and `target_transform` to transform labels (like one hot encoding of labels\n",
    "- CustomDatasetClass must overwrite the `magic methods` of python such as \n",
    "        - `__init__`, `__getitem__` and `__len__` methods inherited from `Dataset`\n",
    "- `torchvision.transforms.ToTensor` (to transform/modify the features) and `torchvision.transforms.Lambda` (to transform the target/labels)\n",
    "        - `torchvision.transforms.ToTensor()` converts features to normalized tensors\n",
    "        - `torchvision.transforms.Lambda` could be used to transform labels\n",
    "        - `Lambda(lambda y: torch.zeros(number_of_classes,dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1)\n",
    "                  )`\n",
    "        - `Tensor.scatter_` is used to change values of a tensor variable at specified indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7491df",
   "metadata": {},
   "source": [
    "### 1A. Converting Data into Model Suitable Iterables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334eee2",
   "metadata": {},
   "source": [
    "- Downloading and transforming the datasets\n",
    "- Preparing train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(datasets.FashionMNIST)\n",
    "help(datasets.MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45bf6b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da763d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 2, 1, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "print(test_data.test_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b84026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43801e1",
   "metadata": {},
   "source": [
    "```python\n",
    "# If you have a custom dataset in your location\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    \"\"\"FashionMNIST like Image Dataset Class\"\"\"\n",
    "    def __init__(self, \n",
    "                 annotations_file,\n",
    "                 img_dir,\n",
    "                 transform=None,\n",
    "                 target_transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transform (Optional): dataset will take an optional argument transform \n",
    "                so that any required processing can be applied on the sample\n",
    "        \"\"\"\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # format of data \n",
    "        # image_location, label_type\n",
    "        # tshirt1.jpg, T-shirt/top # class needs to be convered into numerical format\n",
    "        # pant4.jpg, Trouser # class needs to be convered into numerical format\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n",
    "        image = tvio.read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "        return sample\n",
    "\n",
    "\n",
    "# target_transform\n",
    "# turn the integer y values into a `one_hot_encoded` vector \n",
    "# 1. create a zero tensor of size 10 torch.zeros(10, dtype=torch.float)\n",
    "# 2. `scatter_` assigns a value =1\n",
    "the_target_lambda_function = Lambda(lambda y: torch.zeros(10,\n",
    "                                    dtype=troch.float).scatter_(dim=0,\n",
    "                                                    index=torch.tensor(y), value=1))\n",
    "\n",
    "\n",
    "training_data = CustomImageDataset(\n",
    "    root=\"data\", # the path where the train/test data is stored\n",
    "    train=True, # False if it is a test dataset \n",
    "    download=False, # downloads the data from Web if not available at root\n",
    "    transform=ToTensor(), # transform the features; converts PIL image or numpy array into a FloatTensor and scaled the image's pixel intensity to the range [0,1]\n",
    "    target_transform=the_target_lambda_function\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=the_target_lambda_function\n",
    "    # target_transform=torch.nn.functional.one_hot(y, num_classes=10) # alternate way\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6794e",
   "metadata": {},
   "source": [
    "Preparing Validation Data from Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5983671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7400, 11594, 9947, 24051, 56426]\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(len(training_data)))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "print(indices[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d919334",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(np.floor(0.2 * len(training_data)))\n",
    "training_data_sample = SubsetRandomSampler(indices[split:])\n",
    "validation_data_sample = SubsetRandomSampler(indices[:split])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a83dd",
   "metadata": {},
   "source": [
    "Convert into iterables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f98fe92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "3000\n",
      "2500\n",
      "Shape of Features: torch.Size([4, 1, 28, 28])\n",
      "Shape of Labels: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "batchsize = 4\n",
    "\n",
    "# create iterables \n",
    "train_dataloader = DataLoader(training_data, sampler=training_data_sample, batch_size=batchsize)\n",
    "validation_dataloader = DataLoader(training_data, sampler=validation_data_sample, batch_size=batchsize)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batchsize)\n",
    "\n",
    "print(len(train_dataloader))\n",
    "print(len(validation_dataloader))\n",
    "print(len(test_dataloader))\n",
    "\n",
    "# to understand the shape of input features and output\n",
    "for X,y in test_dataloader:\n",
    "    print(\"Shape of Features:\",X.shape)\n",
    "    print(\"Shape of Labels:\",y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "014bdd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fb18fe",
   "metadata": {},
   "source": [
    "- The above shape of training image is in the format NCHW\n",
    "- batchsize N, no. of channels C, height H, width W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aab2d7",
   "metadata": {},
   "source": [
    "### 1B. Visualize sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b68d315a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_dataloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "for idx in np.arange(4):\n",
    "    ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    ax.set_title(labels[idx].item())\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dac265e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f38e81aedd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking into just one image, label\n",
    "\n",
    "figure = plt.figure(figsize=(5,5))\n",
    "img, label = test_data[0]\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img.squeeze(),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "908dd43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        \n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b26c063",
   "metadata": {},
   "source": [
    "### 1C. Initiating the Tensorboard Logs and Visualizing Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45c68c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the log directory\n",
    "writer = SummaryWriter('runs/fashion_mnist_2_layer_NN_experiment_1')\n",
    "\n",
    "# writing the grid of 4 images to Tensorboard log dir\n",
    "writer.add_image('Four Sample Fashion-MNIST Images', img_grid)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1bf45",
   "metadata": {},
   "source": [
    "**How to load the tensorboard**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de26e76",
   "metadata": {},
   "source": [
    "To view, start TensorBoard on the command line with:\n",
    "- `tensorboard --logdir=runs`\n",
    "- and open a browser tab to http://localhost:6006/\n",
    "- Can view the sample images in `images` tab "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c016e12",
   "metadata": {},
   "source": [
    "- Load the TensorBoard notebook extension for jupyter notebook\n",
    "```\n",
    "%load_ext tensorboard\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d4056",
   "metadata": {},
   "source": [
    "- Run the tensorboard from jupyter notebook\n",
    "\n",
    "```\n",
    "%tensorboard --logdir runs/fashion_mnist_2_layer_NN_experiment_1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973d252",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6b4b2d",
   "metadata": {},
   "source": [
    "## 2. Build the Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d401a2",
   "metadata": {},
   "source": [
    "Build a NN with **2 hidden layers** and 1 output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d1a22",
   "metadata": {},
   "source": [
    "**Components of a Neural Network**:\n",
    "\n",
    "- Typical Neural Network: <br>\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/24909551/160055546-f6150c41-acb0-44a4-942e-0d20c86e8972.png)\n",
    "\n",
    "- Activation Function, Weight and Bias\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/24909551/160055714-0bfb081d-6c1b-4733-a226-d7db71e74fec.png)\n",
    "\n",
    "- Linear weighted sum of inputs: x = &sum;(`weights` * `inputs`) + `bias`    \n",
    "- f(x) = activation_func(x)\n",
    "\n",
    "- Activation Functions add non-linearity to the model    \n",
    "- Different Activation Functions: <br>\n",
    "    - **Sigmoid**: <sup>1</sup>/<sub>(1 + exp(-x))</sub>\n",
    "    - **Softmax**: <sup>exp(x)</sup> / <sub>(sum(exp(x)))</sub>\n",
    "    - **ReLU**: max(0,x)\n",
    "    - **Tanh**: <sup>(exp(x) - exp(-x))</sup>/<sub>(exp(x) + exp(-x))</sub>\n",
    "\n",
    "**Building a neural network in PyTorch** \n",
    "- `torch.nn` class provides all the building block needed to build a NN\n",
    "- Every module/layer in PyTorch subclases the `torch.nn.Module`\n",
    "- A NN is a composite module consisting of other modules (layers)\n",
    "    \n",
    "    \n",
    "- Initialize all layers in `__init__` module\n",
    "- Build a 3-layer NN with \n",
    "    - flattened `28*28` image as input,\n",
    "    - 2 hidden layers will have 512 neurons each and\n",
    "    - the third layer (which also has relu activation function) will have 10 neurons each corresponding to the number of classes\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bf41165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "076ac7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # initialize the layers in __init__ constructor\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        # supercharge your sub-class by inheriting the defaults from Parent class\n",
    "        self.flatten = nn.Flatten()\n",
    "        # one can also use Functional API in PyTorch \n",
    "        # but below codes use Sequential API\n",
    "        # the below stack of layers generates scores or logits\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # hidden layer 1 consisting of 512 neurons\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            # hidden layer 2 consisting of 512 neurons too\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            # output layer consisting of 10 neurons \n",
    "            nn.Linear(512,10),\n",
    "            # we can also build a NN without this final layer ReLU\n",
    "            # instead can also run the log_softmax directly\n",
    "            nn.ReLU(), \n",
    "        )\n",
    "        \n",
    "    def forward(self,x): # need to pass the input argument x\n",
    "        # function where the input is run through \n",
    "        # the initialized layers\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "# create a instance of the class NeuralNetwork \n",
    "# move it to the device (CPU or GPU)\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "# print model structure\n",
    "print(model)\n",
    "\n",
    "# is nn.ReLU in the final layer?\n",
    "# https://ai.stackexchange.com/questions/8491/does-it-make-sense-to-apply-softmax-on-top-of-relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c056ac",
   "metadata": {},
   "source": [
    "- Why `model(X)` instead of `model.forward(X)`? <br>\n",
    "[Source](https://stackoverflow.com/questions/55338756/why-there-are-different-output-between-model-forwardinput-and-modelinput) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6274519",
   "metadata": {},
   "source": [
    "Dissecting the steps using Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5adc5",
   "metadata": {},
   "source": [
    "- **Step 1**:Convert `28*28` into a contiguous array of 784 pixel values\n",
    "    \n",
    "```python\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())\n",
    "# step 1: Flatten the input image\n",
    "flatten = nn.Flatten() # instantitate\n",
    "flat_image = flatten(input_image)  # pass the prev layer (input) into the instance\n",
    "print(flat_image.size())\n",
    "```\n",
    "- **Step 2**: Dense or linear layer in PyTorch `weight * input + bias`\n",
    "    \n",
    "```python    \n",
    "# step 2: apply linear transformation `weight * input + bias`\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=512) # instantiate\n",
    "hidden1 = layer1(flat_image) # pass the prev layer (flattened image) into the instance\n",
    "print(hidden1.size())\n",
    "```\n",
    "\n",
    "- **Step 3**: Apply Relu activation on the linear transformation\n",
    "    \n",
    "```python\n",
    "relu_activation = nn.ReLU() #instantiate\n",
    "hidden1 = relu_activation(hidden1)\n",
    "```    \n",
    "Repeat Step 2 and 3 for `hidden2`: <br>\n",
    "\n",
    "```python\n",
    "layer2 = nn.Linear(in_features=512, out_features=512)\n",
    "hidden2 = layer2(hidden1)\n",
    "hidden2 = relu_activation(hidden2)\n",
    "```    \n",
    "    \n",
    "- **Step 4**: Compute the logits\n",
    "    \n",
    "```python\n",
    "# a simple 1 hidden layer NN with 20 neurons in the hidden layer\n",
    "nn_seq_modules = nn.Sequential(\n",
    "                    flatten,\n",
    "                    layer1,\n",
    "                    relu_activation,\n",
    "                    layer2,\n",
    "                    relu_activation,\n",
    "                    nn.Linear(512, 10), # the output                )\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits =  nn_seq_modules(input_image)   \n",
    "```\n",
    "    \n",
    "- **Step 5**: Apply `Softmax` function\n",
    "    \n",
    "```python\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "predict_probab = softmax(logits)\n",
    "\n",
    "```\n",
    "\n",
    "- Full NN workflow: \n",
    " \n",
    "![image](https://user-images.githubusercontent.com/24909551/161696907-8672f820-3293-4390-b153-bf702731352d.png)\n",
    "Source: docs.microsoft.com/en-US/learn    \n",
    "\n",
    "\n",
    "**How to see internal layers of a NN in PyTorch**:\n",
    "\n",
    "```python\n",
    "print(\"Weights stored in first layer: {model.linear_relu_stack[0].weight} \\n\")\n",
    "print(\"Bias stored in first layer: {model.linear_relu_stack[0].bias} \\n\") \n",
    "    \n",
    "from name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\"\n",
    "```\n",
    "    \n",
    "```bash\n",
    "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784])\n",
    "Layer: linear_relu_stack.0.bias | Size: torch.Size([512])\n",
    "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512])\n",
    "Layer: linear_relu_stack.2.bias | Size: torch.Size([512])\n",
    "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512])\n",
    "Layer: linear_relu_stack.4.bias | Size: torch.Size([10])\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad50b018",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2f3c5",
   "metadata": {},
   "source": [
    "## 3. Training the Model \n",
    "Training with training data and evaluating loss on Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7eb30e",
   "metadata": {},
   "source": [
    "### 3A.Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea5cbd5",
   "metadata": {},
   "source": [
    "- `num_of_epochs`: The number of times the entire training dataset is pass through the network\n",
    "- `batch_size`: The number of data samples seen by the model before updating its weights. (derived parameter `steps = total_training_data/batch_size` - the number of batches needed to complete an epoch)\n",
    "- `learning_rate`: How much to change the weights in the `w = w - learning_rate * gradient`. Smaller value means the model will take a longer time to find best weights. Larger value of learning_rate might make the NN miss the optimal weights because we might step over the best values\n",
    "- Choice of `loss_fn` <br>\n",
    "Common Loss Functions for classification problems :    \n",
    "    - `nn.NLLLoss` #Negative Log Likelihood    \n",
    "    - `nn.CrossEntropyLoss` # combination of `nn.LogSoftmax` and `nn.NLLLoss`   \n",
    "- Choice of `optimizers` <br>\n",
    "    - `torch.optim.SGD`\n",
    "    - `torch.optim.Adam`\n",
    "    - `torch.optim.RMSProp` and many more ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b4dc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epochs = 40\n",
    "batchsize = 4 # already mentioned in the DataLoader arguments\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=learning_rate\n",
    "                           )\n",
    "# SGD optimizer in PyTorch actually is Mini-batch Gradient Descent with momentum\n",
    "# it updates one mini-batch at a time (batchsize)\n",
    "# Source: https://discuss.pytorch.org/t/how-sgd-works-in-pytorch/8060"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff1f01",
   "metadata": {},
   "source": [
    "### 3B. Writing Core Training and Evaluation Loop Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f53c9",
   "metadata": {},
   "source": [
    "- `loss_fn` and `optimizer` are passed to `train_loop` and just `loss_fn` to `test_loop`\n",
    "```python\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}\\n ----------------------------\")\n",
    "    train_loop(train_dataloader, validation_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader,model, loss_fn)\n",
    "print(\"Over!\")    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4a42cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train_dataloader, validation_dataloader, model, loss_fn, optimizer, epoch):\n",
    "    train_size = len(train_dataloader.dataset)\n",
    "    validation_size = len(validation_dataloader.dataset)\n",
    "    training_loss_per_epoch = 0\n",
    "    validation_loss_per_epoch = 0\n",
    "    for batch_number, (X,y) in enumerate(train_dataloader):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        \n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation steps\n",
    "        # key optimizer steps\n",
    "        # by default, gradients add up in PyTorch\n",
    "        # we zero out in every iteration\n",
    "        optimizer.zero_grad() \n",
    "        # performs the gradient computation steps (across the DAG)\n",
    "        loss.backward()\n",
    "        # adjust the weights\n",
    "        optimizer.step()\n",
    "        training_loss_per_epoch += loss.item()\n",
    "        \n",
    "#         if batch_number % 100 == 0:\n",
    "#             print(f\"After completing {batch_number * len(X)} samples, the loss is:\")\n",
    "#             print(loss.item()) \n",
    "            \n",
    "    for batch_number, (X,y) in enumerate(validation_dataloader):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "        \n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        validation_loss_per_epoch += loss.item()\n",
    "    avg_training_loss = training_loss_per_epoch/train_size\n",
    "    avg_validation_loss = validation_loss_per_epoch/validation_size\n",
    "    print(f\"Average Training Loss of {epoch}: {avg_training_loss}\")\n",
    "    print(f\"Average Validation Loss of {epoch}: {avg_validation_loss}\")\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                       {'Training': avg_training_loss, \n",
    "                        'Validation': avg_validation_loss\n",
    "                       },\n",
    "                       epoch\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f2a5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(test_dataloader,model, loss_fn, epoch):\n",
    "    test_size = len(test_dataloader.dataset)\n",
    "    # Failing to do eval can yield inconsistent inference results\n",
    "    model.eval()\n",
    "    test_loss_per_epoch, accuracy_per_epoch = 0, 0\n",
    "    # disabling gradient tracking while inference\n",
    "    with torch.no_grad():\n",
    "        for X,y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            test_loss_per_epoch += loss.item()\n",
    "            accuracy_per_epoch += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    print(f\"Average Test Loss of {epoch}: {test_loss_per_epoch/test_size}\")\n",
    "    print(f\"Average Accuracy of {epoch}: {accuracy_per_epoch/test_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ed4c8",
   "metadata": {},
   "source": [
    "### 3C. Training the model for many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "084a5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 0 \n",
      "---------------------\n",
      "Average Training Loss of 0: 0.37492141907910503\n",
      "Average Validation Loss of 0: 0.07822599628902972\n",
      "Average Test Loss of 0: 0.3941003955438733\n",
      "Average Accuracy of 0: 0.4513\n",
      "Epoch Number: 1 \n",
      "---------------------\n",
      "Average Training Loss of 1: 0.29412952572156986\n",
      "Average Validation Loss of 1: 0.06984573040464893\n",
      "Average Test Loss of 1: 0.3524202892445028\n",
      "Average Accuracy of 1: 0.5089\n",
      "Epoch Number: 37 \n",
      "---------------------\n",
      "Average Training Loss of 37: 0.13975639427933614\n",
      "Average Validation Loss of 37: 0.037423237568447926\n",
      "Average Test Loss of 37: 0.19380079013922005\n",
      "Average Accuracy of 37: 0.7052\n",
      "Epoch Number: 38 \n",
      "---------------------\n",
      "Average Training Loss of 38: 0.13921849230745761\n",
      "Average Validation Loss of 38: 0.038412615390023046\n",
      "Average Test Loss of 38: 0.19745682889677718\n",
      "Average Accuracy of 38: 0.7015\n",
      "Epoch Number: 39 \n",
      "---------------------\n",
      "Average Training Loss of 39: 0.13862396091737622\n",
      "Average Validation Loss of 39: 0.03721317019570803\n",
      "Average Test Loss of 39: 0.1929354560287782\n",
      "Average Accuracy of 39: 0.7063\n",
      "CPU times: user 12min 2s, sys: 5.22 s, total: 12min 7s\n",
      "Wall time: 11min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(num_of_epochs):\n",
    "    print(f\"Epoch Number: {epoch} \\n---------------------\")\n",
    "    train_loop(train_dataloader, validation_dataloader, model, loss_fn, optimizer, epoch)\n",
    "    test_loop(test_dataloader,model, loss_fn, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fca15c",
   "metadata": {},
   "source": [
    "*truncated the results for easy viewing* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d206c1",
   "metadata": {},
   "source": [
    "Points to ponder: \n",
    "- The accuracy for this 2-layer NN stands at 71%. \n",
    "- The Hyperparameters - batch_size, learning_rate, choice of optimizer - can be varied to see how results change.\n",
    "- **Changing Architecture**: Deepening the number of hidden layers can help in improving the accuracy or changing the architecture to use CNN or any pre-trained NN like *LeNet-5* or others will improve further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ff040",
   "metadata": {},
   "source": [
    "### 3D. Saving, Loading and Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04a9016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.utf-8)\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p model_weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7a7f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model_weights/fmnist_2_layer_nn_model_batch_size_4.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ffd613",
   "metadata": {},
   "source": [
    "**How to save and load the model for inference?**    \n",
    "```python    \n",
    "# pytorch models save the parameters in a internal state dictionary called `state_dict`\n",
    "torch.save(model.state_dict(),\"data/modelname.pth\")\n",
    "    \n",
    "# infer from a saved model\n",
    "# instantiate the model architecture class\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"data/modelname.pth\"))\n",
    "# the eval method is called before inferencing so that the batch normalization dropout layers are set to `evaluation` mod\n",
    "# Failing to do this can yield inconsistent inference results\n",
    "model.eval()\n",
    "```    \n",
    "\n",
    "**How to export a pytorch model to run in any Programming Language/Platform**: <br>\n",
    "    \n",
    "- **ONNX**: Open Neural Network Exchange \n",
    "- Converting `PyTorch` model to `onnx` format aids in running the model in Java, Javascript, C# and ML.NET\n",
    "    \n",
    "```python\n",
    "# while explorting pytorch model to onnx, \n",
    "# we'd have to pass a sample input of the right shape\n",
    "# this will help produce a `persisted` ONNX model    \n",
    "import torch.onnx as onnx\n",
    "input_image = torch.zeros((1,28,28))\n",
    "onnx_model_location = 'data/model.onnx'\n",
    "onnx.export(model, input_image, onnx_model)\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa6e2e8",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e775e",
   "metadata": {},
   "source": [
    "## 4. Predict using the Trained Model\n",
    "Loading the trained model and predicting for unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1058551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# construct the model structure\n",
    "model = NeuralNetwork()\n",
    "# load the state_dict\n",
    "model.load_state_dict(torch.load(\"model_weights/fmnist_2_layer_nn_model_batch_size_4.pth\"))\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e23094e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4451, 0.0000, 0.0000, 0.0000,\n",
       "        5.6093])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are logit scores and not softmax outputs \n",
    "# yet they are enough for predicting the class \n",
    "# since the logits are finally coming out of a ReLU() unit\n",
    "# A ReLU outputs from (0,max)\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052d45e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d982df",
   "metadata": {},
   "source": [
    "## 5. Leveraging Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdee91a",
   "metadata": {},
   "source": [
    "Reiterating the steps we have already done using Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e846997",
   "metadata": {},
   "source": [
    "- 1.Specifying the Log directory and using `add_images` method\n",
    "\n",
    "```python\n",
    "# `torch.utils.data.tensorboard.SummaryWriter` class\n",
    "# specifying the log directory\n",
    "writer = SummaryWriter('runs/fashion_mnist_2_layer_NN_experiment_1')\n",
    "\n",
    "# writing the grid of 4 images to Tensorboard log dir\n",
    "# we can look at `IMAGES` tab of Tensorboard for this\n",
    "writer.add_image('Four Sample Fashion-MNIST Images', img_grid)\n",
    "writer.flush()\n",
    "```\n",
    "\n",
    "- 2.Tracking Epoch level Average Training and Validation Losses. \n",
    "\n",
    "```python \n",
    "# We can track in the `SCALARS` tab of the Tensorboard\n",
    "writer.add_scalars('Training vs. Validation Loss',\n",
    "                   {'Training': avg_training_loss, \n",
    "                    'Validation': avg_validation_loss\n",
    "                   },\n",
    "                   epoch\n",
    "                  )\n",
    "```\n",
    "\n",
    "**The Graph of Training Loss (blue line) and Validation Loss (green line) in Tensorboard**\n",
    "\n",
    "![](./pytorch_nn/training_and_validation_loss_over_epochs.png)\n",
    "\n",
    "- 3.After trained model is obtained, we can look at the graph to trace the sample input through your model\n",
    "\n",
    "```python\n",
    "# We can track in the `GRAPH` tab of the Tensorboard\n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# add_graph() will trace the sample input through your model\n",
    "writer.add_graph(model, images)\n",
    "writer.flush()\n",
    "```\n",
    "\n",
    "**NN_graph in Tensorboard**\n",
    "![](./pytorch_nn/NN_Tensorboard_graph.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a086f",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1415bc",
   "metadata": {},
   "source": [
    "## 6. Sources and GitHub Links <br>\n",
    "**Sources**:\n",
    "- MSFT PyTorch Course | [link](https://docs.microsoft.com/en-us/learn/modules/intro-machine-learning-pytorch/8-quickstart)\n",
    "- PyTorch Official Tutorial Explaining with FashionMNIST data | [link](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html)\n",
    "- A useful Medium article on FashionMNIST dataset | [link](https://medium.com/@aaysbt/fashion-mnist-data-training-using-pytorch-7f6ad71e96f4)\n",
    "\n",
    "**Github Links**:\n",
    "- Dockerfile to replicate the environment | [link](https://github.com/senthilkumarm1901/myCodingProjects/blob/main/SpacyNER/docker/Dockerfile.txt)\n",
    "- To replicate the DL workflow described here | [Notebook link](https://github.com/senthilkumarm1901/PythonTutorials/blob/master/PyTorch_Tutorials/Microsoft_PyTorch_Course/PyTorch_NN_model_on_FashionMNIST_Tensorboard.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c658f",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('3.9.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "98c3ded5f4c982d767ead9cded27e95b53d0df25404a508cedfb98865b9710c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}