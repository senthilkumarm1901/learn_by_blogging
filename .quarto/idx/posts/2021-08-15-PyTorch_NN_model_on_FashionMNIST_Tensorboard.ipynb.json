{"title":"An Introduction to PyTorch Fundamentals for Training DL Models","markdown":{"yaml":{"aliases":["/pytorch/2021/08/15/PyTorch_NN_model_on_FashionMNIST_Tensorboard"],"author":"Senthil Kumar","badges":true,"branch":"master","categories":["Coding","DL"],"date":"2021-08-15","description":"This blog post explains the basics of PyTorch Tensors, the workflow to train a 2 layer Neural Network for a vision dataset and track the progress in a Tensorboard","hide":false,"image":"images/pytorch_nn/pytorch_offl_image.png","output-file":"2021-08-15-pytorch_nn_model_on_fashionmnist_tensorboard.html","title":"An Introduction to PyTorch Fundamentals for Training DL Models","toc":true},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\n\n- We have taken `FashionMNIST` dataset and prepared a simple 2-layer NN model to uncover the fundamental concepts of PyTorch\n- Before going into the DL portions, let us look at Tensors first\n\n<hr>\n\n## 0. What are Tensors\n\n- Tensors are **like** numerical arrays that encode the input, output and weights/parameters of a model in the form of arrays and matrices.\n- Typical 1D and 2D arrays:\n\n![image](https://user-images.githubusercontent.com/24909551/157380975-0402a8ec-7f49-49a3-aef8-5fadc19d4c9c.png)\nSource:  docs.microsoft.com/en-US/learn    \n\n- How to imagine a 3D array:\n\n![image](https://user-images.githubusercontent.com/24909551/157381034-056897c1-acea-459b-b43a-1b56d55b2434.png)\nSource:  docs.microsoft.com/en-US/learn    \n\n- Tensors work better on GPUs. They are optimized for **automatic differentiation**\n- Tensors and numpy often have the same memory address. For example, review the code below <br>\n\n```python\nimport numpy as np\nimport torch\n\ndata = [[1,2],[3,4]]\nnp_array = np.array(data)\ntensor_array = torch.from_numpy(np_array)\n\n# doing multiplication opearation on `np_array`\nnp.multiply(np_array,2,out=np_array)\n\nprint(f\"Numpy array:{np_array}\")\nprint(f\"Tensor array:{tensor_array}\")\n```\n\n```python\nNumpy array:[[2 4]\n [6 8]]\nTensor array:tensor([[2, 4],\n        [6, 8]])\n```\n\n**How to initialize a tensor?**: <br>\n\n```python    \n# directly from a python datastructure element\ndata = [[1,2],[3,4]]\nx_tensor_from_data = torch.tensor(data)\n\n# from numpy_array\nnp_array = np.array(data)\nx_tensor_from_numpy = torch.from_numpy(np_array)\n\n# from other tensors\nx_new_tensor = torch.rand_like(x_tensor_from_data, dtype=torch.float) # dtype overrides the dtype of z_tensor_from_data\n    \n# random or new tensor of given shape\nshape = (2,3,) # or just (2,3)\nx_new_tensor_2 = torch.ones(shape)\n```\n    \n**What are the `attributes` of a tensor?**:<br>\n\n```python\nprint(f\"{x_new_tensor_2.shape}\")\nprint(f\"{x_new_tensor_2.dtype}\")\nprint(f\"{x_new_tensor_2.device}\") # whether stored in CPU or GPU\n```\n\n**When to use CPU and and when to use GPU while `operating` tensors?**: <br>\n\n- Some common tensor operations include: Any arithmetic operation, linear algebra, matrix manipulation (transposing, indexing, slicing)\n- Typical GPUs have 1000s of cores. GPUs can handle parallel processing.\n\n![image](https://user-images.githubusercontent.com/24909551/159158293-6faec4f4-e959-4fa6-a5cf-114ddb83810b.png)\nSource:  docs.microsoft.com/en-US/learn    \n\n- Typical CPUs have 4 cores. Modern CPUs can have upto 16 cores. Cores are units that do the actual computation. Each core processes tasks in **sequential** order\n\n![image](https://user-images.githubusercontent.com/24909551/159158302-d75e6fea-eaaa-4c01-a930-0b41a5cfde7c.png)\nSource:  docs.microsoft.com/en-US/learn    \n\n- Caveat: Copying large tensors across devices can be expensive w.r.t `time` and `memory`\n\n- `PyTorch` uses Nvidia `CUDA` library in the backend to operate on GPU cards\n\n```python\nif torch.cuda._is_available():\n    gpu_tensor = original_tensor.to('cuda') \n```\n\n**What are the common tensor operations?**: <br>\n- `Joining` or `ConCATenate`\n```python\nnew_tensor = torch.cat([tensor, tensor],dim=1) # join along column if dim=1\n```    \n- `Matrix Multiplication`   \n```python\n# you would have to do the transpose\ny1 = tensor @ tensor.T\ny2 = tensor.matmul(tensor.T)\ny3 = torch.rand_like(tensor)\ntorch.matmul(tensor, tensor.T, out=y3)\nassert y1 = y2 = y3\n```\n\n- `Element-wise Multiplication`    \n```python\nz1 = tensor * tensor\nz2 = tensor.mul(tensor)\nz3 = torch.rand_like(tensor)\ntorch.mul(tensor, tensor, out=z3)\n```  \n\n- `Single element tensor` into python numerical value    \n```python\nsum_of_values = tensor.sum()\nsum_of_values_python_variable = sum_of_values.item()\nprint(sum_of_values.dtype, type(sum_of_values_python_variable))\n# >> torch.int64, <class 'int'>\n```\n\n- `In-place Operations`    \n\n```python\n# add in_place\ntensor.add_(5)\n```\n\n```\n# transpose  in place\ntensor.t_()\n\n```   \n\nSummary of the key operations\n\n - `torch.cuda.is_available()` gives a boolean output\n - `torch.tensor(x)` <br>\n  - x could be a 1D or 2D iterable (list or tuple) <br>\n - `torch.ones_like(tensor_variable)`, `torch.rand_like(tensor_variable)` <br>\n - `torch.ones(shape_in_a_tuple_or_list)` , `torch.zeros(shape_in_a_tuple_or_list)` and  `torch.rand(shape_in_a_tuple_or_list)` <br>\n - `torch_tensor_variable[start_index:end_index:step_value]` (similar to a numpy indexing)\n - numpy to torch tensor: `torch.from_numpy(np_array)`\n - torch_tensor to numpy: `torch_tensor_variable.numpy()`\n - Concatenate across rows `torch.cat((an_iterable_of_tensors),dim=0)`<br>\n - Concatenate across columns `torch.cat((an_iterable_of_tensors),dim=1)` <br>\n - tensor multiplication `tensor1 * tensor2 == torch.mul(tensor1,tensor2,out=tensor3) == tensor1.mul(tensor2)` <br>\n - convert single_element_tensor into a python datatype using `.item()` --> `single_element_tensor = tensor1.sum(); python_variable = single_element_tensor.item()` <br>\n - In-place Operations in torch using `_`: `x.add_(5)` will add 5 to each element of x <br>\n - tensor `n = t.numpy()` & np.add(n,2,out=n) --> A change in `n` will automatically change `t` (vice versa is true too)\n\n<hr>\n\nImporting relevant modules\n\n<hr>\n\n## 1. Dataset and DataLoaders\n\nTwo data `primitives` to handle data efficiently: <br>\n- `torch.utils.data.Dataset`\n- `torch.utils.data.DataLoader` \n\n**How should the data be preprocessed before training in DL?**: <br>\n- Pass samples of data in `minibatches`\n- reshuffle the data at every epoch to overfitting\n- leverage Python's `multiprocessing` to speed up data retrieval\n\n**`torch.utils.data.DataLoader` abstracts all the above steps**\n\n\nWhat does `Dataset` do?\n- `Dataset`: Stores data samples and their corresponding labels\n- `DataLoader`: Wraps an iterable around Dataset to enable easy access to the samples. `DataLoader` can also be used along with `torch.multiprocessing`\n- `torchvision.datasets` and `torchtext.datasets` are both subclasses of `torch.utils.data.Dataset` (they have __getitem__ and __len__ methods implemented) and also they can be passed to a `torch.utils.data.DataLoader`\n\n\n**What does normalization do?**: <br>\n- Changes the range of the data\n- When one pixel value is 15 and another pixel is 190, the higher pixel value will deviate the learning \n\n**Why do we do normalization of data before training a DL**:\n- Prediction accuracy is better for normalized data\n- Model can learn faster if data is normalized\n\n\n**More details on PyTorch Primitives**\n\n- `torchvision.datasets` --> to use pre-existing datasets like FashionMNIST, coco, cifar, etc.,\n- torchvision.datasets have arguments/parameters to `transform` featuers (aka inputs) and `target_transform` to transform labels (like one hot encoding of labels\n- CustomDatasetClass must overwrite the `magic methods` of python such as \n        - `__init__`, `__getitem__` and `__len__` methods inherited from `Dataset`\n- `torchvision.transforms.ToTensor` (to transform/modify the features) and `torchvision.transforms.Lambda` (to transform the target/labels)\n        - `torchvision.transforms.ToTensor()` converts features to normalized tensors\n        - `torchvision.transforms.Lambda` could be used to transform labels\n        - `Lambda(lambda y: torch.zeros(number_of_classes,dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1)\n                  )`\n        - `Tensor.scatter_` is used to change values of a tensor variable at specified indices\n\n### 1A. Converting Data into Model Suitable Iterables \n\n- Downloading and transforming the datasets\n- Preparing train, validation and test datasets\n\n```python\n# If you have a custom dataset in your location\n\nclass CustomImageDataset(Dataset):\n    \"\"\"FashionMNIST like Image Dataset Class\"\"\"\n    def __init__(self, \n                 annotations_file,\n                 img_dir,\n                 transform=None,\n                 target_transform=None):\n        \"\"\"\n        Args:\n            transform (Optional): dataset will take an optional argument transform \n                so that any required processing can be applied on the sample\n        \"\"\"\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n    \n    def __len__(self):\n        return len(self.img)\n    \n    def __getitem__(self, idx):\n        # format of data \n        # image_location, label_type\n        # tshirt1.jpg, T-shirt/top # class needs to be convered into numerical format\n        # pant4.jpg, Trouser # class needs to be convered into numerical format\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n        image = tvio.read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        sample = {\"image\": image, \"label\": label}\n        return sample\n\n\n# target_transform\n# turn the integer y values into a `one_hot_encoded` vector \n# 1. create a zero tensor of size 10 torch.zeros(10, dtype=torch.float)\n# 2. `scatter_` assigns a value =1\nthe_target_lambda_function = Lambda(lambda y: torch.zeros(10,\n                                    dtype=troch.float).scatter_(dim=0,\n                                                    index=torch.tensor(y), value=1))\n\n\ntraining_data = CustomImageDataset(\n    root=\"data\", # the path where the train/test data is stored\n    train=True, # False if it is a test dataset \n    download=False, # downloads the data from Web if not available at root\n    transform=ToTensor(), # transform the features; converts PIL image or numpy array into a FloatTensor and scaled the image's pixel intensity to the range [0,1]\n    target_transform=the_target_lambda_function\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=False,\n    transform=ToTensor(),\n    target_transform=the_target_lambda_function\n    # target_transform=torch.nn.functional.one_hot(y, num_classes=10) # alternate way\n)\n```\n\nPreparing Validation Data from Test Data\n\nConvert into iterables\n\n- The above shape of training image is in the format NCHW\n- batchsize N, no. of channels C, height H, width W\n\n### 1B. Visualize sample data\n\n### 1C. Initiating the Tensorboard Logs and Visualizing Sample Images\n\n**How to load the tensorboard**\n\nTo view, start TensorBoard on the command line with:\n- `tensorboard --logdir=runs`\n- and open a browser tab to http://localhost:6006/\n- Can view the sample images in `images` tab \n\n- Load the TensorBoard notebook extension for jupyter notebook\n```\n%load_ext tensorboard\n```\n\n- Run the tensorboard from jupyter notebook\n\n```\n%tensorboard --logdir runs/fashion_mnist_2_layer_NN_experiment_1\n```\n\n<hr>\n\n## 2. Build the Model Layers\n\nBuild a NN with **2 hidden layers** and 1 output layer\n\n**Components of a Neural Network**:\n\n- Typical Neural Network: <br>\n\n![image](https://user-images.githubusercontent.com/24909551/160055546-f6150c41-acb0-44a4-942e-0d20c86e8972.png)\n\n- Activation Function, Weight and Bias\n\n![image](https://user-images.githubusercontent.com/24909551/160055714-0bfb081d-6c1b-4733-a226-d7db71e74fec.png)\n\n- Linear weighted sum of inputs: x = &sum;(`weights` * `inputs`) + `bias`    \n- f(x) = activation_func(x)\n\n- Activation Functions add non-linearity to the model    \n- Different Activation Functions: <br>\n    - **Sigmoid**: <sup>1</sup>/<sub>(1 + exp(-x))</sub>\n    - **Softmax**: <sup>exp(x)</sup> / <sub>(sum(exp(x)))</sub>\n    - **ReLU**: max(0,x)\n    - **Tanh**: <sup>(exp(x) - exp(-x))</sup>/<sub>(exp(x) + exp(-x))</sub>\n\n**Building a neural network in PyTorch** \n- `torch.nn` class provides all the building block needed to build a NN\n- Every module/layer in PyTorch subclases the `torch.nn.Module`\n- A NN is a composite module consisting of other modules (layers)\n    \n    \n- Initialize all layers in `__init__` module\n- Build a 3-layer NN with \n    - flattened `28*28` image as input,\n    - 2 hidden layers will have 512 neurons each and\n    - the third layer (which also has relu activation function) will have 10 neurons each corresponding to the number of classes\n  \n\n- Why `model(X)` instead of `model.forward(X)`? <br>\n[Source](https://stackoverflow.com/questions/55338756/why-there-are-different-output-between-model-forwardinput-and-modelinput) \n\nDissecting the steps using Functional API\n\n- **Step 1**:Convert `28*28` into a contiguous array of 784 pixel values\n    \n```python\ninput_image = torch.rand(3, 28, 28)\nprint(input_image.size())\n# step 1: Flatten the input image\nflatten = nn.Flatten() # instantitate\nflat_image = flatten(input_image)  # pass the prev layer (input) into the instance\nprint(flat_image.size())\n```\n- **Step 2**: Dense or linear layer in PyTorch `weight * input + bias`\n    \n```python    \n# step 2: apply linear transformation `weight * input + bias`\nlayer1 = nn.Linear(in_features=28*28, out_features=512) # instantiate\nhidden1 = layer1(flat_image) # pass the prev layer (flattened image) into the instance\nprint(hidden1.size())\n```\n\n- **Step 3**: Apply Relu activation on the linear transformation\n    \n```python\nrelu_activation = nn.ReLU() #instantiate\nhidden1 = relu_activation(hidden1)\n```    \nRepeat Step 2 and 3 for `hidden2`: <br>\n\n```python\nlayer2 = nn.Linear(in_features=512, out_features=512)\nhidden2 = layer2(hidden1)\nhidden2 = relu_activation(hidden2)\n```    \n    \n- **Step 4**: Compute the logits\n    \n```python\n# a simple 1 hidden layer NN with 20 neurons in the hidden layer\nnn_seq_modules = nn.Sequential(\n                    flatten,\n                    layer1,\n                    relu_activation,\n                    layer2,\n                    relu_activation,\n                    nn.Linear(512, 10), # the output                )\ninput_image = torch.rand(3, 28, 28)\nlogits =  nn_seq_modules(input_image)   \n```\n    \n- **Step 5**: Apply `Softmax` function\n    \n```python\n\nsoftmax = nn.Softmax(dim=1)\npredict_probab = softmax(logits)\n\n```\n\n- Full NN workflow: \n \n![image](https://user-images.githubusercontent.com/24909551/161696907-8672f820-3293-4390-b153-bf702731352d.png)\nSource: docs.microsoft.com/en-US/learn    \n\n\n**How to see internal layers of a NN in PyTorch**:\n\n```python\nprint(\"Weights stored in first layer: {model.linear_relu_stack[0].weight} \\n\")\nprint(\"Bias stored in first layer: {model.linear_relu_stack[0].bias} \\n\") \n    \nfrom name, param in model.named_parameters():\n    print(f\"Layer: {name} | Size: {param.size()}\"\n```\n    \n```bash\nLayer: linear_relu_stack.0.weight | Size: torch.Size([512, 784])\nLayer: linear_relu_stack.0.bias | Size: torch.Size([512])\nLayer: linear_relu_stack.2.weight | Size: torch.Size([512, 512])\nLayer: linear_relu_stack.2.bias | Size: torch.Size([512])\nLayer: linear_relu_stack.4.weight | Size: torch.Size([10, 512])\nLayer: linear_relu_stack.4.bias | Size: torch.Size([10])\n```  \n\n<hr>\n\n## 3. Training the Model \nTraining with training data and evaluating loss on Validation Data\n\n### 3A.Setting Hyperparameters\n\n- `num_of_epochs`: The number of times the entire training dataset is pass through the network\n- `batch_size`: The number of data samples seen by the model before updating its weights. (derived parameter `steps = total_training_data/batch_size` - the number of batches needed to complete an epoch)\n- `learning_rate`: How much to change the weights in the `w = w - learning_rate * gradient`. Smaller value means the model will take a longer time to find best weights. Larger value of learning_rate might make the NN miss the optimal weights because we might step over the best values\n- Choice of `loss_fn` <br>\nCommon Loss Functions for classification problems :    \n    - `nn.NLLLoss` #Negative Log Likelihood    \n    - `nn.CrossEntropyLoss` # combination of `nn.LogSoftmax` and `nn.NLLLoss`   \n- Choice of `optimizers` <br>\n    - `torch.optim.SGD`\n    - `torch.optim.Adam`\n    - `torch.optim.RMSProp` and many more ...\n\n### 3B. Writing Core Training and Evaluation Loop Functions\n\n- `loss_fn` and `optimizer` are passed to `train_loop` and just `loss_fn` to `test_loop`\n```python\nfor i in range(epochs):\n    print(f\"Epoch {i+1}\\n ----------------------------\")\n    train_loop(train_dataloader, validation_dataloader, model, loss_fn, optimizer)\n    test_loop(test_dataloader,model, loss_fn)\nprint(\"Over!\")    \n```\n\n### 3C. Training the model for many epochs\n\n*truncated the results for easy viewing* \n\nPoints to ponder: \n- The accuracy for this 2-layer NN stands at 71%. \n- The Hyperparameters - batch_size, learning_rate, choice of optimizer - can be varied to see how results change.\n- **Changing Architecture**: Deepening the number of hidden layers can help in improving the accuracy or changing the architecture to use CNN or any pre-trained NN like *LeNet-5* or others will improve further\n\n### 3D. Saving, Loading and Exporting the model\n\n**How to save and load the model for inference?**    \n```python    \n# pytorch models save the parameters in a internal state dictionary called `state_dict`\ntorch.save(model.state_dict(),\"data/modelname.pth\")\n    \n# infer from a saved model\n# instantiate the model architecture class\nmodel = NeuralNetwork()\nmodel.load_state_dict(torch.load(\"data/modelname.pth\"))\n# the eval method is called before inferencing so that the batch normalization dropout layers are set to `evaluation` mod\n# Failing to do this can yield inconsistent inference results\nmodel.eval()\n```    \n\n**How to export a pytorch model to run in any Programming Language/Platform**: <br>\n    \n- **ONNX**: Open Neural Network Exchange \n- Converting `PyTorch` model to `onnx` format aids in running the model in Java, Javascript, C# and ML.NET\n    \n```python\n# while explorting pytorch model to onnx, \n# we'd have to pass a sample input of the right shape\n# this will help produce a `persisted` ONNX model    \nimport torch.onnx as onnx\ninput_image = torch.zeros((1,28,28))\nonnx_model_location = 'data/model.onnx'\nonnx.export(model, input_image, onnx_model)\n```    \n\n<hr>\n\n## 4. Predict using the Trained Model\nLoading the trained model and predicting for unseen data\n\n<hr>\n\n## 5. Leveraging Tensorboard\n\nReiterating the steps we have already done using Tensorboard\n\n- 1.Specifying the Log directory and using `add_images` method\n\n```python\n# `torch.utils.data.tensorboard.SummaryWriter` class\n# specifying the log directory\nwriter = SummaryWriter('runs/fashion_mnist_2_layer_NN_experiment_1')\n\n# writing the grid of 4 images to Tensorboard log dir\n# we can look at `IMAGES` tab of Tensorboard for this\nwriter.add_image('Four Sample Fashion-MNIST Images', img_grid)\nwriter.flush()\n```\n\n- 2.Tracking Epoch level Average Training and Validation Losses. \n\n```python \n# We can track in the `SCALARS` tab of the Tensorboard\nwriter.add_scalars('Training vs. Validation Loss',\n                   {'Training': avg_training_loss, \n                    'Validation': avg_validation_loss\n                   },\n                   epoch\n                  )\n```\n\n**The Graph of Training Loss (blue line) and Validation Loss (green line) in Tensorboard**\n\n![](./pytorch_nn/training_and_validation_loss_over_epochs.png)\n\n- 3.After trained model is obtained, we can look at the graph to trace the sample input through your model\n\n```python\n# We can track in the `GRAPH` tab of the Tensorboard\ndataiter = iter(train_dataloader)\nimages, labels = dataiter.next()\n\n# add_graph() will trace the sample input through your model\nwriter.add_graph(model, images)\nwriter.flush()\n```\n\n**NN_graph in Tensorboard**\n![](./pytorch_nn/NN_Tensorboard_graph.png)\n\n\n<hr>\n\n## 6. Sources and GitHub Links <br>\n**Sources**:\n- MSFT PyTorch Course | [link](https://docs.microsoft.com/en-us/learn/modules/intro-machine-learning-pytorch/8-quickstart)\n- PyTorch Official Tutorial Explaining with FashionMNIST data | [link](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html)\n- A useful Medium article on FashionMNIST dataset | [link](https://medium.com/@aaysbt/fashion-mnist-data-training-using-pytorch-7f6ad71e96f4)\n\n**Github Links**:\n- Dockerfile to replicate the environment | [link](https://github.com/senthilkumarm1901/myCodingProjects/blob/main/SpacyNER/docker/Dockerfile.txt)\n- To replicate the DL workflow described here | [Notebook link](https://github.com/senthilkumarm1901/PythonTutorials/blob/master/PyTorch_Tutorials/Microsoft_PyTorch_Course/PyTorch_NN_model_on_FashionMNIST_Tensorboard.ipynb)\n\n<hr>\n","srcMarkdownNoYaml":"\n\n\n\n## Introduction\n\n- We have taken `FashionMNIST` dataset and prepared a simple 2-layer NN model to uncover the fundamental concepts of PyTorch\n- Before going into the DL portions, let us look at Tensors first\n\n<hr>\n\n## 0. What are Tensors\n\n- Tensors are **like** numerical arrays that encode the input, output and weights/parameters of a model in the form of arrays and matrices.\n- Typical 1D and 2D arrays:\n\n![image](https://user-images.githubusercontent.com/24909551/157380975-0402a8ec-7f49-49a3-aef8-5fadc19d4c9c.png)\nSource:  docs.microsoft.com/en-US/learn    \n\n- How to imagine a 3D array:\n\n![image](https://user-images.githubusercontent.com/24909551/157381034-056897c1-acea-459b-b43a-1b56d55b2434.png)\nSource:  docs.microsoft.com/en-US/learn    \n\n- Tensors work better on GPUs. They are optimized for **automatic differentiation**\n- Tensors and numpy often have the same memory address. For example, review the code below <br>\n\n```python\nimport numpy as np\nimport torch\n\ndata = [[1,2],[3,4]]\nnp_array = np.array(data)\ntensor_array = torch.from_numpy(np_array)\n\n# doing multiplication opearation on `np_array`\nnp.multiply(np_array,2,out=np_array)\n\nprint(f\"Numpy array:{np_array}\")\nprint(f\"Tensor array:{tensor_array}\")\n```\n\n```python\nNumpy array:[[2 4]\n [6 8]]\nTensor array:tensor([[2, 4],\n        [6, 8]])\n```\n\n**How to initialize a tensor?**: <br>\n\n```python    \n# directly from a python datastructure element\ndata = [[1,2],[3,4]]\nx_tensor_from_data = torch.tensor(data)\n\n# from numpy_array\nnp_array = np.array(data)\nx_tensor_from_numpy = torch.from_numpy(np_array)\n\n# from other tensors\nx_new_tensor = torch.rand_like(x_tensor_from_data, dtype=torch.float) # dtype overrides the dtype of z_tensor_from_data\n    \n# random or new tensor of given shape\nshape = (2,3,) # or just (2,3)\nx_new_tensor_2 = torch.ones(shape)\n```\n    \n**What are the `attributes` of a tensor?**:<br>\n\n```python\nprint(f\"{x_new_tensor_2.shape}\")\nprint(f\"{x_new_tensor_2.dtype}\")\nprint(f\"{x_new_tensor_2.device}\") # whether stored in CPU or GPU\n```\n\n**When to use CPU and and when to use GPU while `operating` tensors?**: <br>\n\n- Some common tensor operations include: Any arithmetic operation, linear algebra, matrix manipulation (transposing, indexing, slicing)\n- Typical GPUs have 1000s of cores. GPUs can handle parallel processing.\n\n![image](https://user-images.githubusercontent.com/24909551/159158293-6faec4f4-e959-4fa6-a5cf-114ddb83810b.png)\nSource:  docs.microsoft.com/en-US/learn    \n\n- Typical CPUs have 4 cores. Modern CPUs can have upto 16 cores. Cores are units that do the actual computation. Each core processes tasks in **sequential** order\n\n![image](https://user-images.githubusercontent.com/24909551/159158302-d75e6fea-eaaa-4c01-a930-0b41a5cfde7c.png)\nSource:  docs.microsoft.com/en-US/learn    \n\n- Caveat: Copying large tensors across devices can be expensive w.r.t `time` and `memory`\n\n- `PyTorch` uses Nvidia `CUDA` library in the backend to operate on GPU cards\n\n```python\nif torch.cuda._is_available():\n    gpu_tensor = original_tensor.to('cuda') \n```\n\n**What are the common tensor operations?**: <br>\n- `Joining` or `ConCATenate`\n```python\nnew_tensor = torch.cat([tensor, tensor],dim=1) # join along column if dim=1\n```    \n- `Matrix Multiplication`   \n```python\n# you would have to do the transpose\ny1 = tensor @ tensor.T\ny2 = tensor.matmul(tensor.T)\ny3 = torch.rand_like(tensor)\ntorch.matmul(tensor, tensor.T, out=y3)\nassert y1 = y2 = y3\n```\n\n- `Element-wise Multiplication`    \n```python\nz1 = tensor * tensor\nz2 = tensor.mul(tensor)\nz3 = torch.rand_like(tensor)\ntorch.mul(tensor, tensor, out=z3)\n```  \n\n- `Single element tensor` into python numerical value    \n```python\nsum_of_values = tensor.sum()\nsum_of_values_python_variable = sum_of_values.item()\nprint(sum_of_values.dtype, type(sum_of_values_python_variable))\n# >> torch.int64, <class 'int'>\n```\n\n- `In-place Operations`    \n\n```python\n# add in_place\ntensor.add_(5)\n```\n\n```\n# transpose  in place\ntensor.t_()\n\n```   \n\nSummary of the key operations\n\n - `torch.cuda.is_available()` gives a boolean output\n - `torch.tensor(x)` <br>\n  - x could be a 1D or 2D iterable (list or tuple) <br>\n - `torch.ones_like(tensor_variable)`, `torch.rand_like(tensor_variable)` <br>\n - `torch.ones(shape_in_a_tuple_or_list)` , `torch.zeros(shape_in_a_tuple_or_list)` and  `torch.rand(shape_in_a_tuple_or_list)` <br>\n - `torch_tensor_variable[start_index:end_index:step_value]` (similar to a numpy indexing)\n - numpy to torch tensor: `torch.from_numpy(np_array)`\n - torch_tensor to numpy: `torch_tensor_variable.numpy()`\n - Concatenate across rows `torch.cat((an_iterable_of_tensors),dim=0)`<br>\n - Concatenate across columns `torch.cat((an_iterable_of_tensors),dim=1)` <br>\n - tensor multiplication `tensor1 * tensor2 == torch.mul(tensor1,tensor2,out=tensor3) == tensor1.mul(tensor2)` <br>\n - convert single_element_tensor into a python datatype using `.item()` --> `single_element_tensor = tensor1.sum(); python_variable = single_element_tensor.item()` <br>\n - In-place Operations in torch using `_`: `x.add_(5)` will add 5 to each element of x <br>\n - tensor `n = t.numpy()` & np.add(n,2,out=n) --> A change in `n` will automatically change `t` (vice versa is true too)\n\n<hr>\n\nImporting relevant modules\n\n<hr>\n\n## 1. Dataset and DataLoaders\n\nTwo data `primitives` to handle data efficiently: <br>\n- `torch.utils.data.Dataset`\n- `torch.utils.data.DataLoader` \n\n**How should the data be preprocessed before training in DL?**: <br>\n- Pass samples of data in `minibatches`\n- reshuffle the data at every epoch to overfitting\n- leverage Python's `multiprocessing` to speed up data retrieval\n\n**`torch.utils.data.DataLoader` abstracts all the above steps**\n\n\nWhat does `Dataset` do?\n- `Dataset`: Stores data samples and their corresponding labels\n- `DataLoader`: Wraps an iterable around Dataset to enable easy access to the samples. `DataLoader` can also be used along with `torch.multiprocessing`\n- `torchvision.datasets` and `torchtext.datasets` are both subclasses of `torch.utils.data.Dataset` (they have __getitem__ and __len__ methods implemented) and also they can be passed to a `torch.utils.data.DataLoader`\n\n\n**What does normalization do?**: <br>\n- Changes the range of the data\n- When one pixel value is 15 and another pixel is 190, the higher pixel value will deviate the learning \n\n**Why do we do normalization of data before training a DL**:\n- Prediction accuracy is better for normalized data\n- Model can learn faster if data is normalized\n\n\n**More details on PyTorch Primitives**\n\n- `torchvision.datasets` --> to use pre-existing datasets like FashionMNIST, coco, cifar, etc.,\n- torchvision.datasets have arguments/parameters to `transform` featuers (aka inputs) and `target_transform` to transform labels (like one hot encoding of labels\n- CustomDatasetClass must overwrite the `magic methods` of python such as \n        - `__init__`, `__getitem__` and `__len__` methods inherited from `Dataset`\n- `torchvision.transforms.ToTensor` (to transform/modify the features) and `torchvision.transforms.Lambda` (to transform the target/labels)\n        - `torchvision.transforms.ToTensor()` converts features to normalized tensors\n        - `torchvision.transforms.Lambda` could be used to transform labels\n        - `Lambda(lambda y: torch.zeros(number_of_classes,dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1)\n                  )`\n        - `Tensor.scatter_` is used to change values of a tensor variable at specified indices\n\n### 1A. Converting Data into Model Suitable Iterables \n\n- Downloading and transforming the datasets\n- Preparing train, validation and test datasets\n\n```python\n# If you have a custom dataset in your location\n\nclass CustomImageDataset(Dataset):\n    \"\"\"FashionMNIST like Image Dataset Class\"\"\"\n    def __init__(self, \n                 annotations_file,\n                 img_dir,\n                 transform=None,\n                 target_transform=None):\n        \"\"\"\n        Args:\n            transform (Optional): dataset will take an optional argument transform \n                so that any required processing can be applied on the sample\n        \"\"\"\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n    \n    def __len__(self):\n        return len(self.img)\n    \n    def __getitem__(self, idx):\n        # format of data \n        # image_location, label_type\n        # tshirt1.jpg, T-shirt/top # class needs to be convered into numerical format\n        # pant4.jpg, Trouser # class needs to be convered into numerical format\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n        image = tvio.read_image(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        sample = {\"image\": image, \"label\": label}\n        return sample\n\n\n# target_transform\n# turn the integer y values into a `one_hot_encoded` vector \n# 1. create a zero tensor of size 10 torch.zeros(10, dtype=torch.float)\n# 2. `scatter_` assigns a value =1\nthe_target_lambda_function = Lambda(lambda y: torch.zeros(10,\n                                    dtype=troch.float).scatter_(dim=0,\n                                                    index=torch.tensor(y), value=1))\n\n\ntraining_data = CustomImageDataset(\n    root=\"data\", # the path where the train/test data is stored\n    train=True, # False if it is a test dataset \n    download=False, # downloads the data from Web if not available at root\n    transform=ToTensor(), # transform the features; converts PIL image or numpy array into a FloatTensor and scaled the image's pixel intensity to the range [0,1]\n    target_transform=the_target_lambda_function\n)\n\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=False,\n    transform=ToTensor(),\n    target_transform=the_target_lambda_function\n    # target_transform=torch.nn.functional.one_hot(y, num_classes=10) # alternate way\n)\n```\n\nPreparing Validation Data from Test Data\n\nConvert into iterables\n\n- The above shape of training image is in the format NCHW\n- batchsize N, no. of channels C, height H, width W\n\n### 1B. Visualize sample data\n\n### 1C. Initiating the Tensorboard Logs and Visualizing Sample Images\n\n**How to load the tensorboard**\n\nTo view, start TensorBoard on the command line with:\n- `tensorboard --logdir=runs`\n- and open a browser tab to http://localhost:6006/\n- Can view the sample images in `images` tab \n\n- Load the TensorBoard notebook extension for jupyter notebook\n```\n%load_ext tensorboard\n```\n\n- Run the tensorboard from jupyter notebook\n\n```\n%tensorboard --logdir runs/fashion_mnist_2_layer_NN_experiment_1\n```\n\n<hr>\n\n## 2. Build the Model Layers\n\nBuild a NN with **2 hidden layers** and 1 output layer\n\n**Components of a Neural Network**:\n\n- Typical Neural Network: <br>\n\n![image](https://user-images.githubusercontent.com/24909551/160055546-f6150c41-acb0-44a4-942e-0d20c86e8972.png)\n\n- Activation Function, Weight and Bias\n\n![image](https://user-images.githubusercontent.com/24909551/160055714-0bfb081d-6c1b-4733-a226-d7db71e74fec.png)\n\n- Linear weighted sum of inputs: x = &sum;(`weights` * `inputs`) + `bias`    \n- f(x) = activation_func(x)\n\n- Activation Functions add non-linearity to the model    \n- Different Activation Functions: <br>\n    - **Sigmoid**: <sup>1</sup>/<sub>(1 + exp(-x))</sub>\n    - **Softmax**: <sup>exp(x)</sup> / <sub>(sum(exp(x)))</sub>\n    - **ReLU**: max(0,x)\n    - **Tanh**: <sup>(exp(x) - exp(-x))</sup>/<sub>(exp(x) + exp(-x))</sub>\n\n**Building a neural network in PyTorch** \n- `torch.nn` class provides all the building block needed to build a NN\n- Every module/layer in PyTorch subclases the `torch.nn.Module`\n- A NN is a composite module consisting of other modules (layers)\n    \n    \n- Initialize all layers in `__init__` module\n- Build a 3-layer NN with \n    - flattened `28*28` image as input,\n    - 2 hidden layers will have 512 neurons each and\n    - the third layer (which also has relu activation function) will have 10 neurons each corresponding to the number of classes\n  \n\n- Why `model(X)` instead of `model.forward(X)`? <br>\n[Source](https://stackoverflow.com/questions/55338756/why-there-are-different-output-between-model-forwardinput-and-modelinput) \n\nDissecting the steps using Functional API\n\n- **Step 1**:Convert `28*28` into a contiguous array of 784 pixel values\n    \n```python\ninput_image = torch.rand(3, 28, 28)\nprint(input_image.size())\n# step 1: Flatten the input image\nflatten = nn.Flatten() # instantitate\nflat_image = flatten(input_image)  # pass the prev layer (input) into the instance\nprint(flat_image.size())\n```\n- **Step 2**: Dense or linear layer in PyTorch `weight * input + bias`\n    \n```python    \n# step 2: apply linear transformation `weight * input + bias`\nlayer1 = nn.Linear(in_features=28*28, out_features=512) # instantiate\nhidden1 = layer1(flat_image) # pass the prev layer (flattened image) into the instance\nprint(hidden1.size())\n```\n\n- **Step 3**: Apply Relu activation on the linear transformation\n    \n```python\nrelu_activation = nn.ReLU() #instantiate\nhidden1 = relu_activation(hidden1)\n```    \nRepeat Step 2 and 3 for `hidden2`: <br>\n\n```python\nlayer2 = nn.Linear(in_features=512, out_features=512)\nhidden2 = layer2(hidden1)\nhidden2 = relu_activation(hidden2)\n```    \n    \n- **Step 4**: Compute the logits\n    \n```python\n# a simple 1 hidden layer NN with 20 neurons in the hidden layer\nnn_seq_modules = nn.Sequential(\n                    flatten,\n                    layer1,\n                    relu_activation,\n                    layer2,\n                    relu_activation,\n                    nn.Linear(512, 10), # the output                )\ninput_image = torch.rand(3, 28, 28)\nlogits =  nn_seq_modules(input_image)   \n```\n    \n- **Step 5**: Apply `Softmax` function\n    \n```python\n\nsoftmax = nn.Softmax(dim=1)\npredict_probab = softmax(logits)\n\n```\n\n- Full NN workflow: \n \n![image](https://user-images.githubusercontent.com/24909551/161696907-8672f820-3293-4390-b153-bf702731352d.png)\nSource: docs.microsoft.com/en-US/learn    \n\n\n**How to see internal layers of a NN in PyTorch**:\n\n```python\nprint(\"Weights stored in first layer: {model.linear_relu_stack[0].weight} \\n\")\nprint(\"Bias stored in first layer: {model.linear_relu_stack[0].bias} \\n\") \n    \nfrom name, param in model.named_parameters():\n    print(f\"Layer: {name} | Size: {param.size()}\"\n```\n    \n```bash\nLayer: linear_relu_stack.0.weight | Size: torch.Size([512, 784])\nLayer: linear_relu_stack.0.bias | Size: torch.Size([512])\nLayer: linear_relu_stack.2.weight | Size: torch.Size([512, 512])\nLayer: linear_relu_stack.2.bias | Size: torch.Size([512])\nLayer: linear_relu_stack.4.weight | Size: torch.Size([10, 512])\nLayer: linear_relu_stack.4.bias | Size: torch.Size([10])\n```  \n\n<hr>\n\n## 3. Training the Model \nTraining with training data and evaluating loss on Validation Data\n\n### 3A.Setting Hyperparameters\n\n- `num_of_epochs`: The number of times the entire training dataset is pass through the network\n- `batch_size`: The number of data samples seen by the model before updating its weights. (derived parameter `steps = total_training_data/batch_size` - the number of batches needed to complete an epoch)\n- `learning_rate`: How much to change the weights in the `w = w - learning_rate * gradient`. Smaller value means the model will take a longer time to find best weights. Larger value of learning_rate might make the NN miss the optimal weights because we might step over the best values\n- Choice of `loss_fn` <br>\nCommon Loss Functions for classification problems :    \n    - `nn.NLLLoss` #Negative Log Likelihood    \n    - `nn.CrossEntropyLoss` # combination of `nn.LogSoftmax` and `nn.NLLLoss`   \n- Choice of `optimizers` <br>\n    - `torch.optim.SGD`\n    - `torch.optim.Adam`\n    - `torch.optim.RMSProp` and many more ...\n\n### 3B. Writing Core Training and Evaluation Loop Functions\n\n- `loss_fn` and `optimizer` are passed to `train_loop` and just `loss_fn` to `test_loop`\n```python\nfor i in range(epochs):\n    print(f\"Epoch {i+1}\\n ----------------------------\")\n    train_loop(train_dataloader, validation_dataloader, model, loss_fn, optimizer)\n    test_loop(test_dataloader,model, loss_fn)\nprint(\"Over!\")    \n```\n\n### 3C. Training the model for many epochs\n\n*truncated the results for easy viewing* \n\nPoints to ponder: \n- The accuracy for this 2-layer NN stands at 71%. \n- The Hyperparameters - batch_size, learning_rate, choice of optimizer - can be varied to see how results change.\n- **Changing Architecture**: Deepening the number of hidden layers can help in improving the accuracy or changing the architecture to use CNN or any pre-trained NN like *LeNet-5* or others will improve further\n\n### 3D. Saving, Loading and Exporting the model\n\n**How to save and load the model for inference?**    \n```python    \n# pytorch models save the parameters in a internal state dictionary called `state_dict`\ntorch.save(model.state_dict(),\"data/modelname.pth\")\n    \n# infer from a saved model\n# instantiate the model architecture class\nmodel = NeuralNetwork()\nmodel.load_state_dict(torch.load(\"data/modelname.pth\"))\n# the eval method is called before inferencing so that the batch normalization dropout layers are set to `evaluation` mod\n# Failing to do this can yield inconsistent inference results\nmodel.eval()\n```    \n\n**How to export a pytorch model to run in any Programming Language/Platform**: <br>\n    \n- **ONNX**: Open Neural Network Exchange \n- Converting `PyTorch` model to `onnx` format aids in running the model in Java, Javascript, C# and ML.NET\n    \n```python\n# while explorting pytorch model to onnx, \n# we'd have to pass a sample input of the right shape\n# this will help produce a `persisted` ONNX model    \nimport torch.onnx as onnx\ninput_image = torch.zeros((1,28,28))\nonnx_model_location = 'data/model.onnx'\nonnx.export(model, input_image, onnx_model)\n```    \n\n<hr>\n\n## 4. Predict using the Trained Model\nLoading the trained model and predicting for unseen data\n\n<hr>\n\n## 5. Leveraging Tensorboard\n\nReiterating the steps we have already done using Tensorboard\n\n- 1.Specifying the Log directory and using `add_images` method\n\n```python\n# `torch.utils.data.tensorboard.SummaryWriter` class\n# specifying the log directory\nwriter = SummaryWriter('runs/fashion_mnist_2_layer_NN_experiment_1')\n\n# writing the grid of 4 images to Tensorboard log dir\n# we can look at `IMAGES` tab of Tensorboard for this\nwriter.add_image('Four Sample Fashion-MNIST Images', img_grid)\nwriter.flush()\n```\n\n- 2.Tracking Epoch level Average Training and Validation Losses. \n\n```python \n# We can track in the `SCALARS` tab of the Tensorboard\nwriter.add_scalars('Training vs. Validation Loss',\n                   {'Training': avg_training_loss, \n                    'Validation': avg_validation_loss\n                   },\n                   epoch\n                  )\n```\n\n**The Graph of Training Loss (blue line) and Validation Loss (green line) in Tensorboard**\n\n![](./pytorch_nn/training_and_validation_loss_over_epochs.png)\n\n- 3.After trained model is obtained, we can look at the graph to trace the sample input through your model\n\n```python\n# We can track in the `GRAPH` tab of the Tensorboard\ndataiter = iter(train_dataloader)\nimages, labels = dataiter.next()\n\n# add_graph() will trace the sample input through your model\nwriter.add_graph(model, images)\nwriter.flush()\n```\n\n**NN_graph in Tensorboard**\n![](./pytorch_nn/NN_Tensorboard_graph.png)\n\n\n<hr>\n\n## 6. Sources and GitHub Links <br>\n**Sources**:\n- MSFT PyTorch Course | [link](https://docs.microsoft.com/en-us/learn/modules/intro-machine-learning-pytorch/8-quickstart)\n- PyTorch Official Tutorial Explaining with FashionMNIST data | [link](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html)\n- A useful Medium article on FashionMNIST dataset | [link](https://medium.com/@aaysbt/fashion-mnist-data-training-using-pytorch-7f6ad71e96f4)\n\n**Github Links**:\n- Dockerfile to replicate the environment | [link](https://github.com/senthilkumarm1901/myCodingProjects/blob/main/SpacyNER/docker/Dockerfile.txt)\n- To replicate the DL workflow described here | [Notebook link](https://github.com/senthilkumarm1901/PythonTutorials/blob/master/PyTorch_Tutorials/Microsoft_PyTorch_Course/PyTorch_NN_model_on_FashionMNIST_Tensorboard.ipynb)\n\n<hr>\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"2021-08-15-pytorch_nn_model_on_fashionmnist_tensorboard.html","toc":true},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.336","theme":"cosmo","title-block-banner":true,"comments":{"utterances":{"repo":"senthilkumarm1901/QuartoBlogComments"}},"aliases":["/pytorch/2021/08/15/PyTorch_NN_model_on_FashionMNIST_Tensorboard"],"author":"Senthil Kumar","badges":true,"branch":"master","categories":["Coding","DL"],"date":"2021-08-15","description":"This blog post explains the basics of PyTorch Tensors, the workflow to train a 2 layer Neural Network for a vision dataset and track the progress in a Tensorboard","hide":false,"image":"images/pytorch_nn/pytorch_offl_image.png","title":"An Introduction to PyTorch Fundamentals for Training DL Models"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}